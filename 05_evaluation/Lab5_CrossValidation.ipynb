{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXDEAQB-4GU_"
      },
      "source": [
        "# PC Lab 5: Resampling Methods for Model Evaluation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vNUHM4IIpSiT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, LeaveOneOut\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pc5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wek8o13f4GVD"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/K-fold_cross_validation_EN.svg/2880px-K-fold_cross_validation_EN.svg.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqSQ6kUj4GVE"
      },
      "source": [
        "This tutorial is about an important tool for evaluating how accurate your model will perform in practice: _Resampling methods_ are an dispensable tool in modern statistics and involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about\n",
        "the fitted model. \n",
        "\n",
        "For example, in order to estimate the variability of a linear regression fit, we can repeatedly draw different samples from the training data, fit a linear regression to each new sample, and then examine the\n",
        "extent to which the resulting fits differ. Such an approach may allow us to obtain information that would not be available from fitting the model only once using the original training sample. \n",
        "\n",
        "Resampling approaches can be computationally expensive, because they involve fitting the same statistical method multiple times using different subsets of the training data. However, due to recent advances in computing\n",
        "power, the computational requirements of resampling methods generally are not prohibitive. In this PC lab, we discuss two of the most commonly used resampling methods, _cross-validation_ and nested cross-validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again first load the necessary files for this PC-lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('promoters.csv', <http.client.HTTPMessage at 0x16dd330d0>)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/tfmortie/mlmust/main/05_evaluation/pc5.py\n",
        "!wget https://raw.githubusercontent.com/tfmortie/mlmust/main/05_evaluation/promoters.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM9PfHRm4GVE"
      },
      "source": [
        "## 2. Data exploration: A simple promoter library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mRhkWCQ4GVG"
      },
      "source": [
        "The dataset used for the first exercise is a simpe [E. coli promoter database](https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.names) that contains a set of both promoter regions and non-promoter regions. A promoter region is the DNA sequence upstream of genes to which the RNA polymerase binds before the transcription of genes is initiated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://ib.bioninja.com.au/_Media/sections-of-a-gene_med.jpeg\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi2MHW4i4GVH"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 2.1</b>: **Load in the data and explore. Use _pd.Series.value_counts()_ to evaluate the empirical distribution of the labels. The data is stored in promoters.csv**\n",
        "</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cvaXLRvd4GVH",
        "outputId": "70acce48-5f3d-464e-a037-58c07b75120b"
      },
      "outputs": [],
      "source": [
        "df_data = \"...\" # TODO: load the data from the promoters.csv file\n",
        "\n",
        "\"...\" # explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHssRY5H4GVI"
      },
      "source": [
        "**We see the first column is not used to identify column names**. Hence, we can just load the dataframe without the header by means of setting <code>header=None<code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PA5Mm3uq4GVI",
        "outputId": "8944ffc9-3b3d-4fbf-9d2a-ca572fa3388e"
      },
      "outputs": [],
      "source": [
        "df_data = \"...\" # load data again without column names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now evaluate the distribution of the 2 labels, using the built-in pandas function <code>pd.Series.value_counts()</code>. Is our dataset balanced?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z05lMXdw4GVJ",
        "outputId": "e8150daf-f4b0-4a54-b496-ae2e61b900c0"
      },
      "outputs": [],
      "source": [
        "\"...\" # count the number of promoters and non-promoters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQU8XOFf4GVJ"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 2.2</b>: **Create the features and labels for the model. Create your own features by using insights from the previous practical or use _pc5.CreateDummyNucleotideFeatures()_. In order to transform the labels, take a look at _sklearn.preprocessing.LabelEncoder_.**\n",
        "</div>  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Hint: As given in the docstring: for the features, a pandas DataFrame object is returned. To transform into Numpy array, use the <code>pd.DataFrame.values</code> function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYGhR8YQ4GVK"
      },
      "outputs": [],
      "source": [
        "X = \"...\" #TODO: use pc5.CreateDummyNucleotideFeatures to create a feature matrix from the DNA sequences\n",
        "#get numpy array from pandas dataframe\n",
        "X = \"...\"\n",
        "\n",
        "y = \"...\" # TODO: encode the labels "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg_n8cWT4GVK"
      },
      "source": [
        "## 3. Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o0wd-MJ4GVK"
      },
      "source": [
        "In this section we will elaborate on two specific questions that are strongly related to cross-validation. Both questions stem from the fact that we aim to build models with a high predictive power, based on a finite dataset.\n",
        " - **Question 1**: Given a relatively small dataset, how can we use the promoter dataset as efficiently as possible, to construct a model that  optimally predicts the existence of a promoter region in the prokaryotic DNA?\n",
        " - **Question 2**: How can we decide which machine learning method should be preferred to predict the presence of a promoter region?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEZpgX4p4GVL"
      },
      "source": [
        "### Question 1: k-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voJN5DPu4GVL"
      },
      "source": [
        "K-fold cross-validation is a resampling technique that is often used in machine learning in order to assess the generalization performance of a machine learning model. It consists of partitioning a dataset into k equally-sized folds or subsets. Next, the model is trained and validated k times, each time using a different fold as the evaluation set and the remaining k-1 folds as training set. The final performance metric is often computed as the average of the performance scores obtained in each iteration, providing a more reliable estimate of the model's generalization ability.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAwIlHM8TpAVe4l2FihNUQ.png\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CljiS6894GVL"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.1</b>: **Write out code that performs cross-validation for a k-nearest neighbor model by using the [_StratifiedKFold()_](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) function in Scikit-learn. Use four folds and determine the optimal number of neighbors that maximize accuracy. What is the optimal number of neighbors?**\n",
        "</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "IK562Hbl4GVM",
        "outputId": "29d8d1d5-fec6-4436-b90d-9a30366ab7a9"
      },
      "outputs": [],
      "source": [
        "fold_scores = []\n",
        "# define space to iterate over\n",
        "space = np.arange(1,20)\n",
        "# define folds\n",
        "folds = StratifiedKFold(\"...\") # TODO: define number of folds, set shuffle to True\n",
        "\n",
        "for tr_idx, tu_idx in \"...\": # TODO: iterate over the folds splitting the data\n",
        "    hyper_scores = [] # store scores for each hyperparameter (number of neighbors in thiss case)\n",
        "    for hyper in space:\n",
        "        knn = \"...\" # TODO: define classifier with hyper as number of neighbors\n",
        "        \"...\" # TODO: fit calssifier on training data\n",
        "        score = \"...\" # TODO: evaluate score on leave-out data\n",
        "        \"...\" # TODO: save score in list\n",
        "    fold_scores.append(hyper_scores) # save scores for each fold\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,6))\n",
        "ax.plot(space, np.mean(fold_scores, axis=0), '-o') # use the mean of the scores for each hyperparameter\n",
        "ax.set_xlabel(\"Number of neighbors\")\n",
        "ax.set_ylabel(\"Mean Score\")\n",
        "ax.set_title(\"KNN cross-validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPUC-3zT4GVM"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.2</b>: **Copy your code from the previous exercise below. Replace the plot function with the _ax.errorbar()_ function and add the variances of the scores displayed as vertical bars. In what range do they lie?**\n",
        "</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "scfFRJ8r4GVM",
        "outputId": "c295eaf0-489a-4d13-ce79-c1d6a11d6087"
      },
      "outputs": [],
      "source": [
        "fold_scores = []\n",
        "# define space to iterate over\n",
        "space = np.arange(1,20)\n",
        "# define folds\n",
        "folds = \"...\"\n",
        "\n",
        "\"...\" # TODO: do same procedure, using erorobars to show the variance between the folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcVwxGxV4GVN"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.3</b>: **Evaluate the variance of the performance measure for an increasing amount of folds. Use as many folds as possible. Applying cross-validation with n-1 folds is also known as leave-one-out cross-validation (LOOCV). Note that using the _StratifiedKFold()_ function does not allow you to perform LOOCV, since it restricts the user to $n/2$ folds, in order to preserve the percentage of sample per class. Use the [_LeaveOneOut_](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html) class in Scikit-learn instead. Think about the (dis)advantages of using few or many folds.**\n",
        "</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "cuRxwYcV4GVN",
        "outputId": "7ad6f5ad-d7f6-4b13-879d-c10577726803"
      },
      "outputs": [],
      "source": [
        "n_splits = \"...\"\n",
        "\n",
        "\"...\" # TODO: explore the effect of the number of folds on the variance of the scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 786,
      "position": {
        "height": "40px",
        "left": "1419.27px",
        "right": "20px",
        "top": "165.95px",
        "width": "482px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
