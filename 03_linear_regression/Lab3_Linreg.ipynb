{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqd-E7gdqZBs"
      },
      "source": [
        "# PC lab 3: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8xRJtLhQq6d"
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/BioML-UGent/MLLS/main/03_linear_regression/pc3.py -O pc3.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqz2SRIbqZBx"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orkPp1-uqZBx"
      },
      "source": [
        "The goal of linear regression is to model the relationship between one or more features *x* and a **continuous** variable *y*. When there is only one feature $x_1$ (univariate linear regression), the equation of the regression line is:\n",
        "\n",
        "<center>$\\hat{y} = w_{0} + w_{1}x_{1}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ANrT8zqZBy"
      },
      "source": [
        "where $w_{0}$ is the intercept on the y-axis, or bias. In the case of multiple features, we talk about multiple linear regression, and y is modelled as a linear combination of the features, weighted by some set of weights w:\n",
        "\n",
        "<center>$\\hat{y} = w_{0}x_{0} + w_{1}x_{1} + ... + w_{p}x_{p} = \\sum\\limits_{i=0}^{p}w_{i}x_{i}$,\n",
        "\n",
        "In this notation, we introduced an additional feature $x_{0}$ which always equals 1. This notation allows to formulate linear regression as a matrix multiplication:\n",
        "\n",
        "<center>$\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{w}$,\n",
        "\n",
        "where $\\mathbf{\\hat{y}}$ (a vector of dimension $n \\times 1$) contains the predicted target variable for the $n$ instances, $\\mathbf{w}$ is a $p \\times 1$ vector containing the weights and $\\mathbf{X}$ is a $n \\times (p+1)$ matrix with the features. Note that the first column of $\\mathbf{X}$ is a column of ones, because it represents the feature $x_{0}$ that we introduced to go with the intercept. We will stick to this matrix notation for the rest of this lab, as this notation is common practice in machine learning. Also, this notation makes it much easier to translate an algorithm into python code. Make sure that you understand it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKN22v6EqZBy"
      },
      "source": [
        "Fitting this model to a set of data comes down to finding the weight vector $\\mathbf{w}$ that minimizes the discrepancy between the true target values $\\mathbf{y}$ and the predictions $\\hat{\\mathbf{y}}$. As is often the case in regression problems, this discrepancy between true values and predicted values is expressed by the total sum of squared errors or the **residual sum of squares (RSS)**:\n",
        "\n",
        "<center>$RSS = \\sum\\limits_{i=1}^{n}(\\hat{y}_{i} - y_{i})^2$,\n",
        "\n",
        "or, equivalently:\n",
        "\n",
        "<center>$RSS = (\\mathbf{y} - \\mathbf{Xw})^{T}(\\mathbf{y} - \\mathbf{Xw})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PQErPaZqZBz"
      },
      "source": [
        "Note that the mean sum of squares (MSE) is perfectly equivalent to the RSS.\n",
        "\n",
        "\n",
        "For most machine learning algorithms we need an optimization algorithm such as gradient descent to find the set of weights that minimize the discrepancy between true and predicted values. However, for linear regression there is a convenient analytical solution to find the optimal weight vector $\\mathbf{w}$ that minimizes the RSS. This solution is obtained by solving the so-called normal equations, leading to the following expression:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0e0zykJqZBz"
      },
      "source": [
        "<center>$\\mathbf{w_{OLS}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA1ILGreqZB0"
      },
      "source": [
        "This solution is called the ordinary least squares or OLS solution. With this equation in our toolbox, we can fit a linear regression model to a toy dataset. Let's first simulate some datapoints from a linear ground truth, but with some Gaussian noise $\\epsilon$ added to the observations. We will use only one feature $x$ so that we can visualize the regression line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBIDPn2CqZB0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "2cc70812-0dc5-41c8-9ae2-c72850c41f94"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-white')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import pc3 as pc3 # some custom functions for this PC lab\n",
        "\n",
        "n=50 # number of data points\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=6) # you can change the standard deviation of the noise\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-0fac6056a117>:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-white')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JjMNziEqZB2"
      },
      "source": [
        "Now, let's use linear regression to model $y$ as a function of $x$. We can use the analytic result from the normal equations to find the optimal weight vector $\\mathbf{w_{OLS}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pR5ecYhqZB3"
      },
      "source": [
        "### EXERCISE: Implement the solution from the normal equations to find $w_{OLS}$. You can have a look at [https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html](NumPy) reference manual on how to do matrix manipulations with numpy. For example, use the np.matmul() to do matrix multiplications and np.linalg.inv to calculate the inverse of a matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp-qRbgdqZB3"
      },
      "source": [
        "# Put the features in a matrix, with a column of ones for the intercept\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find the weight vector that minimizes the MSE between observations and predictions. With this weight matrix, we can estimate $y$ for the $x$'s in our dataset (or for any future value of $x$):"
      ],
      "metadata": {
        "id": "yiIBNXW4npTk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFTcUwruqZB4"
      },
      "source": [
        "### EXERCISE: find y_hat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGwc3cqCqZB5"
      },
      "source": [
        "y_hat ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhTJpIbQqZB5"
      },
      "source": [
        "Let's visualize the regression line. **To convert the cells below to code, click on the cell, press escape and then y. ** They will return an error if you made a mistake in calculating w or y_hat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfREh2yPqZB5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "1063c680-de89-4bda-a914-059a0688500a"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');\n",
        "ax.plot(x, y_hat, color='orange');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate the performance of our model by computing the MSE:"
      ],
      "metadata": {
        "id": "H6RGpAHWnzLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute MSE\n",
        "def compute_MSE(y_true, y_predicted):\n",
        "    \"\"\"Obtain MSE between true y's and predicted y's\"\"\"\n",
        "    return\n",
        "\n",
        "MSE = compute_MSE(y, y_hat)\n",
        "print('Mean squared error: {}'.format(MSE))\n",
        "\n",
        "#Note that the vectorized notation would give the same result: MSE = np.dot(np.transpose(y_hat-y),(y_hat-y))/n"
      ],
      "metadata": {
        "id": "e4iU6EjGn2Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed23edf-f7f0-4087-e2d8-a3c5882a6a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 28.31699171537876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obviously, this just reflects the performance of our model on the training data and we could get an arbitrarily low MSE by making our model more complex. In reality, we are more interested in the performance of our model on new, unseen data that was not used to train the model. We will illustrate this on a practical example."
      ],
      "metadata": {
        "id": "4Ks8U773n90q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbRqtRWwqZB6"
      },
      "source": [
        "### EXERCISE: Put the code for calculating $\\mathbf{w_{OLS}}$ and $\\hat{y}$ in functions so we can use them further on.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Ak_XKeqZB6"
      },
      "source": [
        "def fit(X,y):\n",
        "    \"\"\"Function to obtain the least-squares weights of a linear regression model\n",
        "    Inputs\n",
        "    ------\n",
        "    X: numpy array. Contains the features, with the first row containing all ones for the intercept.\n",
        "    y: numpy array. Contains the outcome\"\"\"\n",
        "\n",
        "    # copy your code from above here\n",
        "    w =\n",
        "\n",
        "    return(w)\n",
        "\n",
        "def predict(X, w):\n",
        "    \"\"\"Make predictions for a set of features X\"\"\"\n",
        "    y_hat =\n",
        "    return(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9AHHlp-qZB7"
      },
      "source": [
        "## Application: predicting house prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBmNcQxJqZB7"
      },
      "source": [
        "We will use a [housing dataset](https://www.kaggle.com/harlfoxem/housesalesprediction) hosted on Kaggle for a practical illustration, slightly modified for the purpose of this PC lab. You can find the data in the file pc3_housingdata_modified.csv. The dataset contains the price of 21613 houses in US dollars, together with the following features:\n",
        "1. **categorical features** (discrete categories): waterfront yes/no, color (yellow, blue, white or 'other')\n",
        "2. **ordinal features** (take on discrete values, but there is a natural ordering, unlike categorical features): number of bedrooms, bathrooms, floors, yr_built\n",
        "3. **continuous features**: surface areas: sqft_living, sqft_lot, sqft_above, sqft_basement, and latitude, longitude\n",
        "\n",
        "We would like to build a model that can predict the price of a house based on these features. First, let's read in the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIPobbwhqZB7"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/BioML-UGent/MLLS/main/03_linear_regression/pc3_housingdata_modified.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtUWYyNFqZB7"
      },
      "source": [
        "Let's visualize some features to get an idea of what this data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdPEC6fqZB7"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(data.loc[:,['price', 'sqft_living', 'sqft_basement', 'lat', 'long']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sFT5T3cqZB8"
      },
      "source": [
        "sns.pairplot(data.loc[:,['price','color', 'waterfront', 'bathrooms', 'bedrooms']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-5C6BiuqZB8"
      },
      "source": [
        "There are different types of features here. How can we use the color attribute in a linear regression model? In general, dummy variables are introduced to encode categorical features. In machine learning, this is more often called **one-hot encoding**. It turns out that both [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) have functions that can do this trick. Let's use pandas, since it can handle text features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGC-lxuvqZB8"
      },
      "source": [
        "dummies = pd.get_dummies(data.color)\n",
        "dummies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e1BgNzLqZB9"
      },
      "source": [
        "Let's add these encoded features to the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5aGwuTqZB9"
      },
      "source": [
        "data_onehot = pd.concat([data, dummies], axis=1)\n",
        "data_onehot = data_onehot.drop(['color'], axis=1) # remove the original color column\n",
        "data_onehot.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDkhvS4GqZB9"
      },
      "source": [
        "We can use these dummy variables in a linear regression model. First, it's good to extract the data from the pandas dataframe into numpy arrays, since most machine learning APIs are compatible with numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3r6Yq8dqZB9"
      },
      "source": [
        "# Put data in numpy arrays\n",
        "y = data_onehot.price.values\n",
        "X = data_onehot.drop('price', axis=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_2zvs4uqZB9"
      },
      "source": [
        "Finally, we would like to evaluate the performance of our data on new, unseen data, that was not used to train the model. Therefore, we split up our dataset into a training and a test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_pDKvBhqZB9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7) # Use 70% of data for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpXx-tmqZB-"
      },
      "source": [
        "###EXERCISE: Use the scikit-learn Linear Regression implementation to fit a model on the housing dataset. Use the training data to fit the model. Compare the MSE of the model on the training and on the test data. Finally, compute the coefficient of determination ($R^2$) on the test data. The relevant documentation page contains all the information that you need. Convenient methods that are defined in almost all scikit-learn models are .fit(), .predict() and .score().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZZMQMPFqZB-"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# call an instance of the class LinearRegression\n",
        "linreg =\n",
        "\n",
        "# fit the model on the training data\n",
        "\n",
        "\n",
        "# predict training data\n",
        "y_hat_train =\n",
        "\n",
        "# Compute training set MSE\n",
        "train_MSE =\n",
        "\n",
        "# predict test data\n",
        "y_hat_test =\n",
        "\n",
        "# Test set MSE\n",
        "test_MSE =\n",
        "\n",
        "R2_train = linreg.score(X_train, y_train)\n",
        "R2_test = linreg.score(X_test, y_test)\n",
        "\n",
        "print('Training set MSE: {}'.format(train_MSE))\n",
        "print('Test set MSE: {}'.format(test_MSE))\n",
        "print('Training set R2: {}'.format(R2_train))\n",
        "print('Test set R2: {}'.format(R2_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEQRfNbqZB-"
      },
      "source": [
        "\n",
        "## Adding model flexibility: polynomial feature expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHxg7FpsqZB-"
      },
      "source": [
        "We can model non-linear relations by performing some non-linear transformation $\\phi(\\mathbf{x})$ on the original features $\\mathbf{x}$. This is known as a **basis function expansion**. An example of such a transformation are polynomial basis functions, where we consider higher-order powers of the original features:\n",
        "\n",
        "$\\phi(x) = [1, x, x^2, x^3,...,x^d]$\n",
        "\n",
        "It is important to note here that, although we use non-linear transformations, the model linear regression model $y = f(\\phi(x)$ will still be linear in the parameters:\n",
        "\n",
        "$\\hat{y} = w_{10}x_{0} + w_{11}x_{1} + w_{12}x_{1}^2 ... + w_{md}x_{m}^d$\n",
        "\n",
        "This means that the solution will still be a line, be it in a transformed and typically higher-dimensional space instead of in the original feature space. This also means that we obtain the least-squares solutions just as we did earlier on.\n",
        "\n",
        "With different feature expansions, we can strongly improve the performance of linear regression by taking into account interaction effects, quadratic or cubic effects... However, the risk of overfitting also increases! Let's go back to the simulation example. In stead of doing a simple linear regression, we will perform a polynomial feature expansion of the single feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp_hRfbtqZB-"
      },
      "source": [
        "import pc3 as pc3 # some custom functions for this PC lab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n=100 # number of data points 5000\n",
        "eps=10 # amount of noise 20\n",
        "\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=eps) # you can change the standard deviation of the noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGF8MhhwqZB-"
      },
      "source": [
        "# Put the features in a matrix, with a column of ones for the intercept. Add polynomial expansions.\n",
        "\n",
        "# add x up to the 10th power\n",
        "n_polynomials=20\n",
        "\n",
        "X = np.ones((n,n_polynomials))\n",
        "X[:,1] = x\n",
        "\n",
        "for i in np.arange(2, n_polynomials):\n",
        "    X[:,i] = x**i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq13UySzqZB_"
      },
      "source": [
        "### EXERCISE: Create the polynomial expansions of the original dataset using the [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) option from Scikit-learn Use the fit and predict functions you used in the previous exercise to obtain the predictions $\\hat{y}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly = PolynomialFeatures(...)\n",
        "poly.fit(...)\n",
        "X = poly.transform(...)\n",
        "\n",
        "LinReg = # call an instance of the class LinearRegression\n",
        "\n",
        "# fit the model on the training data\n",
        "\n",
        "y_hat = # predict training data"
      ],
      "metadata": {
        "id": "52HDud5opO9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_f3EmLSqZB_"
      },
      "source": [
        "Again, let's visualize the regression line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8A9BmtBqZCA"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');\n",
        "ax.scatter(x, y_hat , color='orange');\n",
        "ax.legend(['Observation', 'Predicted']);\n",
        "ax.set_title('MSE: {}'.format(mean_squared_error(y, y_hat))).set_fontsize(20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7p3gTtrqZCA"
      },
      "source": [
        "Obviously, expanding the polynomial up to the fifth power leads to a much better fit of our model to the data. **But we simulated the data from an underlying linear relation between x and y!** This is a clear example of overfitting. By performing the polynomial expansion, our model becomes too flexible and fits to patterns in the data that, in reality, are just noise."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISE: Play with the parameters in the code above. Change the number of simulated data points from 50 to 100, 200, 500. What happens with the overfitting? Change the amount of noise. Increase the size of the polynomial up to degree 12. Compare the MSE's. Try to understand the influence of each of these factors on the behavior of the model."
      ],
      "metadata": {
        "id": "vPBrA3GVpWv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE: Play with the parameters in the code above. Change the number of simulated data points from 50 to 100, 200, 500. What happens with the overfitting? Change the amount of noise.  Increase the size of the polynomial up to degree 12. Compare the MSE's. Try to understand the influence of each of these factors on the behavior of the model.</b>\n",
        "</div>"
      ],
      "metadata": {
        "id": "fRKEnghXy2mw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W245ttFIqZCA"
      },
      "source": [
        "### By evaluating the performance of our model on a test set, we can check if we are overfitting or not. The following code simulates n data points from a linear model with noise. 50% of them are used to fit a linear regression model, with an increasing number of polynomial features. The other 50% data points are held out as a test set. For each model, the MSE on both the training and test data is evaluated. The plot shows the training and test MSE for increasing degrees of the polynomial expansion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a2dx-r2qZCA"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "n=100\n",
        "eps= 20\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=eps) # you can change the standard deviation of the noise\n",
        "\n",
        "x_test, x_train = x[:n//4].reshape(-1, 1), x[n//4:].reshape(-1, 1)\n",
        "\n",
        "y_test, y_train = y[:n//4].reshape(-1, 1), y[n//4:].reshape(-1, 1)\n",
        "\n",
        "LinReg = LinearRegression()\n",
        "\n",
        "MSE_train = []\n",
        "MSE_test = []\n",
        "\n",
        "for i in np.arange(1, 15):\n",
        "    poly = PolynomialFeatures(degree=i)\n",
        "    poly.fit(x_train)\n",
        "    X_train = poly.transform(x_train)\n",
        "    X_test = poly.transform(x_test)\n",
        "\n",
        "    LinReg.fit(X_train,y_train.reshape(-1,1))\n",
        "    pred_train = LinReg.predict(X_train)\n",
        "    pred_test = LinReg.predict(X_test)\n",
        "    MSE_train.append(mean_squared_error(y_train, pred_train))\n",
        "    MSE_test.append(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "pd.Series(MSE_train).plot(ax=ax, marker='o');\n",
        "pd.Series(MSE_test).plot(ax=ax, marker='o', color='orange');\n",
        "ax.legend(['Train MSE', 'Test MSE']);\n",
        "ax.set_xlabel('size of polynomial');\n",
        "ax.set_ylabel('MSE');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE: Describe what you see. What happens with the training MSE as you increase the number of features? What happens with the test MSE? How can you explain this?</b>\n",
        "</div>"
      ],
      "metadata": {
        "id": "p-4rhvqjypOo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWltJxMvqZCB"
      },
      "source": [
        "### OPTIONAL EXERCISE: Try to improve the performance of the linear model for the housing dataset by expanding the feature space. Scikit-learn has a method to expand a numpy array with polynomial features. Keep an eye on possible overfitting! I was able to increase the R on the test data to 0.73..."
      ]
    }
  ]
}