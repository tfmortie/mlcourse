{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqd-E7gdqZBs"
      },
      "source": [
        "# PC Lab 3: Linear Regression\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8xRJtLhQq6d"
      },
      "outputs": [],
      "source": [
        "!wget -c https://raw.githubusercontent.com/tfmortie/mlmust/main/03_linear_regression/pc3.py -O pc3.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqz2SRIbqZBx"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ANrT8zqZBy"
      },
      "source": [
        "The goal of linear regression is to model the relationship between one or more features *x* and a **continuous** variable *y*. When there is only one feature $x_1$ (univariate linear regression), the equation of the regression line is:\n",
        "\n",
        "$$\\hat{y} = w_{0} + w_{1}x_{1},$$\n",
        "\n",
        "where $w_{0}$ is the intercept or bias. In case of multiple features, we talk about multiple linear regression, and $y$ is modelled as a linear combination of the features, weighted by some set of weights $\\mathbf{w}$:\n",
        "\n",
        "$$\\hat{y} = w_{0}x_{0} + w_{1}x_{1} + ... + w_{p}x_{p} = \\sum\\limits_{i=0}^{p}w_{i}x_{i},$$\n",
        "\n",
        "In this notation, we introduced an additional feature $x_{0}$ which always equals 1. This notation allows to formulate linear regression as a matrix multiplication:\n",
        "\n",
        "$$\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{w},$$\n",
        "\n",
        "where $\\mathbf{\\hat{y}}$ (a vector of dimension $n \\times 1$) contains the predicted target variable for the $n$ instances, $\\mathbf{w}$ is a $p \\times 1$ vector containing the weights and $\\mathbf{X}$ is a $n \\times (p+1)$ matrix with the features. Note that the first column of $\\mathbf{X}$ is a column of ones, because it represents the feature $x_{0}$. We will stick to this matrix notation for the rest of this lab, as this notation is common practice in machine learning. Also, this notation makes it much easier to translate an algorithm into Python code.\n",
        "\n",
        "Fitting this model to a dataset comes down to finding the weight vector $\\mathbf{w}$ that minimizes the discrepancy between the true target values $\\mathbf{y}$ and the predictions $\\hat{\\mathbf{y}}$. As is often the case in regression problems, this discrepancy between true values and predicted values is expressed by the **residual sum of squares (RSS)**:\n",
        "\n",
        "$$RSS = \\sum\\limits_{i=1}^{n}(\\hat{y}_{i} - y_{i})^2,$$\n",
        "\n",
        "or, equivalently:\n",
        "\n",
        "$$RSS = (\\mathbf{y} - \\mathbf{Xw})^{T}(\\mathbf{y} - \\mathbf{Xw}).$$\n",
        "\n",
        "Note that the _mean squared error_ (MSE), as seen in the previous practical, is similar to RSS.\n",
        "\n",
        "For most machine learning algorithms we need an optimization algorithm such as gradient descent to find the set of weights that minimize the discrepancy between true and predicted values. However, for linear regression there is a convenient analytical solution to find the optimal weight vector $\\mathbf{w}$ that minimizes the RSS. This solution is obtained by solving the so-called normal equations, leading to the following expression:\n",
        "\n",
        "$$\\mathbf{w_{OLS}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}.$$\n",
        "\n",
        "This solution is called the ordinary least squares or OLS solution. With this equation in our toolbox, we can fit a linear regression model to a toy dataset. Let's illustrate this by means of a simple simulated dataset that consists of one feature $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "mBIDPn2CqZB0",
        "outputId": "2cc70812-0dc5-41c8-9ae2-c72850c41f94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-0fac6056a117>:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-white')\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGsCAYAAADKVj2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAu/0lEQVR4nO3dfXSU9Z338c8kCqmQTBx5mDS9V6gs8R4mpQUNGuyNSsFsaQhwgAaaQ1koYHxY5UBFVm02ypbjYdUb2z2UcgrraU4xNxx2Q1w3VaCytA2HBarNBKSahm5Nh1JIJhCX8JCZ+4+ciQzJhMxkZq7rmnm/zvGPXHNBv9gt89nfw/drCwQCAQEAAFhYmtEFAAAADBaBBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWN4tRheQCPfcc4+uXLmikSNHGl0KAAAYoL/85S8aMmSIjh49etN3UyLQXL58WV1dXUaXAQAAInDt2jUNdKBBSgSaUaNGSZL2799vcCUAAGCgpk+fPuB3OUMDAAAsj0ADAAAsj0ADAAAszzKB5vvf/77y8vJ6fq6vr9f8+fM1adIkzZo1S3v37jWwOgAAYCRLHAo+efKkampqen4+e/asHnvsMT333HMqLi7WsWPHVF5errFjxyo/P9/ASgEAgBFMv0Lj9/tVUVGhpUuX9jyrra3VmDFjNH/+fA0dOlSFhYV6+OGHtWvXLuMKBQAAhjF9oHnzzTc1dOhQFRcX9zxrbGyUy+UKec/lcsnj8SS6PAAAYAKm3nI6d+6cfvCDH+inP/1pyHOfz6fRo0eHPMvOzlZbW1siywMAACZh6hWajRs3at68eRo3bpzRpQAAABMz7QpNfX29fvOb3+itt97q9dntt98un88X8qytrU0OhyNB1QEAADMxbaDZu3evzp8/r4ceekiSemY5TJkyRcuWLesVdDwejyZOnJjwOgEASGVd/oCONLfq7MVOjcrMUMFYh9LTbAmvw7SB5tlnn9VTTz3V8/OZM2f0zW9+UzU1NfL7/dq6dat27dql2bNn6/Dhwzp48KCqq6sNrBgAgNRS5/GqsvaEvO2dPc9y7BmqKHapyJ2T0FpMG2jsdrvsdnvPz9euXZMkOZ1OSdLWrVu1YcMGVVZWKjc3V5s2bdLdd99tSK0AAKSaOo9X5VXHdeMs7DPtnSqvOq4tZZMSGmpMG2hu9IUvfEGnTp3q+fnee+8NabYHAAASo8sfUGXtiV5hRpICkmySKmtPaIbLmbDtJ1PfcgIAAOZzpLk1ZJvpRgFJ3vZOHWluTVhNBBoAABCRsxfDh5lo3osFAg0AAIjIqMyMmL4XCwQaAAAQkYKxDuXYMxTudIxN3bedCsYmrj8cgQYAAEQkPc2miuLumYo3hprgzxXFroT2oyHQAACAiBW5c7SlbJKc9tBtJac9I+FXtiULXdsGAADmUuTO0QyXk07BAADA2tLTbLr/rjuMLoNAAwCAFZhlZpJZEWgAADA5M81MMisOBQMAYGLBmUk3duYNzkyq83gNqsxcCDQAAJjUzWYmSd0zk7r8fb2RWgg0AACYlBlnJpkVgQYAAJMy48wksyLQAABgUmacmWRWBBoAAEzKjDOTzIpAAwCASZlxZpJZEWgAADAxs81MMisa6wEAYHJmmplkVgQaAAAswCwzk8yKLScAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5dAoGACCBuvwBRhjEAYEGAIAEqfN4VVl7Qt72zp5nOfYMVRS7GDI5SGw5AQCQAHUer8qrjoeEGUk6096p8qrjqvN4DaosORBoAACIsy5/QJW1JxTo47Pgs8raE+ry9/UGBoJAAwBAnB1pbu21MnO9gCRve6eONLcmrqgkY+pA8+GHH+rb3/62Jk+erMLCQj399NP6y1/+Ikmqr6/X/PnzNWnSJM2aNUt79+41uFoAAPp29mL4MBPNe+jNtIHmypUrWrZsmQoKClRfX6+33npL58+f1z/8wz/o7Nmzeuyxx1RaWqr6+no999xzeuGFF9TQ0GB02QAA9DIqMyOm76E30waaS5cuafXq1Vq1apWGDBkih8OhGTNm6KOPPlJtba3GjBmj+fPna+jQoSosLNTDDz+sXbt2GV02AAC9FIx1KMeeoXCXs23qvu1UMNaRyLKSimkDjd1u14IFC3TLLd03y3//+9/rX//1X/U3f/M3amxslMvlCnnf5XLJ4/EYUSoAAP1KT7Oporj7e+vGUBP8uaLYRT+aQTBtoAlqaWmR2+3W17/+deXn5+vv/u7v5PP5lJWVFfJedna22traDKoSAID+FblztKVskpz20G0lpz1DW8om0YdmkEzfWC83N1cNDQ36wx/+oO9973t65plnjC4JAICoFLlzNMPlpFNwHJg+0EiSzWbTmDFjtHr1apWWlmratGny+Xwh77S1tcnhYO8RAGBu6Wk23X/XHUaXkXRMu+VUX1+vRx55RH6/v+dZWlp3uV/60pd6nZfxeDyaOHFiQmsEAADmYNpA43a71dHRoU2bNunSpUtqbW3VD37wA91zzz1atGiRWlpatGvXLl2+fFkHDx7UwYMHtXDhQqPLBgAABjBtoMnMzNT27dvl8Xh03333adasWcrMzNSrr76qO+64Q1u3blVVVZUmT56s73//+9q0aZPuvvtuo8sGAAAGMPUZmry8PP30pz/t87N7771XNTU1Ca4IAACYkakDDQAA/enyB7gxBEkEGgCARdV5vKqsPREy9DHHnqGKYhc9XVKQac/QAAAQTp3Hq/Kq470mWJ9p71R51XHVebwGVQajEGgAAJbS5Q+osvaEAn18FnxWWXtCXf6+3kCyItAAACzlSHNrr5WZ6wUkeds7daS5NXFFwXAEGgCApZy9GD7MRPMekgOBBgBgKaMyM27+UgTvITkQaAAAllIw1qEce4bCXc62qfu2U8FY5vulEgINAMBS0tNsqih2SVKvUBP8uaLYRT+aFEOgAQBYTpE7R1vKJslpD91WctoztKVsEn1oUhCN9QAAllTkztEMl5NOwZBEoAEAWFh6mk3333WH0WXABNhyAgAAlkegAQAAlkegAQAAlkegAQAAlkegAQAAlkegAQAAlse1bQAA+tHlD9DrxgIINAAAhFHn8aqy9oS87Z9N7s6xZ6ii2EU3YpNhywkAgD7UebwqrzoeEmYk6Ux7p8qrjqvO4zWoMvSFQAMAwA26/AFV1p5QoI/Pgs8qa0+oy9/XGzACW04AYCJWOq9hpVojdaS5tdfKzPUCkrztnTrS3MroBZMg0ACASVjpvIaVao3G2Yvhw0w07yH+2HICABOw0nkNK9UarVGZGTF9D/FHoAEAg1npvIaVah2MgrEO5dgzFG4DzabuFamCsY5EloV+EGgAwGCRnNcwmpVqHYz0NJsqil2S1CvUBH+uKHYlzZmhZECgAQCDWem8hpVqHawid462lE2S0x66reS0Z2hL2aSkOCuUTDgUDAAGs9J5DSvVGgtF7hzNcDmT9jZXMiHQAIDBguc1zrR39nk2xabuVQEznNcwc63xukaenmbjarYFEGgAwGDB8xrlVcdlk0KCgtnOa5i11mS/Ro6b4wwNAJiAlc5rFLlz9M+LJ+n2YUNCnhtVaypcI8fNsUIDACZhlfMadR6vXvr3E2r99ErPM8ewW/XCrP+d8DBzs2vkNnVfI5/hcpru3yNii0ADACZi9vMawdWQGwNE26dX9fjPfqMtabaEhhpGFCDI1FtOLS0tevzxxzVlyhQVFhbq2Wef1YULFyRJJ0+eVFlZmSZPnqyZM2dq+/btBlcLAMnNjE319p04M6D3kuEaOfpn6kDz6KOPKisrSwcOHNCePXv00Ucf6eWXX1ZnZ6dWrVql++67T4cOHdJrr72mrVu36p133jG6ZABIWmZrqlfn8eonvzo9oHeT5Ro5wjNtoLlw4YLcbrfWrFmjYcOGyel0au7cuTp69Kjee+89Xb16VeXl5brttts0YcIELViwQNXV1UaXDQBJ68wF8zTVC64W3QwjClKHaQNNVlaWNm7cqBEjRvQ883q9GjVqlBobG5WXl6f09PSez1wulzwejxGlAkDSq/N49dJbjQN6NxGrITdbLQoKyDxX3hFfpg00N2poaFBVVZXKy8vl8/mUlZUV8nl2drZ8Pp/8fr9BFQJAcgoeBG799Gq/7yVyNWSgq0DLpo4x1ZV3xI8lAs2xY8e0fPlyrVmzRoWFhWHfs9lI4AAQS/0dBL5eopvqDXQVaIbLGedKYBamDzQHDhzQypUr9fd///dasmSJJMnhcKitrS3kPZ/Pp+zsbKWlmf6PBACWMdCtHcewIQltqhccwRAuOnF2JvWY+tv/+PHjWrdunTZv3qw5c+b0PHe73Tp16pSuXbvW86yhoUETJ040oEoASF4D3dp5PsFN9YIjGCT1CjVmGxeBxDBtoLl27Zqef/55rV27Vg888EDIZ9OmTdPw4cO1ZcsWXbp0SR988IF2796tRYsWGVQtACSngW7tOO2fi3MlvVlpXATizxYIBBLXASkCR48e1be+9S0NGTKk12d1dXX69NNPVVFRIY/HoxEjRmjFihVavHhxn7/X9OnTJUn79++Pa80AkGy6/AE98PKBm07X/uW6hw1bDYnXlG0YL5Lvb9OOPrjnnnt06tSpft/ZuXNngqoBgNRk1una1zP7uAgkhmm3nAAA5jCQrZ0uf0D1TedV836L6pvOJ3T8ASCZeIUGAGAe/U0Cr/N4VVl7IuQ2VI49QxXFLs6xIGEINACAAelrayfc9O0z7Z0qrzrO4VwkDFtOAIComHH6NlIXgQYAEBWzTd9GamPLCQAQlYE23UvE9G2r4ap57BFoAABRGWjTvURM37YSDlHHB1tOAICoME8pcsFD1Ddu1QUPUdd5vAZVZn0EGgBAVJinFBkOUccXgQYAEDXmKQ0ch6jjizM0AIBB6a/pHj7DIer4ItAAAAaNeUo3xyHq+GLLCQCABOAQdXwRaAAASAAOUccXgQYAgAThEHX8cIYGAIAE4hB1fBBoAABIMA5Rxx5bTgAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPIINAAAwPKY5QQAiKsuf4BBjIg7Ag0AIG7qPF5V1p6Qt72z51mOPUMVxS4VuXMMrAzJhi0nAEBc1Hm8Kq86HhJmJOlMe6fKq46rzuM1qDIkIwINACDmuvwBVdaeUKCPz4LPKmtPqMvf1xtA5Ag0AICYO9Lc2mtl5noBSd72Th1pbk1cUUhqBBoAQMydvRg+zETzHnAzpg80hw4dUmFhoVavXt3rs7ffflvFxcX6yle+onnz5umXv/ylARUCAG40KjMjpu8BN2PqQLNt2zZt2LBBd955Z6/PTp48qXXr1mnt2rU6fPiwli5dqieeeEJnzpwxoFIAwPUKxjqUY89QuMvZNnXfdioY60hkWUhipg40Q4cO1e7du/sMNLt27dK0adM0bdo0DR06VLNnz9b48eO1d+9eAyoFAFwvPc2mimKXJPUKNcGfK4pd9KNBzJg60CxZskSZmZl9ftbY2CiXyxXyzOVyqaGhIRGlAQBuosidoy1lk+S0h24rOe0Z2lI2iT40iCnLNtbz+Xyy2+0hz+x2uz7++GODKgIA3KjInaMZLiedghF3lg00khQI0L8AAMwuPc2m+++6w+gykORMveXUn9tvv10+ny/kmc/nk8PBATMAAFKNZQON2+2Wx+MJedbQ0KCJEycaVBEAADCKZQPNwoUL9etf/1rvvfeeLl++rN27d+v06dOaPXu20aUBSDFd/oDqm86r5v0W1Tedp50/YABTn6HJz8+XJF27dk2StG/fPkndKzHjx4/XP/3TP2njxo1qaWnRuHHjtHXrVo0cOdKwegGkHqZJA+ZgC6TAydrp06dLkvbv329wJQCSSXCa9I1/iQbv73A1GRicSL6/LbvlBABGYpo0YC4EGgCIAtOkAXMh0ABAFJgmDZiLqQ8FA4BZpdI06S5/gE6/MD0CDYCUFu2XdXCa9Jn2zj7P0djUPbPI6tOkucUFqyDQAEhZkX5Z3xh+Xpjl0uM/Oy6bFBJqkmWadLhbXGfaO1VedZxbXDAVAg2AlBTpl3W48LPy/4zV3g+8Ic+dSbCCcbNbXDZ13+Ka4XJaOrQheRBoAKScSL+s+ws/P/7PZv3z4q/o9mFDk+qMSSS3uBg8CTMg0ABIOZF8WReMddw0/Lz07yf1y3UPWz7EXI9bXLAarm0DSDmRfFmnar+ZVLrFheRAoAGQciL5sk7VlYrgLa5wa042dZ8hsvotLiQPAg2AlBPJl3WqrlSkp9lUUeySpF7/npLlFheSC4EGQMqJ5Ms6lisVXf6A6pvOq+b9FtU3nTf9nKcid462lE2S0x4a1pz2DK5sw3Q4FAwgJQW/rG+8in3jletg+CmvGly/Gas2qCty52iGy0mnYJieLRAImPv/RYiBSMaPA0gt1zfLGzFsqGSTznVc7vXFPZhAEu7adzASsNoB9C2S729WaAAklUhHGaSn2XT/XXeozuPV2t0fhA0s0a5UxLtBHXOWgG4EGgBJI9pVlIF2DQ6Gn0jEs0GdVbexgHjgUDCAuEj0AdhgKLkxPARDSZ3HG7bO/lZQpO4VlGjrj9e172j/vECyYoUGQMwleuVgMNs68W7xH49r38xZAnpjhQZATBmxcjCYbr7xbpwXjwZ1qdq9GOgPgQZAzMR7+yacwYSSeDfOi0eDulTtXgz0h0ADIGaMWjkYTChJRIv/WDeoS9XuxUB/OEMDIGaMWjkIhpIz7Z19rg7Z1B0e+golsWqcdzOxbFA3mD8vkKxYoQEQM0atHAx2WydRLf6D175Lvpyr+++6I+qQxJwloDdWaADEjJErBwMdZdDfr7dSi//B/nmBZEOgARAzidq+CWewoSSaxnlGsloIA+KJQAMgpoxeObBaKBmsVPvzAuEQaADEHCsHABKNQAMgLlg5AJBI3HICAACWxwoNAMRQlz/AVhtggIgDzaJFi1RSUqKioiJlZ2fHoSQAsKZED+UE8JmIt5weeOABvfnmm/rqV7+qRx99VG+//bYuX74cj9oAICJd/oDqm86r5v0W1Tedj/nMqP4YMZQTwGdsgUAgqv/F//GPf9S7776rd999Vx9//LG+9rWvqbi4WIWFhbGuMayWlhZVVlbqgw8+0G233aavf/3rWrNmjdLSQnPa9OnTJUn79+9PWG0AEsvI1ZEuf0APvHwg7Bwrm6TRWUP1ysIv61zHZbaigAGK5Ps76kATdOXKFe3evVuvvvqqOjo6lJubqxUrVqi0tHQwv+2AzJs3TxMmTNAzzzyj8+fPa9WqVSotLdXf/u3fhrxHoAESw6jzI8HVkRv/Mgv+J8dyfEFf6pvOa9G2wxH9GraigJuL5Ps76kPBhw8fVm1trd555x0NGzZMpaWlmjNnjs6dO6eNGzeqqalJzz33XLS//U01NDToww8/1I4dO5SZmanMzEwtXbpUb7zxRq9AAyD+Yr1CMtBw1OUPqLL2RJ+jFgLqDjWVtSc0w+WMW7iKZthmcCsq3mELSBURB5qXX35Zb7/9ti5evKivfe1r2rx5s+6//37ZbN1/UYwbN07btm3TrFmz4hpoGhsblZubK7vd3vNswoQJam5uVkdHh4YPHx63/2zA6mK9khJuhSTaL+1IwtGR5tawWz1Sd6jxtnfqSHNr3PriRDNsM1FhC0gVEQeakydPavXq1Zo5c6Zuu+22Pt8ZNWqUVqxYMeji+uPz+ZSVlRXyLBhu2traCDRAGPFYSYnlCkmk4WigqyPRrKIM1M2GcoaTiLAFpIqIbzn9y7/8i+bMmRM2zAStXLky6qIGapDHf4CUE4+bOJGskNzMzcKR1B2Orr+9NNDVkWhWUSJReu//iijMXC+eYQtIFZbtFOxwOOTz+UKe+Xw+2Ww2ORwOY4oCTCyasDAQsVwhiSYcBVdHwq392NS9AlUwNj5/L9R5vHrg5QN6bd9HUf8e8Q5bQCqwbKBxu93yer1qbf3sL7aGhgaNGzdOw4YNM7AywJxiuZJyvViukEQTjtLTbKoodoV9NyBp9sSciM+oDKSnTbgVr6Cnpv+1nFnGhS0glVg20LhcLuXn5+uVV15RR0eHmpqatGPHDi1atMjo0gBTGmhY+NXHf4moMV0sV0iiDUdF7hyt/D9jw77/4/9sjmg7LbjqsmjbYT315vtatO2wHnj5QMjv0d+Kl9T95/5/R/+o733D1fPzjZ9LUkWxiwPBQAxYNtBI0uuvv66zZ89q6tSpWrJkiebMmaPFixcbXRZgSgMNCz/8RVPYL/G+XL9CMtgv7WjDUZc/oL0f9F/nQLfTBnrOaKArXrcPG6ItZZPktIf++3faM7iyDcSQpYdTOp1Obdu2zegyAEuI5ibOQK9dF7lztKVsUq/bU84Ib08Fw1F51XHZpJA6+wtHsbq6HcmNrUi2x0q+nKsZLidDK4E4snSgATBw/YWFcCK5dl3kzonJl3Y04ShWB5MjCUaRbo+lp9m4mg3EEYEGSCHhwkJ/IumVEqsv7UjDUawOJkcSjL7xpc/3u+JlU3cI48AvkBgEGiDF3BgWPvpzh374i49v+usS3SslknA0kO20NJvU9umVfn+fSIJRtNtjAOLD0oeCAUQnGBZKvpyrqeNGDOjXnD73aZyrit7Nrm5Lkj8gPf6z/psHRnooObjixYFfwHis0AAprmCsQ86sDJ250P8KzM4j/60nHv5r0644FLlz9M+Lv6Indv5G/V1m6u88UDSrLrE6OwRgcFihAVJceppNiwr+6qbvnblwOeKme4l2+7Ch/YaZgTQPjGbV5foVr/vvuqPfMDOQhn0AIscKDTAIsZ5abZQxI/qfzRZk9plDsbrtFK9Vl1gPBgXwGQINEKVk+nIyy4DHwYrlnyPW16wjnSIOIDJsOQFRiMfUaiMZPeAxVsz654jXYFAAnyHQABFKxi+nWI4vMJJZ/xzxGgwK4DMEGiBCyfrllCxXkM3454jV2R4A4XGGBohQMn85JcsVZLP9OZLljBJgZgQaIELJ/uWULDOHzPTnuFknY8YkAIPHlhMQIbMePIV5mfVsD5BMCDRAhPhyQjTMeLYHSCZsOQFRCDe12mnRPjRIDLOd7QGSCYEGiBJfToiGmc72AMmEQAMMAl9OAGAOnKEBAACWR6ABAACWR6ABAACWR6ABAACWR6ABAACWxy0nwCK6/AGuiANAGAQawALqPN5eTfxyaOIHAD3YcgJMrs7jVXnV8ZAwI0ln2jtVXnVcdR6vQZUBgHkQaAAT6/IHVFl7os8JzcFnlbUn1OXv6w0ASB0EGsDEjjS39lqZuV5Akre9U0eaWxNXFACYEIEGMLGzF8OHmWjeA4BkRaABTGxUZkZM3wOAZEWgAUysYKxDOfYMhbucbVP3baeCsY5ElgUApkOgAUwsPc2mimKXJPUKNcGfK4pd9KMBkPIINIDJFblztKVskpz20G0lpz1DT39tvC5f86u+6bxhN526/AHVN51XzfsthtYBILXRWA+wgCJ3jma4nD2dgk+f+1Q7j/y3Xtv3u553jGi0R8M/AGZh6hWahoYGzZgxQwsXLuz1WX19vebPn69JkyZp1qxZ2rt3rwEVAomTnmbT/XfdoaG3pOn/7vtIZy5cDvk80Y32aPgHwExMG2j27t2rJ598UnfeeWevz86ePavHHntMpaWlqq+v13PPPacXXnhBDQ0NBlQKJI5ZGu2ZpQ4ACDJtoLl8+bKqq6s1ceLEXp/V1tZqzJgxmj9/voYOHarCwkI9/PDD2rVrlwGVAoljlkZ7ZqkDAIJMG2gWLFig0aNH9/lZY2OjXC5XyDOXyyWPx5OI0gDDmKXRnlnqAIAg0waa/vh8PmVlZYU8y87OVltbm0EVAYlhlkZ7ZqkDAIIMCzQ1NTXKy8vr8589e/YYVRZgamZptGeWOgAgyLBr2yUlJSopKYnq195+++3y+Xwhz9ra2uRw8Jcnkluw0V551XHZpJBDuYlstGeWOgAgyJJbTvn5+b3Oy3g8nj4PEAPJpr9Ge1vKJiWs/4tZ6gAAyaKN9YqLi/X6669r165dmj17tg4fPqyDBw+qurra6NKQAF3+QE+DuVGZ3dsaqbYScGOjPaP+PZilDgAwbaB55JFH9Kc//UldXV3y+/3Kz8+XJNXV1Sk3N1dbt27Vhg0bVFlZqdzcXG3atEl33323wVUj3uhM+5lgoz2jmaUOAKnNFggEkr7z1fTp0yVJ+/fvN7gSDEawM+2N/wcbXAtgmwMAkksk39+WPEOD1ENnWgBAfwg0sAQ60w4Mk68BpCrTnqEBrkdn2pvjfBGAVMYKDSyBzrT9Y/I1gFRHoIEl0Jk2PM4XAQCBBhYR7EwrqVeoSfXOtJwvAgACDSyEzrR943wRAHAoGBZDZ9reOF8EAAQaWBCdaUMFzxedae/s8xyNTd2rWKl4vghA6mDLCbA4zhcBAIEGSAqcLwKQ6thyguUwbbtvnC8CkMoINLAUuuH2j/NFAFIVW06wDLrhAgDCIdDAEuiGCwDoD4EGlkA3XABAfwg0sAS64QIA+kOggSXQDRcA0B8CDSyBadsAgP4QaGAJdMMFAPSHQAPLoBsuACAcGuvBUuiGCwDoC4EGlhNJN1zGJABAaiDQIGkxJgEAUgdnaJCUGJMAAKmFQIOkw5gEAEg9BBokHcYkAEDqIdAg6TAmAQBSD4eCERUz3x5iTAIApB4CDSJm9ttDwTEJZ9o7+zxHY1N3Mz7GJABA8mDLCRGxwu0hxiQAQOoh0GDArHR7iDEJAJBa2HLCgEVye2ignXzjiTEJAJA6CDQYMCveHopkTAIAwLpMu+XU1tamdevWaerUqZoyZYqeeOIJeb2fnc9oaWnRypUrNWXKFD300EPatGmT/H6/gRUnP24PAQDMyrSBZv369Tp37pxqa2v185//XFevXtX69et7Pn/yySc1evRo7du3Tzt27NC+ffv0xhtvGFhx8gveHgq3YWNT920nbg8BABLNlIEmEAho9OjRWrdunRwOh7Kzs1VaWqpjx44pEAiooaFBH374odauXavMzEyNGTNGS5cuVXV1tdGlJzVuDwEAzMqUgcZms6myslLjx4/veeb1ejVy5EjZbDY1NjYqNzdXdru95/MJEyaoublZHR0dRpScMrg9BAAwI0scCv7kk0+0efNmrV27VpLk8/mUlZUV8k4w3LS1tWn48OEJrzGVcHsIAGA2hgWampoaPfPMM31+tnHjRs2bN0+S1NTUpOXLl2vu3LlasGBBzzuBgPG9TlIZt4cAAGZiWKApKSlRSUlJv+/89re/1YoVK7Rs2TKtWrWq57nD4ZDP5wt51+fzyWazyeHgQKoRzDzbCQCQ/Ey75XT69GmtXLlS69at61mtCXK73fJ6vWptbe0JMA0NDRo3bpyGDRtmRLkpLRaznQhEAIDBMG2gefHFF7Vw4cJeYUaSXC6X8vPz9corr2j9+vX685//rB07dmjZsmUGVJragrOdbtwADM52GshBYbMPuwQAmJ8pbzl5vV796le/0vbt25Wfnx/yz3/9139Jkl5//XWdPXtWU6dO1ZIlSzRnzhwtXrzY4MpTSyxmO1lh2CUAwPxMuUKTk5OjU6dO9fuO0+nUtm3bElQR+jLY2U43C0Q2dQeiGS4n208AgH6ZcoUG1jDY2U6RBCIAAPpDoEHUBjqz6dzFy6p5v0X1TedDtp+sOOwSAGBOptxygjUEZzudae/sc9tIktJs0kv/frLn5+sP+zLsEgAQK6zQIGr9zXYKuvE88PWHfRl2CQCIFQINBiXcbKdwZ3ivv/0kiWGXAICYYMsJg3bjbKdzFy+HbDPd6PrDvsFAdGMfGid9aAAAESDQICaun+1U837LgH5N8LAvwy4BAINFoEHMRXPYl2GXAIDB4AwNYo7DvgCARCPQIOb6u/3EYV8AQDwQaBAX4W4/Oe0ZAxpYCQBAJDhDg7jhsC8AIFEINIgrDvsCABKBLScAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5BBoAAGB5TNvGgHX5AzrS3KqzFzs1KjNDBWMdSk+zGV0WAAAEGgxMncerytoT8rZ39jzLsWeootilIneOgZUBAMCWEwagzuNVedXxkDAjSWfaO1VedVx1Hq9BlQEA0I1Ag351+QOqrD2hQB+fBZ9V1p5Ql7+vNwAASAwCDfp1pLm118rM9QKSvO2dOtLcmriiAAC4AYEG/Tp7MXyYieY9AADigUCDfo3KzIjpewAAxAOBBv0qGOtQjj1D4S5n29R926lgrCORZQEAEMK0geaTTz7RY489poKCAk2ZMkUrVqxQc3Nzz+cnT55UWVmZJk+erJkzZ2r79u0GVpu80tNsqih2SVKvUBP8uaLYRT8aAIChTBtoHn/8cY0YMUK/+MUvtH//fg0fPlyrV6+WJHV2dmrVqlW67777dOjQIb322mvaunWr3nnnHYOrTk5F7hxtKZskpz10W8lpz9CWskn0oQEAGM6UjfWuXLmisrIyzZw5U8OGDZMkfeMb39BTTz2lQCCg9957T1evXlV5ebnS09M1YcIELViwQNXV1Zo5c6bB1SenIneOZricdAoGAJiSKQPNkCFDtGDBgp6fvV6vfvazn6moqEg2m02NjY3Ky8tTenp6zzsul0u7du0yotyUkZ5m0/133WF0GQAA9GLaLacgt9utBx98UJ/73Of04osvSpJ8Pp+ysrJC3svOzpbP55Pf7zeiTAAAYCDDAk1NTY3y8vL6/GfPnj0973k8Hh08eFC33nqrli9f3m9gsdnY/gAAIBUZtuVUUlKikpKSAb3rdDq1fv16ffWrX1VjY6McDodOnz4d8o7P51N2drbS0ky/6AQAAGLMlN/+v//97zVt2jS1tbX1PAsGlVtvvVVut1unTp3StWvXej5vaGjQxIkTE14rAAAwnikDzZ133qnMzExt2LBBFy5cUEdHh1555RX91V/9lb74xS9q2rRpGj58uLZs2aJLly7pgw8+0O7du7Vo0SKjSwcAAAYwZaBJT0/X1q1b9T//8z+aNm2apk+frnPnzulHP/qRhgwZoiFDhuhHP/qRfv3rX6ugoEBPP/20Vq9erQcffNDo0gEAgAFMeW1bknJzc7Vly5awn48fP147d+5MYEUAAMCsTLlCAwAAEAkCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsDwCDQAAsLxbjC7Ayrr8AR1pbtXZi50alZmhgrEOpafZjC4LAICUQ6CJUp3Hq8raE/K2d/Y8y7FnqKLYpSJ3joGVAQCQethyikKdx6vyquMhYUaSzrR3qrzquOo8XoMqAwAgNRFoItTlD6iy9oQCfXwWfFZZe0Jd/r7eAAAA8UCgidCR5tZeKzPXC0jytnfqSHNr4ooCACDFEWgidPZi+DATzXsAAGDwCDQRGpWZEdP3AADA4BFoIlQw1qEce4bCXc62qfu2U8FYRyLLAgAgpRFoIpSeZlNFsUuSeoWa4M8VxS760QAAkEAEmigUuXO0pWySnPbQbSWnPUNbyibRhwYAgASjsV6Uitw5muFy0ikYAAATINAMQnqaTfffdYfRZQAAkPLYcgIAAJZHoAEAAJZHoAEAAJZHoAEAAJZniUDzxhtvKC8vT5988knPs5MnT6qsrEyTJ0/WzJkztX37dgMrBAAARjJ9oPnzn//cK6x0dnZq1apVuu+++3To0CG99tpr2rp1q9555x2DqgQAAEYyfaD5x3/8R5WWloY8e++993T16lWVl5frtttu04QJE7RgwQJVV1cbVCUAADCSqQPNwYMHderUKS1fvjzkeWNjo/Ly8pSent7zzOVyyePxJLpEAABgAqYNNJ2dnXrppZf0ve99T0OGDAn5zOfzKSsrK+RZdna2fD6f/H5/IssEAAAmYFin4JqaGj3zzDN9frZx40b94Q9/kNvt1tSpUwf8e9psfY8dOHv2rLq6ujR9+vSoagUAAInn9XpDdmP6Y1igKSkpUUlJSZ+fNTU1adOmTfq3f/u3Pj93OBw6ffp0yDOfz6fs7GylpfVedBo6dKiuXLky2JIBAEAC3XLLLb12acK+G+daovIf//EfunjxombPnh3yfN68eVqxYoXcbrd27typa9eu6ZZbuv8IDQ0NmjhxYp+/39GjR+NeMwAAMI4tEAgEjC7iRh0dHero6Ah5Nm3aNFVXV2vcuHEaMmSIioqKNHfuXH3nO9/R7373O33nO9/Rpk2b9OCDDxpTNAAAMIwpA01f8vLytH//fn3hC1+QJP3ud79TRUWFPB6PRowYoRUrVmjx4sUGVwkAAIxgmUADAAAQjmmvbWNg2tratG7dOk2dOlVTpkzRE088Ia/Xa3RZKamhoUEzZszQwoULjS4lpbS0tGjlypWaMmWKHnroIW3atIn2DQY5dOiQCgsLtXr1aqNLSVktLS16/PHHNWXKFBUWFurZZ5/VhQsXjC4rIQg0Frd+/XqdO3dOtbW1+vnPf66rV69q/fr1RpeVcvbu3asnn3xSd955p9GlpJwnn3xSo0eP1r59+7Rjxw7t27dPb7zxhtFlpZxt27Zpw4YN/G/AYI8++qiysrJ04MAB7dmzRx999JFefvllo8tKCAKNhQUCAY0ePVrr1q2Tw+FQdna2SktLdezYMbGTmFiXL19WdXV12Jt2iI+GhgZ9+OGHWrt2rTIzMzVmzBgtXbqUMSgGGDp0qHbv3k2gMdCFCxfkdru1Zs0aDRs2TE6nU3Pnzk2Zm76mvLaNgbHZbKqsrAx55vV6NXLkyLBNBhEfCxYsMLqElNTY2Kjc3FzZ7faeZxMmTFBzc7M6Ojo0fPhwA6tLLUuWLDG6hJSXlZWljRs3hjzzer0aNWqUQRUlFis0SeSTTz7R5s2bVV5ebnQpQEL0NQYlGG7a2tqMKAkwjYaGBlVVVaXMdwKBxuRqamqUl5fX5z979uzpea+pqUllZWWaO3cuqwVxMND/HpB4bK8CvR07dkzLly/XmjVrVFhYaHQ5CcGWk8n1NyIi6Le//a1WrFihZcuWadWqVQmqLLUM5L8HJJ7D4ZDP5wt55vP5ZLPZ5HA4jCkKMNiBAwf03e9+Vy+88ILmzJljdDkJQ6CxuNOnT2vlypVat26d5s2bZ3Q5QEK53W55vV61trb2BJiGhgaNGzdOw4YNM7g6IPGOHz+udevWafPmzXrggQeMLieh2HKyuBdffFELFy4kzCAluVwu5efn65VXXlFHR4eampq0Y8cOLVq0yOjSgIS7du2ann/+ea1duzblwoxEp2BL83q9evDBB3Xrrbf2utW0fft23XvvvQZVlnoeeeQR/elPf1JXV5f8fr9uvfVWSVJdXZ1yc3MNri65nTlzRi+88IKOHDmi4cOHq7S0VE888QQ3/RIsPz9fUveXqqSQwcFIjKNHj+pb3/pWn9OpU+HvIgINAACwPLacAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAACA5RFoAFhSdXW1HnroIXV2dkqSzp8/r3vuuUfvvvuuwZUBMAKBBoAlLVy4UJ///Of14x//WJL06quvqrCwUDNmzDC4MgBGuMXoAgAgGjabTS+99JK++c1vavz48dq3b5/eeusto8sCYBBWaABY1he/+EV9+9vf1tNPP621a9dq5MiRRpcEwCAEGgCW1tLSos997nNqbm42uhQABiLQALCs+vp6HTx4UDt37tSbb74pj8djdEkADEKgAWBJly9fVkVFhb773e/q7rvv1ooVK/T888/r2rVrRpcGwAAEGgCW9MMf/lAjRozQnDlzJEnLly/XpUuX9JOf/MTYwgAYwhYIBAJGFwEAADAYrNAAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADLI9AAAADL+/+ze7e18M66FwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-white')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import pc3 as pc3 # some custom functions for this PC lab\n",
        "\n",
        "n=50 # number of data points\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=6) # you can change the standard deviation of the noise\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JjMNziEqZB2"
      },
      "source": [
        "Now, let's use linear regression to model $y$ as a function of $x$. We can use the analytic result from the normal equations to find the optimal weight vector $\\mathbf{w_{OLS}}$. For this, we will need the [np.linalg.inv()](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html) and [np.matmul()](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) functions in NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp-qRbgdqZB3"
      },
      "outputs": [],
      "source": [
        "# Put the features in a matrix, with a column of ones for the intercept\n",
        "X = np.ones((n,2))\n",
        "X[:,1] = x\n",
        "\n",
        "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)),X.T),y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiIBNXW4npTk"
      },
      "source": [
        "We find the weight vector that minimizes the MSE between observations and predictions. With this weight matrix, we can estimate $y$ for the $x$'s in our dataset (or for any future value of $x$):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGwc3cqCqZB5"
      },
      "outputs": [],
      "source": [
        "y_hat = np.matmul(X, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhTJpIbQqZB5"
      },
      "source": [
        "Now, let's visualize the regression line. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "BfREh2yPqZB5",
        "outputId": "1063c680-de89-4bda-a914-059a0688500a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');\n",
        "ax.plot(x, y_hat, color='orange');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6RGpAHWnzLV"
      },
      "source": [
        "We can evaluate the performance of our model by computing the MSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4iU6EjGn2Oc",
        "outputId": "bed23edf-f7f0-4087-e2d8-a3c5882a6a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error: 28.31699171537876\n"
          ]
        }
      ],
      "source": [
        "# Function to compute MSE\n",
        "def compute_MSE(y_true, y_predicted):\n",
        "    \"\"\"Obtain MSE between true y's and predicted y's\"\"\"\n",
        "    return(np.mean((y_true-y_predicted)**2))\n",
        "\n",
        "MSE = compute_MSE(y, y_hat)\n",
        "print('Mean squared error: {}'.format(MSE))\n",
        "\n",
        "#Note that the vectorized notation would give the same result: MSE = np.dot(np.transpose(y_hat-y),(y_hat-y))/n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ks8U773n90q"
      },
      "source": [
        "Obviously, this just reflects the performance of our model on the training data and we could get an arbitrarily low MSE by making our model more complex. In reality, we are more interested in the performance of our model on new, unseen data that was not used to train the model. We will illustrate this on a practical example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9AHHlp-qZB7"
      },
      "source": [
        "## 2. Application: predicting house prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBmNcQxJqZB7"
      },
      "source": [
        "We will use a [housing dataset](https://www.kaggle.com/harlfoxem/housesalesprediction) hosted on Kaggle for a practical illustration, slightly modified for the purpose of this PC lab. You can find the data in the file pc3_housingdata_modified.csv. The dataset contains the price of 21613 houses in US dollars, together with the following features:\n",
        "1. **Categorical features** (take on one of a limited, and usually fixed, number of possible values): waterfront yes/no, color (yellow, blue, white or 'other').\n",
        "2. **Ordinal features** (similar as categorical features, yet, equipped with a natural ordering): number of bedrooms, bathrooms, floors, yr_built.\n",
        "3. **Continuous features**: surface areas: sqft_living, sqft_lot, sqft_above, sqft_basement, and latitude, longitude.\n",
        "\n",
        "We would like to build a model that can predict the price of a house based on these features. First, let's read in the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIPobbwhqZB7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/tfmortie/mlmust/main/03_linear_regression/pc3_housingdata_modified.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtUWYyNFqZB7"
      },
      "source": [
        "Let's visualize some features to get an idea of what this data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xdPEC6fqZB7"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(data.loc[:,['price', 'sqft_living', 'sqft_basement', 'lat', 'long']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sFT5T3cqZB8"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data.loc[:,['price','color', 'waterfront', 'bathrooms', 'bedrooms']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-5C6BiuqZB8"
      },
      "source": [
        "There are different types of features here. How can we use the color attribute in a linear regression model? As seen in the previous practical, dummy variables can be used to encode categorical features. In machine learning, this is called **one-hot encoding**. As seen in the previous practical, both [Scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [Pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) provide functions of that kind. Let's use Pandas, since it can handle text features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGC-lxuvqZB8"
      },
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(data.color)\n",
        "dummies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e1BgNzLqZB9"
      },
      "source": [
        "Let's add these encoded features to the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z5aGwuTqZB9"
      },
      "outputs": [],
      "source": [
        "data_onehot = pd.concat([data, dummies], axis=1)\n",
        "data_onehot = data_onehot.drop(['color'], axis=1) # remove the original color column\n",
        "data_onehot.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDkhvS4GqZB9"
      },
      "source": [
        "We can use these dummy variables in a linear regression model. First, it's good to extract the data from the Pandas dataframe into NumPy arrays, since most machine learning APIs are compatible with NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3r6Yq8dqZB9"
      },
      "outputs": [],
      "source": [
        "# Put data in numpy arrays\n",
        "y = data_onehot.price.values\n",
        "X = data_onehot.drop('price', axis=1).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_2zvs4uqZB9"
      },
      "source": [
        "Finally, we would like to evaluate the performance of our data on new, unseen data, that was not used to train the model. Therefore, we split up our dataset into a training and a test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_pDKvBhqZB9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7) # Use 70% of data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpXx-tmqZB-"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 2.1</b>: **Use the Scikit-learn Linear Regression implementation to fit a model on the housing dataset. Use the training data to fit the model. Compare the MSE of the model obtained on the training and on the test data, respectively. Finally, compute the coefficient of determination ($R^2$) on the test data. The relevant documentation page contains all the information that you need. Convenient methods that are defined in almost all Scikit-learn models are _fit()_, _predict()_ and _score()_.**     \n",
        "</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZZMQMPFqZB-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# call an instance of the class LinearRegression\n",
        "linreg = \"...\"\n",
        "\n",
        "# fit the model on the training data\n",
        "\"...\"\n",
        "\n",
        "# predict training data\n",
        "y_hat_train = \"...\"\n",
        "\n",
        "# Compute training set MSE\n",
        "train_MSE = \"...\"\n",
        "\n",
        "# predict test data\n",
        "y_hat_test = \"...\"\n",
        "\n",
        "# Test set MSE\n",
        "test_MSE = \"...\"\n",
        "\n",
        "R2_train = linreg.score(X_train, y_train)\n",
        "R2_test = linreg.score(X_test, y_test)\n",
        "\n",
        "print('Training set MSE: {}'.format(train_MSE))\n",
        "print('Test set MSE: {}'.format(test_MSE))\n",
        "print('Training set R2: {}'.format(R2_train))\n",
        "print('Test set R2: {}'.format(R2_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEQRfNbqZB-"
      },
      "source": [
        "## 3. Adding model flexibility: polynomial feature expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHxg7FpsqZB-"
      },
      "source": [
        "We can model non-linear relations by performing some non-linear transformation $\\phi(\\mathbf{x})$ on the original features $\\mathbf{x}$. This is known as a **basis function expansion**. An example of such a transformation are polynomial basis functions, where we consider higher-order powers of the original features:\n",
        "\n",
        "$$\\phi(x) = [1, x, x^2, x^3,...,x^d].$$\n",
        "\n",
        "It is important to note here that, although we use non-linear transformations, the model linear regression model $y = f(\\phi(x)$ will still be linear in the parameters:\n",
        "\n",
        "$$\\hat{y} = w_{10}x_{0} + w_{11}x_{1} + w_{12}x_{1}^2 ... + w_{md}x_{m}^d.$$\n",
        "\n",
        "This means that the solution will still be a line, be it in a transformed and typically higher-dimensional space instead of in the original feature space. This also means that we obtain the least-squares solutions just as we did earlier on.\n",
        "\n",
        "With different feature expansions, we can strongly improve the performance of linear regression by taking into account interaction effects, quadratic or cubic effects... However, the risk of overfitting also increases! Let's go back to the simulation example. Instead of doing a simple linear regression, we will perform a polynomial feature expansion of the single feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp_hRfbtqZB-"
      },
      "outputs": [],
      "source": [
        "import pc3 as pc3 # some custom functions for this PC lab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n=100 # number of data points 5000\n",
        "eps=10 # amount of noise 20\n",
        "\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=eps) # you can change the standard deviation of the noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGF8MhhwqZB-"
      },
      "outputs": [],
      "source": [
        "# Put the features in a matrix, with a column of ones for the intercept. Add polynomial expansions.\n",
        "\n",
        "# add x up to the 10th power\n",
        "n_polynomials=20\n",
        "\n",
        "X = np.ones((n,n_polynomials))\n",
        "X[:,1] = x\n",
        "\n",
        "for i in np.arange(2, n_polynomials):\n",
        "    X[:,i] = x**i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq13UySzqZB_"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.1</b>: **Create the polynomial expansions of the original dataset using the [PolynomialFeatures()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) function from Scikit-learn. Use the fit and predict functions you used in the previous exercise to obtain the predictions $\\hat{y}$.**     \n",
        "</div>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52HDud5opO9J"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "poly = PolynomialFeatures(degree=20)\n",
        "\"...\"\n",
        "\n",
        "LinReg = \"...\" # call an instance of the class LinearRegression\n",
        "\n",
        "# fit the model on the training data\n",
        "\"...\"\n",
        "\n",
        "y_hat = \"...\" # predict training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_f3EmLSqZB_"
      },
      "source": [
        "Again, let's visualize the regression line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8A9BmtBqZCA"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x,y);\n",
        "ax.set_xlabel('x');\n",
        "ax.set_ylabel('y');\n",
        "ax.plot(np.sort(x), y_hat[np.argsort(x)] , '--', color=\"orange\");\n",
        "ax.legend(['Observation', 'Predicted']);\n",
        "ax.set_title('MSE: {}'.format(mean_squared_error(y, y_hat))).set_fontsize(20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7p3gTtrqZCA"
      },
      "source": [
        "As can be seen above, expanding the polynomial up to the 20th power leads to a too complex model. **Remember that we simulated the data from an underlying linear relation between x and y!** This is a clear example of overfitting: by performing the polynomial expansion, our model becomes too flexible and fits to patterns in the data that, in reality, are just noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRKEnghXy2mw"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>OPTIONAL EXERCISE: Play with the parameters in the code above. Change the number of simulated data points from 50 to 100, 200, 500. What happens with the overfitting? Change the amount of noise.  Increase the size of the polynomial up to degree 12. Compare the MSE's. Try to understand the influence of each of these factors on the behavior of the model.</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W245ttFIqZCA"
      },
      "source": [
        "By evaluating the performance of our model on a test set, we can check if we are overfitting or not. The following code simulates n data points from a linear model with noise. 50% of them are used to fit a linear regression model, with an increasing number of polynomial features. The other 50% data points are held out as a test set. For each model, the MSE on both the training and test data is evaluated. The plot shows the training and test MSE for increasing degrees of the polynomial expansion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a2dx-r2qZCA"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "n=100\n",
        "eps= 20\n",
        "x, y = pc3.simulate_linear_data(n=n, eps=eps) # you can change the standard deviation of the noise\n",
        "\n",
        "x_test, x_train = x[:n//4].reshape(-1, 1), x[n//4:].reshape(-1, 1)\n",
        "\n",
        "y_test, y_train = y[:n//4].reshape(-1, 1), y[n//4:].reshape(-1, 1)\n",
        "\n",
        "LinReg = LinearRegression()\n",
        "\n",
        "MSE_train = []\n",
        "MSE_test = []\n",
        "\n",
        "for i in np.arange(1, 15):\n",
        "    poly = PolynomialFeatures(degree=i)\n",
        "    poly.fit(x_train)\n",
        "    X_train = poly.transform(x_train)\n",
        "    X_test = poly.transform(x_test)\n",
        "\n",
        "    LinReg.fit(X_train,y_train.reshape(-1,1))\n",
        "    pred_train = LinReg.predict(X_train)\n",
        "    pred_test = LinReg.predict(X_test)\n",
        "    MSE_train.append(mean_squared_error(y_train, pred_train))\n",
        "    MSE_test.append(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "pd.Series(MSE_train).plot(ax=ax, marker='o');\n",
        "pd.Series(MSE_test).plot(ax=ax, marker='o', color='orange');\n",
        "ax.legend(['Train MSE', 'Test MSE']);\n",
        "ax.set_xlabel('size of polynomial');\n",
        "ax.set_ylabel('MSE');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-4rhvqjypOo"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>OPTIONAL EXERCISE: Describe what you see. What happens with the training MSE as you increase the number of features? What happens with the test MSE? How can you explain this?</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWltJxMvqZCB"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>OPTIONAL EXERCISE: Try to improve the performance of the linear model for the housing dataset by expanding the feature space. Scikit-learn has a method to expand a NumPy array with polynomial features. Keep an eye on overfitting!</b>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
