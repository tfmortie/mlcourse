{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-QGekCYXVyl"
   },
   "source": [
    "# PC lab: Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xPw7_lWXmq4"
   },
   "source": [
    "In this practical, we’ll introduce a class of unsupervised deep learning models, called generative models, that enables us to learn the underlying, unknown distribution of a given dataset. Using these models, we can generate new samples that resemble the observed training data. \n",
    "\n",
    "We’ll begin by constructing an autoencoder network — a neural network architecture designed to encode and reconstruct data, learning efficient representations. Finally, we’ll extend our autoencoder into a generative model, known as a variational autoencoder (VAE), capable of producing realistic new samples. For demonstration, we will train and test the VAE on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cm1zTrfXaz2"
   },
   "source": [
    "## 1.1 Creating an autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1BfaMXKYweI"
   },
   "source": [
    "Typically, an autoencoder will look something like this:\n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*gzJAJDLDavH_W7Zv2M2J7w.png' width = 600>\n",
    "\n",
    "In essence, the first part of the network (the encoder) compresses the input to a lower dimensional space. It does this by (1) first using convolutions, (2) flattening, and (3) a linear layer at the end. The second part (the decoder) undergoes the same steps, but in reverse.\n",
    "\n",
    "In order to make an autoencoder, we can copy the model from the CNN PC lab, use it as an encoder, and then make the inverse of that model as the decoder, and place the two in sequence.\n",
    "\n",
    "As a reminder, this was the CNN Classifier from the previous PC lab, with some small changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.471118Z",
     "iopub.status.busy": "2023-11-23T21:25:09.470283Z",
     "iopub.status.idle": "2023-11-23T21:25:09.480442Z",
     "shell.execute_reply": "2023-11-23T21:25:09.479475Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.471083Z"
    },
    "id": "gPisFRgXevnG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim = 64, kernel_size = 5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size, padding = \"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(hidden_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size = 8):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 5),\n",
    "            ResidualBlock(8),\n",
    "            nn.MaxPool2d(2),\n",
    "            ResidualBlock(8),\n",
    "            nn.Conv2d(8, 16, 5),\n",
    "            ResidualBlock(16),\n",
    "            nn.MaxPool2d(2),\n",
    "            ResidualBlock(16),\n",
    "            nn.Conv2d(16, 16, 3),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.MLP = nn.Linear(16 * 2 * 2, bottleneck_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.MLP(self.flatten(self.cnn(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOfOoFF3bnLc"
   },
   "source": [
    "For the decoder, we need inverse convolutions (and maybe inverse max pooling) operations to upscale our image again from its compressed representation to its original dimensions.\n",
    "\n",
    "In PyTorch, we have these options:\n",
    "\n",
    "- [ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) also visualized [here](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html), the inverse of convolutions, also called deconvolution.\n",
    "- [Upsample](https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html#torch.nn.Upsample), performing simple non-parametric upscaling of inputs with any of a number of methods such as bilinear or bicubic upscaling.\n",
    "- [MaxUnpool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html?highlight=maxunpool#torch.nn.MaxUnpool2d), performing the inverse of a previous max pooling operation. Essentially putting the maximal elements back in the location/index where they originally appeared before the previous max pooling. As such, this operation can only be used conjoined with a paired max pooling operation. (see examples in documentation).\n",
    "\n",
    "For this PC lab, we simply recommend to replace Convolutions with `ConvTranspose2d` and Max-Pooling layers with `Upsample`.\n",
    "\n",
    "Also, you will need to [Unflatten](https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html) your image after flattening it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.482525Z",
     "iopub.status.busy": "2023-11-23T21:25:09.482185Z",
     "iopub.status.idle": "2023-11-23T21:25:09.499317Z",
     "shell.execute_reply": "2023-11-23T21:25:09.498468Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.482501Z"
    },
    "id": "2uaiGkaHhrDe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Illustration of unflatten:\n",
    "# The dimensions we want:\n",
    "C = 64\n",
    "H = 16\n",
    "W = 16\n",
    "\n",
    "unflatten = nn.Unflatten(1, (C, H, W))\n",
    "x = torch.randn(8, C*H*W) # imagine you have a tensor of this size before unflattening\n",
    "print(x.shape)\n",
    "y = unflatten(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXfxN4d5il1d"
   },
   "source": [
    "The following code illustrates the use of [Upsample](https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html#torch.nn.Upsample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.501557Z",
     "iopub.status.busy": "2023-11-23T21:25:09.501054Z",
     "iopub.status.idle": "2023-11-23T21:25:09.512917Z",
     "shell.execute_reply": "2023-11-23T21:25:09.511748Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.501516Z"
    },
    "id": "UJvKk_zuirrd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "upsample = nn.Upsample(scale_factor = 2)\n",
    "x = torch.randn(8, 64, 16, 16)\n",
    "print(x.shape)\n",
    "y = upsample(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvrLG23kfOYA"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>EXERCISE:</b>\n",
    "<p> Implement a Decoder by creating the inverse of the Encoder model in the cell above. Create an autoencoder model that combines the Encoder and decoder.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.514177Z",
     "iopub.status.busy": "2023-11-23T21:25:09.513936Z",
     "iopub.status.idle": "2023-11-23T21:25:09.532228Z",
     "shell.execute_reply": "2023-11-23T21:25:09.531385Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.514154Z"
    },
    "id": "Kr5IUJdxjJNW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size = 8):\n",
    "        super().__init__()\n",
    "        self.MLP = nn.Linear(...) # Your code here\n",
    "        self.flatten = nn.Unflatten(...) # Your code here\n",
    "        self.cnn = nn.Sequential(\n",
    "            ... # your code here, try to invert the CNN of the encoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(self.flatten(self.MLP(x)))\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size = 8):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(bottleneck_size = bottleneck_size)\n",
    "        self.decoder = Decoder(bottleneck_size = bottleneck_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "\n",
    "model = AutoEncoder(bottleneck_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.534150Z",
     "iopub.status.busy": "2023-11-23T21:25:09.533868Z",
     "iopub.status.idle": "2023-11-23T21:25:09.556826Z",
     "shell.execute_reply": "2023-11-23T21:25:09.555991Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.534127Z"
    },
    "id": "rhanNshDkaOI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(8, 1, 28, 28)\n",
    "print(\"original shape of x:\")\n",
    "print(x.shape)\n",
    "print(\"Testing encoder:\")\n",
    "x_encoded = model.encode(x)\n",
    "print(x_encoded.shape)\n",
    "print(\"Testing decoder:\")\n",
    "x_decoded = model.decode(x_encoded)\n",
    "print(x_decoded.shape)\n",
    "print(\"Testing whole model at once:\")\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i3ufw9ukOkn"
   },
   "source": [
    "After successfully implementing the autoencoder, we can work on some real data. The following code loads in the MNIST data. It's exactly copy-pasted from the CNN PC-lab so you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.558207Z",
     "iopub.status.busy": "2023-11-23T21:25:09.557938Z",
     "iopub.status.idle": "2023-11-23T21:25:09.898382Z",
     "shell.execute_reply": "2023-11-23T21:25:09.897579Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.558182Z"
    },
    "id": "mj6toMK7kXc_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "X_train = train_data.data\n",
    "y_train = train_data.targets\n",
    "\n",
    "X_test = test_data.data\n",
    "y_test = test_data.targets\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "\n",
    "np.random.seed(42)\n",
    "train_indices, val_indices = np.split(np.random.permutation(len(X_train)), [int(len(X_train)*0.8)])\n",
    "X_val = X_train[val_indices]\n",
    "y_val = y_train[val_indices]\n",
    "X_train = X_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, pin_memory=True, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KkyjWBHlzo6"
   },
   "source": [
    "The following code trains the resulting autoencoder model on MNIST, using similar code as in previous PC labs. Some notes:\n",
    "- We are reconstructing pixels. These are real-valued. Hence, this is a regression task and we're using the Mean squared error loss.\n",
    "- Our batches return an X and a Y, but we're not using the labels Y here. Instead, the true \"labels\" for our loss is simply X.\n",
    "- In contrast to previous PC labs - this code uses the GPU (note the `.to(\"cuda\")` calls). This considerably speeds up training. If you're running this locally and don't have a GPU, delete these calls. If you're running on colab but it still returns an error: Go to `Runtime > Change runtime type`, and select an instance with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:25:09.900466Z",
     "iopub.status.busy": "2023-11-23T21:25:09.900167Z",
     "iopub.status.idle": "2023-11-23T21:32:55.930873Z",
     "shell.execute_reply": "2023-11-23T21:32:55.929834Z",
     "shell.execute_reply.started": "2023-11-23T21:25:09.900439Z"
    },
    "id": "V6tb5BCBl6tW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "model = AutoEncoder(bottleneck_size = 8).to(\"cuda\")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(1, N_EPOCHS + 1):\n",
    "    all_losses = []\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, _ = batch\n",
    "        X_batch = X_batch.to(\"cuda\")\n",
    "\n",
    "        y_hat_batch = model(X_batch)\n",
    "\n",
    "        loss = loss_function(y_hat_batch, X_batch) # Compute loss\n",
    "\n",
    "        loss.backward()   # Calculate gradients\n",
    "        optimizer.step()   # Update weights using defined optimizer\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "    train_loss = np.mean(all_losses)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            X_batch, _ = batch\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "\n",
    "            y_hat_batch = model(X_batch)\n",
    "\n",
    "            loss = loss_function(y_hat_batch, X_batch)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    print(i, '\\t', train_loss, np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCHfiT2sXfAP"
   },
   "source": [
    "## 1.2 Going variational\n",
    "\n",
    "Putting an explanation based on rigorous mathematical theory aside, variational autoencoders can also be viewed as normal autoencoders, but with regularization on the bottleneck space.\n",
    "This bottleneck regularization pushes the samples in the latent space to be normally distributed.\n",
    "In turn, this means that - after training - if we send randomly generated Gaussian noise through the model, the model will generate samples that are similar to the training samples.\n",
    "In order to get a better understanding of this process: [this blog](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) provides a really good overview.\n",
    "\n",
    "An overview image:\n",
    "\n",
    "<img src=https://learnopencv.com/wp-content/uploads/2020/11/vae-diagram-1-1024x563.jpg width=400>\n",
    "\n",
    "In order to go variational: we need to adapt three things.\n",
    "- Instead of generating a single vectore, we'll need to generate two vectors, parametrizing the mean and variance of the estimated distribution of that sample.\n",
    "- After encoding and before decoding, in the bottleneck space, we need to stochastically sample from that distribution.\n",
    "- We need to add a loss term that pushes bottleneck points towards a gaussian distribution.\n",
    "\n",
    "Typically, we let our model generate the mean and the *log*-variance of the model. This ensures that the model can not predict negative variances (which makes no sense).\n",
    "\n",
    "The following code illustrates step 1: how to extend the encoder with two layers so that two outputs are obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:32:55.932602Z",
     "iopub.status.busy": "2023-11-23T21:32:55.932305Z",
     "iopub.status.idle": "2023-11-23T21:32:55.947812Z",
     "shell.execute_reply": "2023-11-23T21:32:55.946661Z",
     "shell.execute_reply.started": "2023-11-23T21:32:55.932576Z"
    },
    "id": "ONqVy5n7tGY6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(8, 1, 28, 28)\n",
    "print(x.shape)\n",
    "encoder = Encoder(bottleneck_size = 8)\n",
    "z = encoder(x)\n",
    "print(z.shape)\n",
    "\n",
    "# two separate linear combinations separate the bottleneck space into means and logvars:\n",
    "linear_to_means = nn.Linear(8, 8)\n",
    "linear_to_logvars = nn.Linear(8, 8)\n",
    "\n",
    "z_means = linear_to_means(z)\n",
    "z_logvars = linear_to_logvars(z)\n",
    "print(z_means.shape)\n",
    "print(z_logvars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTj_gg56tF2Y"
   },
   "source": [
    "The following code shows step 2: how to resample from a mean and a log-variance, as how it is done in the [original VAE paper](https://arxiv.org/abs/1312.6114):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:32:55.949597Z",
     "iopub.status.busy": "2023-11-23T21:32:55.949042Z",
     "iopub.status.idle": "2023-11-23T21:32:55.956921Z",
     "shell.execute_reply": "2023-11-23T21:32:55.955994Z",
     "shell.execute_reply.started": "2023-11-23T21:32:55.949563Z"
    },
    "id": "UOtaYP3sqYSe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reparameterization(mean, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mean + eps * std\n",
    "\n",
    "means = torch.randn(8, 8)\n",
    "logvars = torch.randn(8, 8)\n",
    "\n",
    "y = reparameterization(means, logvars)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiKm_CeyuQRP"
   },
   "source": [
    "The following code shows an adaptation of the loss function (step 3).\n",
    "It shows that the loss still contains the reconstruction error (as with normal autoencoders), but an extra term is added: the [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence). The KL divergence measures how much the estimated means and logvars of the model deviate from a normal distribution. So, by incorporating this into our loss, the model will be stimulated to push these values to a Gaussian distribution. Beta is an additional parameter that weighs the loss component (higher values of beta means that the loss will place higher weight on optimizing the KL divergence instead of focusing on reconstruction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:32:55.958535Z",
     "iopub.status.busy": "2023-11-23T21:32:55.958229Z",
     "iopub.status.idle": "2023-11-23T21:32:55.965792Z",
     "shell.execute_reply": "2023-11-23T21:32:55.964803Z",
     "shell.execute_reply.started": "2023-11-23T21:32:55.958509Z"
    },
    "id": "oWwrasvguWUp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class VAELoss(nn.Module):\n",
    "    def __init__(self, beta = 0.001):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, x_reconstruct, means, logvars, x_true):\n",
    "        reconstruction_loss = F.mse_loss(x_reconstruct, x_true)\n",
    "        KL_div_loss = (-0.5 * torch.sum(1 + logvars - means**2 - logvars.exp())) / means.size(1)\n",
    "\n",
    "        return reconstruction_loss + self.beta * KL_div_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTzQHTRIvvTj"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>EXERCISE:</b>\n",
    "<p> Use the examples of the steps below to reimplemt the autoencoder to make it variational. You can use the code below as a guideline. It should not require more than some copy pasting in the right places.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:32:55.969852Z",
     "iopub.status.busy": "2023-11-23T21:32:55.969029Z",
     "iopub.status.idle": "2023-11-23T21:32:55.987352Z",
     "shell.execute_reply": "2023-11-23T21:32:55.986108Z",
     "shell.execute_reply.started": "2023-11-23T21:32:55.969809Z"
    },
    "id": "rjazrKJ-v7GS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size = 8):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(bottleneck_size = bottleneck_size)\n",
    "\n",
    "        # YOUR CODE HERE, define two separate linear projections.\n",
    "        self.linear_to_means = ...\n",
    "        self.linear_to_logvars = ...\n",
    "\n",
    "        self.decoder = Decoder(bottleneck_size = bottleneck_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        # YOUR CODE HERE, use the two separate linear projections.\n",
    "        z_means = ...\n",
    "        z_logvars = ...\n",
    "        return z_means, z_logvars\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    def forward(self, x):\n",
    "        z_means, z_logvars = self.encode(x)\n",
    "        # YOUR CODE HERE, sample from z_means and z_logvars using the reparameterization trick\n",
    "        z = ...\n",
    "        x_reconstruct = self.decode(z)\n",
    "        # Note that we return three vectors with this model! This is because we need these three to compute the loss\n",
    "        return x_reconstruct, z_means, z_logvars\n",
    "\n",
    "    def reparameterization(self, mean, logvar):\n",
    "        ...\n",
    "\n",
    "model = VariationalAutoEncoder(bottleneck_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvEba2sdxP36"
   },
   "source": [
    "A couple of things will need to be changed compared to the previous training code:\n",
    "- We use our own custom VAELoss function\n",
    "- Our model returns multiple outputs, which are all used in the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:32:55.988941Z",
     "iopub.status.busy": "2023-11-23T21:32:55.988621Z",
     "iopub.status.idle": "2023-11-23T21:41:38.920770Z",
     "shell.execute_reply": "2023-11-23T21:41:38.919723Z",
     "shell.execute_reply.started": "2023-11-23T21:32:55.988910Z"
    },
    "id": "VBbca2PAxSow",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "model = VariationalAutoEncoder(bottleneck_size = 8).to(\"cuda\")\n",
    "\n",
    "loss_function = VAELoss(beta = 0.001)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(1, N_EPOCHS + 1):\n",
    "    all_losses = []\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, _ = batch\n",
    "        X_batch = X_batch.to(\"cuda\")\n",
    "\n",
    "        x_reconstruct, z_means, z_logvars = model(X_batch)\n",
    "        loss = loss_function(x_reconstruct, means, logvars, X_batch) # Compute loss\n",
    "\n",
    "        loss.backward()   # Calculate gradients\n",
    "        optimizer.step()   # Update weights using defined optimizer\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "    train_loss = np.mean(all_losses)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            X_batch, _ = batch\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "\n",
    "            x_reconstruct, z_means, z_logvars = model(X_batch)\n",
    "            loss = loss_function(x_reconstruct, means, logvars, X_batch) # Compute loss\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    print(i, '\\t', train_loss, np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSrHiFfCXjzF"
   },
   "source": [
    "## 1.3 Dimensionality reduction and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L01k5WYyjMC"
   },
   "source": [
    "Now that we have trained our model, let's see how good it is at dimensionality reduction. For this purpose, let's repeat the validation loop, but this time only use the encoder of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:41:38.922580Z",
     "iopub.status.busy": "2023-11-23T21:41:38.922160Z",
     "iopub.status.idle": "2023-11-23T21:41:39.933075Z",
     "shell.execute_reply": "2023-11-23T21:41:39.932062Z",
     "shell.execute_reply.started": "2023-11-23T21:41:38.922544Z"
    },
    "id": "TWtaxR1nXT16",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoded_inputs = []\n",
    "classes = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in val_dataloader:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch = X_batch.to(\"cuda\")\n",
    "\n",
    "        z = model.linear_to_means(model.encoder(X_batch))\n",
    "        encoded_inputs.append(z)\n",
    "        classes.append(y_batch)\n",
    "\n",
    "classes = torch.cat(classes).cpu().numpy()\n",
    "encoded_inputs = torch.cat(encoded_inputs).cpu().numpy()\n",
    "\n",
    "print(encoded_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty4X5lcj1Uk6"
   },
   "source": [
    "Let's use t-SNE -- a dimensionality reduction technique -- to reduce our encodings to two-dimensional vectors, which can be visualized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:41:39.934828Z",
     "iopub.status.busy": "2023-11-23T21:41:39.934446Z",
     "iopub.status.idle": "2023-11-23T21:42:51.712357Z",
     "shell.execute_reply": "2023-11-23T21:42:51.711440Z",
     "shell.execute_reply.started": "2023-11-23T21:41:39.934794Z"
    },
    "id": "VmFEMXd91T20",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "encoded_tsne = TSNE(verbose = 10, init = \"pca\", learning_rate = \"auto\").fit_transform(encoded_inputs)\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.scatterplot(x = encoded_tsne[:,0], y = encoded_tsne[:, 1], hue = classes, alpha = .75, palette=\"pastel\", s = 3, linewidth = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akW-urHKXVT2"
   },
   "source": [
    "We can see that the model embeds samples of the class together, in clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3msfS58C3pw"
   },
   "source": [
    "Next, let's try to generate some new samples from our learned distribution. \n",
    "\n",
    "Remember that our variational autoencoder has been trained to represent samples as Gaussians in the bottleneck space. Logically, this allows to sample random Gaussians and retrieve realistic-looking samples after decoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T21:42:56.924903Z",
     "iopub.status.busy": "2023-11-23T21:42:56.924062Z",
     "iopub.status.idle": "2023-11-23T21:42:58.618341Z",
     "shell.execute_reply": "2023-11-23T21:42:58.617397Z",
     "shell.execute_reply.started": "2023-11-23T21:42:56.924866Z"
    },
    "id": "MLCSVoYkC3TU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# generating some random noise\n",
    "samples = torch.randn(16, 8).to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    decoded_samples = model.decode(samples)\n",
    "    decoded_samples = torch.clip(decoded_samples, min = 0, max = 1).cpu().numpy() * 255\n",
    "\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 4, 4\n",
    "for i in range(cols * rows):\n",
    "    img = decoded_samples[i]\n",
    "    figure.add_subplot(rows, cols, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.reshape(-1, 28, 28).squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
