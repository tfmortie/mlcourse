{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a033a991-9066-425e-b842-84cb72288e2a",
   "metadata": {},
   "source": [
    "# PC Lab 4: Linear Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed54e2d-c0ef-4b5e-8fe3-7551baa4f4c8",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701d14b-e08f-48be-b011-5063525017c7",
   "metadata": {},
   "source": [
    "In a binary classification setting, we are interested in assigning an observation ùê± to one of two possible classes, denoted by ùë¶. For example, maybe we would like to tell if a patient has a particular disease (y = 1) or not (y = 0), given certain symptoms ùê±, in other words, we want to model $Pr(y|\\mathbf{x})$, also called the *class posterior* or the *class-membership probability*. Two main approaches exist to model this probability: either directly using *discriminative models* or using *generative models*, which first model the joint probability $Pr(\\mathbf{x},y)$ and obtain the class posterior using Bayes' rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666eb86a-66f7-46ec-9305-e7b92cc1c0a4",
   "metadata": {},
   "source": [
    "### 1.1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8826e63-fbe7-4bba-ac02-d71ec7f1c7d9",
   "metadata": {},
   "source": [
    "**Logistic regression** (LR) is the most fundamental example of a **discriminative** model. Just like linear regression, LR is a linear model. However, LR does not model the mean of a continuous outcome, but the logarithm of the [odds](https://en.wikipedia.org/wiki/Odds) of $Pr(y|\\mathbf{x})$:\n",
    "\n",
    "$$log \\frac{Pr(y|\\mathbf{x})}{1-Pr(y|\\mathbf{x})} = w_{0}x_{0} + w_{1}x_{1} + ... + w_{p}x_{p} = \\mathbf{w^Tx}.$$\n",
    "\n",
    "In practice, we are really interested in the probability $Pr(y|\\mathbf{x})$ and not in the log-odds of $Pr(y|\\mathbf{x})$. To obtain this from the previous equation, we apply the *logistic function* (otherwise called a *sigmoid* function):\n",
    "\n",
    "$$\\phi(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^{z}}{1+e^{z}}.$$\n",
    "\n",
    "Applying this function on both sides of the LR equation, we get a model for $Pr(y|\\mathbf{x})$ as follows:\n",
    "\n",
    "$$Pr(y|\\mathbf{x}) = \\phi(\\mathbf{w^Tx}) = \\frac{1}{1 + e^{-\\mathbf{w^Tx}}}.$$\n",
    "\n",
    "If we want to classify a data point $\\mathbf{x}$, we can calculate the probability of it being class $y$ with the above equation. A final classification is then made by assigning it to the class if the probability $Pr(y|\\mathbf{x})$ exceeds a certain threshold, such as 0.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320607af-ec39-4868-a7c2-b7a04ad8d56a",
   "metadata": {},
   "source": [
    "![sigmoid](https://qph.fs.quoracdn.net/main-qimg-6ab7369356c16f17ac39fbb83d5d56c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2bc11-3f38-49c1-aa30-90730c5dae69",
   "metadata": {},
   "source": [
    "### 1.2. Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b6ee4-d219-4845-acdc-088a7fa170b5",
   "metadata": {},
   "source": [
    "In contrast to the (discriminative) logistic regression model, linear discriminative analysis (LDA) is a **generative** model. Generative models are called as they are because they specify the class-conditional densities $Pr(\\mathbf{x}|y)$, which allows to generate new observations $\\mathbf{x}$ for a class $y$: for a given class $y$, we can sample from the distribution $Pr(\\mathbf{x}|y)$. \n",
    "\n",
    "The main assumption in LDA is that the data in each class is assumed to follow a multivariate Gaussian distribution. Furthermore, the assumption is made that the (co)variance within and between predictor variables is the same for all the classes. As such, only a limited number of parameters have to be estimated from the data to fully specify the class-conditional distributions: in the multivariate case, we need to estimate the class-specific mean vectors $\\mathbf{\\mu_{k}}$ and the common covariance matrix $\\Sigma$. In the case of just one predictor (feature), this simplifies to estimating the mean of $x$ within each class and the variance $\\sigma^2$. The priors $Pr(y=k)$ are simply estimated from the data by calculating the proportion of training instances in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a882f-fc6c-42dc-835e-4655713e0678",
   "metadata": {},
   "source": [
    "![lda](https://d3i71xaburhd42.cloudfront.net/1ab8ea71fbef3b55b69e142897fadf43b3269463/1-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeabd4c-f0ec-485f-822c-86797c9395ce",
   "metadata": {},
   "source": [
    "Once the class-conditional densities $Pr(\\mathbf{x}|y)$ are modeled using LDA, predictions can be obtained by using Bayes' rule:\n",
    "\n",
    "$$Pr(y=k|\\mathbf{x}) = \\frac{Pr(\\mathbf{x}|y=k)Pr(y=k)}{Pr(\\mathbf{x})} = \\frac{Pr(\\mathbf{x}|y=k)Pr(y=k)}{\\sum_{l=1}^{K}Pr(\\mathbf{x}|y=l)Pr(y=l)},$$\n",
    "\n",
    "where all probabilities $Pr(\\mathbf{x}|y=l)$ are obtained by the LDA model and all probabilities $Pr(y=l)$ are simply obtained by means of the class frequency in the dataset (e.g. 70% of the training dataset samples belongs to class $l$, therefore, $Pr(y=l)=0.70$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76029b-4c52-4249-8118-4a1fe1431f25",
   "metadata": {},
   "source": [
    "## 2. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fd492-9851-440b-b723-3a23a4155878",
   "metadata": {},
   "source": [
    "### 2.1. Breast cancer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a51876-fd4c-4160-8da9-ef52bf22a09a",
   "metadata": {},
   "source": [
    "In the following exercises, we will use the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). The dataset contains information on the disease status of 569 breast cancer patients: they were either diagnosed with a malign (status M) or with a benign (status B) tumor. \n",
    "\n",
    "For each patient, the dataset also contains 30 features that represent statistics of the cell nuclei present in images taken after [fine needle aspirate tissue samples](https://en.wikipedia.org/wiki/Fine-needle_aspiration). These 30 features are the mean, standard deviation and the maximum of 10 measurements on the cell nuclei:\n",
    "- radius\n",
    "- texture\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness\n",
    "- compactness\n",
    "- concavity\n",
    "- concave points\n",
    "- symmetry\n",
    "- fractal dimension\n",
    "\n",
    "**Based on these features of the cell nuclei, we would like to predict whether a patient has a malign or a benign breast cancer tumor.** Let's download and read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f31a68-5049-4b65-b07f-7fc83358f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tfmortie/mlmust/main/04_linear_classification/wdbc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235338a5-837a-4f24-94df-39068166dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./wdbc.data', header=None, index_col=0, names=['Patient ID', 'status'] + list(np.arange(1,31,1)))\n",
    "status = data['status']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307da604-e41b-4a5e-b0cb-3529469f3b2e",
   "metadata": {},
   "source": [
    "First, let's look at the distribution of the disease status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd9c72-fdd5-4c75-a0b3-c3554db4ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(data['status']).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317cbd1-51a6-40a9-bf34-8cfdf864d967",
   "metadata": {},
   "source": [
    "There are about 350 benign cases and roughly 200 malign cases. This is a fairly balanced dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>THOUGHT EXERCISE: Suppose that the dataset was unbalanced, with 525 B cases and only 25 M cases. Would you still use accuracy to evaluate the model?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2e589-7e63-4f94-bf08-83391e546c5f",
   "metadata": {},
   "source": [
    "In these exercises, we will use the [Scikit-learn](https://scikit-learn.org/stable/) implementations of [LR](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [LDA](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b545166-f0b7-48eb-823b-cf33076a09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = status\n",
    "x = data.drop('status', axis=1).values # Drop the disease status from the dataframe, convert to numpy array\n",
    "y[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e98a44-9d8f-48b3-a14b-17abec8fd1b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE 2.1.1: Using Scikit-learn, split the data in a 80% training and a 20% test set. Fit a logistic regression model and evaluate training and testing accuracy. </b>\n",
    "</div>\n",
    "\n",
    "Use [this method](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for train-test splitting and [this implementation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to perform logistic regression. Accuracy can be computed by using the score() method of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487cb9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea370b71-a7a2-4825-a626-b995c6e407b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE 2.1.2: Now do the same with LDA. Do you split your dataset again in a new random training and testing split? Think about fair evaluation/comparison between the two models.</b>\n",
    "</div>\n",
    "\n",
    "Use [this implementation](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429fc4f-7b70-44c4-a314-7a690e1f82e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a65d05-4aa3-4174-b676-f536db0ce761",
   "metadata": {},
   "source": [
    "Depending on your data split, LDA or LR will perform better. The model that we prefer is hence determined by a random data split. One way to avoid this is to perform [cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/), we will return on this topic later in the course.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE 2.1.3</b>: **Use your preferred (LDA or LR) model to predict the class probabilities $Pr(y|\\mathbf{x})$ and the classes for the training data. Use the _predict_proba()_ function to generate the predicted probabilities and the _predict()_ function to generate the predicted classes. Take note of the output shape of _predict_proba()_. What do the columns mean? Use the code below to plot the two against each other. Which data points are most likely to be misclassified?**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2fa93-d53e-4ef0-8e82-c267166a0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_probabilities = \"...\"\n",
    "predicted_classes = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8c46f-a997-4ad2-bca2-f2a2c194108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "misclassified = predicted_classes !=  y_train\n",
    "\n",
    "colors = ['#b2182b' if wrong else '#2166ac' for wrong in misclassified ]\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "test_jitter = np.random.normal(scale=0.1, size=len(predicted_class_probabilities))\n",
    "ax.scatter(test_jitter, predicted_class_probabilities,\n",
    "           marker='.', s=25, color=colors, alpha=0.75)\n",
    "ax.get_xaxis().set_ticks([]);\n",
    "ax.set_ylabel('Predicted class probabilies').set_fontsize(20)\n",
    "ax.set_title('Correctly classified samples in blue', size=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8c24b-3ddb-46f2-af34-86638ae6681e",
   "metadata": {},
   "source": [
    "Clearly, the misclassified points are those points where the predicted probability of class membership is rather close to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff0d95-b9ce-4202-9990-3f43d982d3ce",
   "metadata": {},
   "source": [
    "### 2.2. Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74e505-4b14-42bf-97f4-9cbdf2d8acb4",
   "metadata": {},
   "source": [
    "Some classifiers inherently support multi-class classification as part of their design, for example, in LDA, the class-conditional density $Pr(\\mathbf{x}|y)$ is modeled for every class $y$ and can be converted to predictions using Bayes' rule. For logistic regression, a natural extension to the multi-class case is [multinomial logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression). Check out the [Scikit-learn page on multi-class prediction](https://scikit-learn.org/stable/modules/multiclass.html) for more information. In principle, any classifier can be made multi-class using following methods:\n",
    "\n",
    "#### One-versus-one classification\n",
    "\n",
    "One-versus-one classification is another approach to a multi-class classification problem. For a K-class problem, the strategy consists of training $\\frac{K(K-1)}{2}$ classifiers. Each of these classifiers must learn to distinguish two classes. Once the classifiers are trained, a voting scheme is applied to make a prediction for an unseen data point: each classifier has to decide between two possible classes. The final predicted class is that class that gets the largest number of votes. \n",
    "\n",
    "#### One-versus-all classification\n",
    "\n",
    "In one-versus-all (OvA) classification (also called one-versus-rest), a single classifier is trained per class, with the samples of that class as positive samples and all other samples as negatives. The strategy proceeds as follows for a K-class classification problem:\n",
    "\n",
    "**Inputs:**\n",
    "* a classification algorithm L (learner)\n",
    "* feature matrix $\\mathbf{X}$\n",
    "* label vector $\\mathbf{y}$ where $y_i \\in \\{1,...,K\\}$\n",
    "\n",
    "\n",
    "**Procedure:**\n",
    "for each $k$ in $\\{1,...,K\\}$:\n",
    "* construct a new label vector $\\mathbf{z}$ where $z_i$ is 1 if $y_i = k$ and 0 otherwise\n",
    "* train L on $\\mathbf{X}$ to obtain a classifier $f_k$. The classifier should return class probabilities and not hard labels.\n",
    "\n",
    "**Returns:**\n",
    "A list of trained classifiers $f_k$ for each $k$ in $\\{1,...,K\\}$\n",
    "\n",
    "To make predictions for a new sample $\\mathbf{x}$, the $k$ classifiers are applied to $\\mathbf{x}$ and the final predicted label is the label that is predicted with the highest confidence (probability):\n",
    "\n",
    "$\\hat{y} = \\underset{k \\in \\{1,...,K\\}}{\\mathrm{argmax}} \\, f_k(\\mathbf{x})$\n",
    "\n",
    "Let's simulate a toy dataset with three classes and two features, and split it in training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb57c6-a91d-445e-a107-440e68c180a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers= [[-2.5, 0], [0, 1], [3.5, -1]], random_state=42)\n",
    "\n",
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306093e-50fc-45e2-93bb-50a224436eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "colors=['#66c2a5', '#fc8d62', '#8da0cb']\n",
    "for i, color in enumerate(colors):\n",
    "    idx_train = np.where(y_train==i)\n",
    "    idx_test = np.where(y_test==i)\n",
    "    plt.scatter(X_train[idx_train,0], X_train[idx_train,1], c=color, edgecolor='black', s=30)\n",
    "    plt.scatter(X_test[idx_test,0], X_test[idx_test, 1],c='white', edgecolor=color, s=70)\n",
    "    \n",
    "ax.legend(['Class 1 - train',\n",
    "           'Class 1 - test',\n",
    "           'Class 2 - train',\n",
    "           'Class 2 - test',\n",
    "           'Class 3 - train',\n",
    "           'Class 3 - test']);\n",
    "\n",
    "ax.set_xlabel('Feature 1');\n",
    "ax.set_ylabel('Feature 2');\n",
    "ax.set_title('Toy dataset for multiclass classification').set_fontsize(20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df44bb7-77de-45df-b4af-1a8d0496bec2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>EXERCISE 2.2.1: Look again at the documentation of LDA and Logistic Regression. What options do you need to specify to train these models on a multi-class problem? Train a model on this toy dataset</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f94238-9c1d-4b00-89c4-eb9c809dc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model ...\n",
    "\n",
    "# fit ...\n",
    "\n",
    "predicted_classes = \"...\"\n",
    "\n",
    "classification_accuracy = np.round(np.mean(y_test == predicted_classes)*100,2)\n",
    "\n",
    "# Visualize the predictions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "colors=['#66c2a5', '#fc8d62', '#8da0cb']\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    idx_train = np.where(y_train==i)\n",
    "    idx_test = np.where(y_test==i)\n",
    "    \n",
    "    plt.scatter(X_train[idx_train,0], X_train[idx_train,1], c=color, edgecolor='black', s=30)\n",
    "    plt.scatter(X_test[idx_test,0], X_test[idx_test, 1],c='white', edgecolor=color, s=70)\n",
    "        \n",
    "ax.legend(['Class 1 - train',\n",
    "           'Class 1 - test',\n",
    "           'Class 2 - train',\n",
    "           'Class 2 - test',\n",
    "           'Class 3 - train',\n",
    "           'Class 3 - test']);\n",
    "\n",
    "# add predictions\n",
    "for i, color in enumerate(colors):\n",
    "    idx_predicted = np.where(predicted_classes==i)\n",
    "    plt.scatter(X_test[idx_predicted,0], X_test[idx_predicted,1], c=color, marker='s', s=2)\n",
    "\n",
    "ax.set_xlabel('Feature 1');\n",
    "ax.set_ylabel('Feature 2');\n",
    "ax.set_title('Toy dataset for multiclass classification - classification accuracy: {}%'.format(classification_accuracy)).set_fontsize(20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb1559-d45e-4f22-bf89-208c875360f0",
   "metadata": {},
   "source": [
    "### 2.3. OPTIONAL: Data preprocessing for text inputs (example with DNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5c0db-3741-4312-9436-d37586de15cc",
   "metadata": {},
   "source": [
    "Since machine learning models expect numbers as inputs, not words, we need to do some preprocessing first to make textual data compatible with ML models. A very common feature representation for text sequences is called the **Bag of Words**. It consists of listing all the possible tokens that might occur in your text. A token might be one word, or a combination of two or multiple words. The feature representation is then a matrix with the count of the tokens for each text instance. The simplest transformation is to just look at the counts of individual tokens: the 1-grams. However, it might be interesting to count combinations of two or more words as well. Consider the following example, where we have 2 example input sample sentences:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2687a32-aa48-47ac-85e8-d9ca871edc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = ['this is real life',\n",
    "       'is this real life']\n",
    "print('data:\\n', data[0], '\\n', data[1])\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\n",
    "\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print('vocabulary:\\n', analyze(data[0]))\n",
    "      \n",
    "features = vectorizer.fit_transform(data)\n",
    "print('final feature representation:\\n', features.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76defec4-5339-47e5-8f90-eee4e7a88d57",
   "metadata": {},
   "source": [
    "Note that by default, the vectorizer returns the features as a sparse array: in most applications, each row of the feature matrix will contain a lot of zeros. For this exercise, you can convert it to a regular numpy array with the ```toarray()``` method.\n",
    "\n",
    "If we restrict ourselves to 1-grams, both sentences above are transformed into the exact same feature representation. However, suppose we want to do sentiment analysis and classify whether a sentence contains a question or not. Then it might be useful to look at bigrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77830cc6-1c26-435b-a975-64c612dc6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,1))\n",
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(data[0])\n",
    "features = vectorizer.fit_transform(data)\n",
    "print('Only 1-grams:')\n",
    "print('final feature representation:\\n', features.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0603f-e6a3-42cc-9890-3e9e55406309",
   "metadata": {},
   "source": [
    "When we consider bigrams, the feature representation for both sentences is no longer exactly the same. Maybe the features that represent 'this is' and 'is this' could be helpful here.\n",
    "\n",
    "Still the bag-of-words features completely ignores where every n-gram was in the sentence. A possible way to take positional information into account is to assign $v$ dummy features for every location in the sentence, with $v$ being the vocabulary size (number of possible different words). This is called [one-hot encoding](https://en.wikipedia.org/wiki/One-hot#Natural_language_processing) and requires the sentences to be all of the same length, for example, 4 words as in the 2 sentences above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f472098-d002-4d8e-8242-2a6f76819d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splitwords = [sentence.split(' ') for sentence in data]\n",
    "print('data splitted by words:')\n",
    "print(data_splitwords)\n",
    "vocab = list(set([word for sentence in data_splitwords for word in sentence]))\n",
    "print('vocabulary:')\n",
    "print(vocab)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore',\n",
    "                    categories=[vocab]*len(data_splitwords[0]))\n",
    "\n",
    "features = enc.fit_transform(data_splitwords)\n",
    "print('resulting feature representation:')\n",
    "print(features.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da97a-e5b5-4361-8220-93587b8b4f11",
   "metadata": {},
   "source": [
    "If it is not immediately clear what the features mean in this example: the first four features represent which word is the first word in each sentence. The first and sentence has as first word 'this', this is the last word in the vocabulary, so of the first four features, the last is given by $1$. The second sentence has 'is' as the first word, which is the second word in the vocabulary, for this reason, the second column of the first four features is given by $1$ for this sentence. Both sentences have the same last two words 'real life', it can be seen that the last 8 features for both sentences are identical.\n",
    "\n",
    "Armed with these encoding schemes, we can tackle a real problem. **DNA sequences** as inputs are peculiar because they are essentially text: following an alphabet containing only A, T, C or G. We will use data from a published [study](https://bmcbiol.biomedcentral.com/articles/10.1186/1741-7007-12-4) about sigma factors in E. coli. Some biological background information for those interested:\n",
    "\n",
    "> The binding region of the transcription unit,  commonly called the promoter region, is known to play a key role  in the transcription rate of downstream genes. In Eubacteria, the sigma factor ($\\sigma$) binds with the RNA  polymerase subunit ($\\alpha\\beta\\beta'\\omega$) to create RNA polymerase. Being part of the RNA polymerase holoenzyme, the sigma element acts as the connection between RNA polymerase and DNA. Depending on the sigma factor bound to the transcription unit, different binding regions of the enzyme with the DNA are observed. The data represents specific DNA regions of the *E. coli* genome to which one or more sigma factors bind.\n",
    "\n",
    "In less-biological-jargon words: certain molecules called sigma factors control activity of genes, they do so by binding to the DNA close to the gene. If we can predict for an input DNA sequence if such a molecule will bind, we gain an understanding in the biological function of those genes and molecules.\n",
    "\n",
    "The dataset contains 4724 DNA sequences. For each sequence, we have information on five target variables, each representing 5 sigma factors. Each time, the outcome is binary, indicating whether the sigma factor binds to the sequence or not. This is a **multi-label** problem, where an input can belong to any (multiple at once) of the classes, as opposed to only one possible class for each sample in multi-class. For simplicity in this exercise, we will focus only on one class: RPOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e920919-d888-41f4-a55a-486938fe3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tfmortie/mlmust/main/04_linear_classification/promotor_list_exp_growth.csv\n",
    "promotor_data = pd.read_csv('./promotor_list_exp_growth.csv', index_col=0)\n",
    "promotor_data.head(20)\n",
    "\n",
    "X = np.array(promotor_data.PROBE_SEQUENCE)\n",
    "y = promotor_data['RPOD'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b816f3c3-2965-4997-a655-0e77b4971e02",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b> EXERCISE: \n",
    "Use one of the encoding schemes to preprocess the DNA data. Construct a model and evaluate performance on the test set. Play around with different preprocessing values, and keep testing performances. What types of preprocessing lead to good performance for this dataset? In what cases are we overfitting? Think about fair evaluation: if we keep testing out configurations and evaluating on the test set, is our final test performance estimate fair? We can solve this by keeping an additional data split separate: training, validation and testing. Then we test different hyperparameters (different ways of preprocessing) on the validation set. We don't touch the test set until we have our final model. This is the only fair way of evaluating. For more information, see this [link](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets).</b>\n",
    "</div></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c1b6d7-d837-48ba-b3af-41e85990e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder\n",
    "\n",
    "# fit and transform data with encoder\n",
    "\n",
    "# instantiate modle\n",
    "\n",
    "# fit model\n",
    "\n",
    "# evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('predmod')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "79f7229f32224f2aa3b7ff71071c711311f5fb22ad26e5b83f3cb875eb6ce551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
