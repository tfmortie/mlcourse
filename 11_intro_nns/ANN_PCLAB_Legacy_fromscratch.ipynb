{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC lab 10: Artificial Neural Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neural_nets_art.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although artificial neural networks enjoy a lot of progress today, they were first described by [Warren McCulloch and Walter Pitts](https://link.springer.com/article/10.1007%2FBF02478259) in 1943. Early progress in training competitive neural networks was stalled by a multitude of reasons, such as the limited computer resources, sub-optimal network architectures and the use of smaller datasets. In this PC-lab we will implement a custom neural network on a step-by-step basis, allowing an in-depth comprehension of the essential elements of deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core unit of every (artificial) neural network is considered the neuron. The neuron can be observed as a switch. It receives **one or more inputs** $\\mathbf{x}$, processes a **weighted sum** $z$ (adding **bias** $b$) that is sent through the **sigmoid activation function $\\sigma()$**, outputing a **single response**  $a$:\n",
    "\n",
    "$$ \n",
    "z = \\sum\\limits_{i=1}^{n}(w_ix_i) + b = \\sum\\limits_{i=0}^{n}(w_ix_i)$$ with $$ x_0 = 1 \\tag{1}\\\\\n",
    "$$\n",
    "\n",
    "$$ a = \\sigma(z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/neuron_bishop.jpg\" style=\"width:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default recommended activation function is the **Rectified Linear Unit**, or **ReLU**. \n",
    "\n",
    "$$ ReLU(z) = max\\{0,z\\} $$\n",
    "\n",
    "<img src=\"img/relu.png\" style=\"width:30%\">\n",
    "\n",
    "The ReLU function has many properties that make optimization easy using gradient-based methods. It can be seen as a switch giving no response for $z < 0$ and giving a response $z$ for $z > 0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic artificial neural network is the **feedforward neural network**. There are no feedback connections such as can be found in **recurrent neural networks**. A feedforward neural network is called a network as it is composed out of many inheriting functions making up the model, e.g. $f(\\textbf{x})= f^{(3)}(f^{(2)}(f^{(1)}(\\textbf{x})))$. Neural networks typically are constructed in different layers of neurons in which every neuron is connected with all the neurons of the previous layer, eventually resulting in a set of **output neurons** $\\mathbf{\\hat{\\textbf{y}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nn_bishop_adapted.png\" style=\"width:70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the network, samples are processed in batches. This allows for faster training and improved convergence of the loss during gradient descent. Advantages of stochastic gradient descent or other optimization algorithms for loss calculation are not discussed in this PC-lab, but have been [extensively discussed](https://ruder.io/optimizing-gradient-descent/) before.\n",
    "Practically, the first fully-connected layer of the network using batch size $B$ is computed by matrix combination of the input $X \\in \\mathbb{R}^{B, D}$ with a set of weights $W^{(12)} \\in \\mathbb{R}^{D, M}$.\n",
    "\n",
    "\\begin{equation}\n",
    "XW^{(12)} =\n",
    "\\begin{bmatrix}\n",
    "1 & x_{0,1} & ...  & x_{0,D-1} & x_{0,D} \\\\\n",
    "1 & x_{1,1} & ... & x_{1,D-1} & x_{1,D} \\\\\n",
    "... & ... & ... & ... & ...\\\\\n",
    "1 & x_{B-1,1} & ... & x_{B-1,D-1} & x_{B-1,D} \\\\\n",
    "1 & x_{B,1} & ...  & x_{B,D-1} & x_{B,D} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "W_{0,0} & W_{0,1} & ...  & W_{0,M-1} & W_{0,M} \\\\\n",
    "W_{1,0} & W_{1,1} & ... & W_{1,M-1} & W_{1,M} \\\\\n",
    "... & ... & ... & ... & ...\\\\\n",
    "W_{D-1,0} & W_{D-1,1} & ... & W_{D-1,M-1} & W_{D-1,M} \\\\\n",
    "W_{D,0} & W_{D,1} & ...  & W_{D,M-1} & W_{D,M} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h2>Structure of the exercise</h2>\n",
    "    <p>The idea of this PC-Lab will be to construct our very own neural network from scratch. Every exercize will introduce a new feature necessary to train a working model.</p>\n",
    "    <p>We define the class <code>Neural_Network</code> for which the structural architecture is given at initialization. Let's start by creating a neural network with one hidden layer. To include the bias term, we add a scalar to the weights vector for every layer.</p> \n",
    "    \n",
    "<code>\n",
    "    class Neural_Network(object):\n",
    "    def __init__(self, input_nodes, output_nodes, hlayer_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.hlayer_nodes = hlayer_nodes\n",
    "        # initialize weights + bias in the first layer\n",
    "        self.W_12 = np.random.randn(self.input_nodes+1, self.hlayer_nodes)) \n",
    "        # initialize weights + bias in the second layer\n",
    "        self.W_23 = append(np.random.randn(self.hlayer_nodes+1, self.output_nodes))\n",
    "</code>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<h3>EXERCISE</h3> <p><b>Complete</b> the attribute function <code>Neural_Net.forward()</code> and <code>Neural_Net.relu()</code></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data| (batch_size, input_nodes) |\n",
    "|y|$$y$$|label| (batch_size, output_nodes) |\n",
    "|y_hat| $$\\hat{y}$$| Output Data | (batch_size, output_nodes) |\n",
    "|W_12 | $$W^{(12)}$$ | Layer 1 weights | (input_nodes + 1, hlayer_nodes) |\n",
    "|W_23 | $$W^{(23)}$$ | Layer 2 weights | (hlayer_nodes + 1, output_nodes) |\n",
    "|a_1 | $$a^{(1)}$$ | Layer 1 activity (inputs) | (batch_size, input_nodes + 1) |\n",
    "|z_2 | $$z^{(2)}$$ | Layer 2 linear combination | (batch_size, hlayer_nodes) |\n",
    "|a_2 | $$a^{(2)}$$ | Layer 2 activity | (batch_size, hlayer_nodes + 1) |\n",
    "| y_hat | $\\hat{y}$ | Layer 3 linear combination | (batch_size, output_nodes) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{z}^{(2)} = \\textbf{a}^{(1)}\\textbf{W}^{(12)}  \\tag{2}\\\\\n",
    "$$\n",
    "$$\n",
    "\\textbf{a}^{(2)} = ReLU(\\textbf{z}^{(2)}) \\tag{3}\\\\\n",
    "$$\n",
    "$$\n",
    "\\hat{\\textbf{y}} = \\textbf{a}^{(2)}\\textbf{W}^{(23)} \\tag{4}\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self, input_nodes, output_nodes, hlayer_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.hlayer_nodes = hlayer_nodes\n",
    "        \n",
    "        # initialize weights + bias in the first layer\n",
    "        self.W_12 = np.random.randn(self.input_nodes+1, self.hlayer_nodes)\n",
    "        # initialize weights + bias in the second layer\n",
    "        self.W_23 = np.random.randn(self.hlayer_nodes+1, self.output_nodes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # add bias to input samples\n",
    "        self.a_1 = np.hstack((np.ones((len(X),1)), X))\n",
    "        \n",
    "        self.z_2 = \"\"\"...\"\"\"\n",
    "        self.a_2 = \"\"\"...\"\"\"\n",
    "        self.y_hat = \"\"\"...\"\"\"\n",
    "        \n",
    "        \n",
    "        return np.clip(self.y_hat, -10e6, 10e6)\n",
    "    \n",
    "    def relu(self, z):\n",
    "        \"\"\"...\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.10183529],\n",
       "       [2.37793415]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "# Initialize neural network with 1 input, 1 output and 2 nodes in hidden layer\n",
    "NN = Neural_Network(1,1,3)\n",
    "# Input two samples, each with one input\n",
    "NN.forward([[2],[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a dataset that follows the function $\\mathbf{y = sin(x)}$. To train the neural network we have to evaluate how the prediction $\\hat{y}$ compares to the true label $y$. This is done through the loss function $L$. The formula used for L is dependent upon the problem we are trying to solve. In line with previous methods fitting a **regression** problem, we consider the **MSE** :\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{n}\\sum_{i=1}^{n}{(y_i-\\hat{y_i})^2}\\tag{6}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efbbde50860>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def squared_error(y, y_hat):\n",
    "    return (y-y_hat)**2\n",
    "\n",
    "X = np.random.uniform(-3, 3, size=(1000,1)) # sample random points for x=[0, pi]\n",
    "y = -26*X + 145*X**2 + 28*X**3 - 26*X**4 - 2*X**5 + X**6 - 80\n",
    "#y = np.sum(np.sin(X),axis=1).reshape(-1,1) # sinus transform\n",
    "NN = Neural_Network(1,1,40)\n",
    "y_hat = NN.forward(X) # predict values\n",
    "loss = squared_error(y, y_hat)\n",
    "\n",
    "fig, (ax_1, ax_2, ax_3) = plt.subplots(1,3, figsize=(15,4))\n",
    "ax_1.set_title(\"sample data\")\n",
    "ax_1.scatter(X, y)\n",
    "ax_2.set_title(\"predictions on sample data\")\n",
    "ax_2.scatter(X, y_hat)\n",
    "ax_3.set_title(\"loss function at each sample\")\n",
    "ax_3.scatter(X, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we must find a set of weights that minimizes the overall loss function. An exhaustive method would be to try all possible combinations of weights, a solution that blows up with increasing dimensionality. In order to reduce processing times to obtain the optimal set of weights, we evaluate the influence of each weight on the loss function. If we consider the different equations to obtain our loss: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{z}^{(2)} = \\textbf{a}^{(1)}\\textbf{W}^{(12)} \\tag{2}\\\\\n",
    "$$\n",
    "$$\n",
    "\\textbf{a}^{(2)} = ReLU(\\textbf{z}^{(2)}) \\tag{3}\\\\\n",
    "$$\n",
    "$$\n",
    "\\hat{\\textbf{y}} = \\textbf{a}^{(2)}\\textbf{W}^{(23)} \\tag{4}\\\\\n",
    "$$\n",
    "$$\n",
    "L = \\frac{1}{n} \\sum_{i=0}^{n}{(y_{i}-\\hat{y_{i}})^2} \\tag{6}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the influence of $W^{(23)}$ on the loss $L$, we can find the **partial derivative** of the loss in function of $W^{(23)}$. Using the **chain rule**, this can be calculated using a step-by-step approach.\n",
    "$$ \\frac{\\delta L}{\\delta W^{(23)}} = \\frac{\\delta \\textbf{L}}{\\delta \\hat{\\textbf{y}}} \\cdot \\frac{\\delta \\hat{\\textbf{y}}}{\\delta \\textbf{W}^{(23)}} = \\delta_{1} \\cdot \\frac{\\delta \\hat{\\textbf{y}}}{\\delta \\textbf{W}^{(23)}}  \\tag{7}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is the step-by-step evaluation of the partial derivatives of the loss in function of the network weights, performed by backward iteration over the different transformations performed by the network. The values obtained when iterating down from the loss function are recyclable when calculating the derivative of weights further down in the chain rule, making **a substantial difference** in the amount of processing power needed to obtain all derivatives. The use of backpropagation is a major element in making training of deep neural networks possible. For example, to obtain the derivatives of the weights in the first layer ($\\textbf{W}^{(12)}$) we apply:\n",
    "\n",
    "$$ \\frac{\\delta L}{\\delta W^{(12)}} = \\delta_{1} \\cdot \\frac{\\delta \\hat{\\textbf{y}}}{\\delta \\textbf{a}^{(2)}} \\cdot \\frac{\\delta \\textbf{a}^{(2)}}{\\delta \\textbf{z}^{(2)}} \\cdot \\frac{\\delta \\textbf{z}^{(2)}}{\\delta \\textbf{W}^{(12)}} = \\delta_{2} \\cdot \\frac{\\delta \\textbf{z}^{(2)}}{\\delta \\textbf{W}^{(12)}} \\tag{8} $$\n",
    "\n",
    "\n",
    "$\\delta_{1}$ and $\\delta_{2}$ are solely introduced as variables to which the intermediate values can be assigned. Using these variables when implementing backpropagation into the neural network will make things easier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE:</b> \n",
    "<p><b>Write out</b> the following partial derivatives as found in the chain rule.</p>\n",
    "\n",
    "$$\\frac{\\delta L}{\\delta \\hat{y}}$$\n",
    "<hr>\n",
    "$$\\frac{\\delta \\hat{y}}{\\delta W^{(23)}}$$\n",
    "<hr>\n",
    "$$\\frac{\\delta \\hat{y}}{\\delta a^{(2)}}$$\n",
    "<hr>\n",
    "$$\\frac{\\delta a^{(2)}}{\\delta z^{(2)}}$$\n",
    "<hr>\n",
    "$$\\frac{\\delta z^{(2)}}{\\delta W^{(12)}}$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<h3>EXERCISE</h3>\n",
    "<p><b>Complete</b> the attribute functions <code>NN.backpropagate()</code> and <code>NN.relu_prime()</code>, and the function <code>loss_prime</code>. Use the partial derivatives of the previous exercise to get an overview of the sequential steps executed in backpropagation.</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with solution of NN here\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, input_nodes, output_nodes, hlayer_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.hlayer_nodes = hlayer_nodes\n",
    "        \n",
    "        # initialize weights + bias in the first layer\n",
    "        self.W_12 = np.random.randn(self.input_nodes+1, self.hlayer_nodes)\n",
    "        # initialize weights + bias in the second layer\n",
    "        self.W_23 = np.random.randn(self.hlayer_nodes+1, self.output_nodes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # add bias to input samples\n",
    "        self.a_1 = np.hstack((np.ones((len(X),1)), X))\n",
    "        \n",
    "        \"\"\"...\"\"\"\n",
    "        \n",
    "        return np.clip(self.y_hat, -10e6, 10e6)\n",
    "    \n",
    "    def relu(self, z):\n",
    "        \n",
    "        \"\"\"...\"\"\"\n",
    "\n",
    "    def relu_prime(self, z):\n",
    "\n",
    "        \"\"\"...\"\"\"\n",
    "\n",
    "    def backpropagate(self, X, y, get_loss_prime):\n",
    "        self.y_hat = \"\"\"...\"\"\"\n",
    "        \n",
    "        self.delta_1 = \"\"\"...\"\"\"\n",
    "        self.dLdW_23 = \"\"\"...\"\"\"\n",
    "        self.dLda_2 = \"\"\"...\"\"\"\n",
    "        self.delta_2 = \"\"\"...\"\"\"\n",
    "        self.dLdW_12 = \"\"\"...\"\"\"\n",
    "\n",
    "        # join two flattened arrays in one vector\n",
    "        return np.concatenate((self.dLdW_12.ravel(), self.dLdW_23.ravel())) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-101-460f4000b56d>(36)backpropagate()\n",
      "-> self.y_hat = self.forward(X)\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  387.7926547 , -1248.30602047, -1414.45232628,  3539.78947657,\n",
       "         448.10403971,  1591.13799986,  1318.43267606])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_prime(y_hat, y): \n",
    "    \"\"\"...\"\"\" # Cost function over all batches, divided by # batches\n",
    "\n",
    "np.random.seed(1)\n",
    "NN = Neural_Network(1,1,2)\n",
    "NN.backpropagate(X[:2], y[:2], get_loss_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE:</b> \n",
    "<p><b>Evaluate</b> the values and shapes of <i>dLdW_12</i> and <i>dLdW_23</i> separately, and compare the size of vectors. Can you differentiate the updates for weights from the updates for the biases? Can you predict the shapes of these values after changing the amount of nodes of the different layers within the neural network? Don't forget to run <code>NN.backpropagation()</code> with updated arguments when changing the hyperparameters of the network!</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dCdW_12:\n",
      " [[0. 0.]\n",
      " [0. 0.]]\n",
      "dCdW_23:\n",
      " [[-3.55219522]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network(1,1,2)\n",
    "NN.backpropagate([[1],[2]], [[np.sin(1)],[np.sin(2)]], get_loss_prime)\n",
    "print(\"dLdW_12:\\n {}\".format(NN.dLdW_12))\n",
    "print(\"dLdW_23:\\n {}\".format(NN.dLdW_23))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple neural network is close to completion now. One more important element is the ability to train this network. To adjust the weights based on the partial derivatives we need to apply the obtained gradient to perform an update to the actual weights. As we are dealing with a **non-convex** and **non-linear optimization problem**, updates are performed using the well-known **gradient descent** algorithm. Small variations on the gradient descent method have shown to drastically increase the speed at which deep neural networks can be trained (i.e. [momentum, adam, ...](http://ruder.io/optimizing-gradient-descent/index.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A brief recap: Gradient Descent\n",
    "\n",
    "\n",
    "\n",
    "$$W_{t+1} = W_{t} - \\eta \\nabla L(\\theta)$$\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "$\\eta$: learning rate (default: 1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**input** starting point $\\textbf{x}\\in$ **dom** $f$.\n",
    ">\n",
    ">**repeat** \n",
    ">\n",
    ">>    1. $\\Delta \\textbf{x} := -\\nabla f(\\textbf{x})$.\n",
    ">>    3. *Update*. $\\textbf{x}:=\\textbf{x}+\\eta\\Delta \\textbf{x}$.\n",
    ">\n",
    ">**until** stopping criterion is satisfied.\n",
    "\n",
    ">**output** $x$\n",
    "\n",
    "The stopping criterion is usually expressed as the amount of times the dataset is iterated. An **epoch** is one iteration over the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with solution of NN here\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, input_nodes, output_nodes, hlayer_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.hlayer_nodes = hlayer_nodes\n",
    "        \n",
    "        # initialize weights + bias in the first layer\n",
    "        self.W_12 = np.random.randn(self.input_nodes+1, self.hlayer_nodes)\n",
    "        # initialize weights + bias in the second layer\n",
    "        self.W_23 = np.random.randn(self.hlayer_nodes+1, self.output_nodes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # add bias to input samples\n",
    "        self.a_1 = np.hstack((np.ones((len(X),1)), X))\n",
    "        \n",
    "        \"\"\"...\"\"\"\n",
    "        \n",
    "        return np.clip(self.y_hat, -10e6, 10e6)\n",
    "    \n",
    "    def relu(self, z):\n",
    "        \n",
    "        \"\"\"...\"\"\"\n",
    "\n",
    "    def relu_prime(self, z):\n",
    "\n",
    "        \"\"\"...\"\"\"\n",
    "\n",
    "    def backpropagate(self, X, y, get_loss_prime):\n",
    "        self.y_hat = \"\"\"...\"\"\"\n",
    "        \n",
    "        self.dLdW_23 = \"\"\"...\"\"\"\n",
    "        self.dLda_2 = \"\"\"...\"\"\"\n",
    "        self.delta_2 = \"\"\"...\"\"\"\n",
    "        self.dLdW_12 = \"\"\"...\"\"\"\n",
    "\n",
    "        # join two flattened arrays in one vector\n",
    "        return np.concatenate((self.dLdW_12.ravel(), self.dLdW_23.ravel())) \n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        self.W_12 = weights[:len(self.W_12.ravel())].reshape(self.W_12.shape)\n",
    "        self.W_23 = weights[len(self.W_12.ravel()):].reshape(self.W_23.shape)\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return np.concatenate((self.W_12.ravel(), self.W_23.ravel()))\n",
    "    \n",
    "    def compile(self, optimizer_f, loss_f, loss_prime_f):\n",
    "        self.optimizer =  optimizer_f\n",
    "        self.get_loss = loss_f\n",
    "        self.get_loss_prime = loss_prime_f\n",
    "        \n",
    "    def fit(self, X, y, batch_size=8, epochs=50, eta=1e-5):\n",
    "        epoch = 0   # set starting epoch\n",
    "        pool = np.arange(len(X)//batch_size)   # setup batch pool\n",
    "        avg_loss_all = []   # initialize loss vector\n",
    "        while epoch<epochs:\n",
    "            print(\"\\repoch: {}\".format(epoch), end=\"\")\n",
    "            epoch +=1\n",
    "            # shuffle X, y\n",
    "            X_scrambled, y_scrambled = shuffle(X,y) \n",
    "            avg_loss = 0\n",
    "            for i in shuffle(pool):   # select random batch\n",
    "                # select batch data\n",
    "                X_batch = X_scrambled[i*batch_size:(i+1)*batch_size]   \n",
    "                y_batch = y_scrambled[i*batch_size:(i+1)*batch_size]\n",
    "                # get prediction\n",
    "                y_hat = self.forward(X_batch)\n",
    "                # get loss on prediction\n",
    "                avg_loss += self.get_loss(y_hat, y_batch)\n",
    "                # get gradients on weights\n",
    "                dLdW = self.backpropagate(X_batch, y_batch, self.get_loss_prime)\n",
    "                # get update values with weight gradients\n",
    "                dLdW_update = self.optimizer(dLdW, eta)\n",
    "                self.set_weights(self.get_weights()+dLdW_update)   # set new weights with update values\n",
    "            avg_loss_all.append(avg_loss)\n",
    "            \n",
    "        return avg_loss_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<h3>EXERCISE</h3> \n",
    "    <p><b>Complete</b> the function <code>gradient_descent()</code>. The different steps as explained above have already been partially implemented in the <code>Neural_Network.fit()</code> function, make sure to analyze it before completing the code for the <code>gradient_descent</code> function. <code>gradient_descent</code> is one way to optimize your weights given a loss, and is stored in <code>Neural_Network.optimizer</code> when running <code>Neural_Network.compile()</code></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(y_hat, y):\n",
    "    return \"\"\"...\"\"\"\n",
    "\n",
    "def MSE_loss_prime(y_hat, y):\n",
    "    return \"\"\"...\"\"\"\n",
    "\n",
    "def gradient_descent(dLdW, eta):\n",
    "    return \"\"\"...\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<h3>EXERCISE</h3> \n",
    "    <p><b>Run</b> the code below and <b>evaluate</b> how the network trains when tweaking with specific functions such as the amount of hidden nodes, epochs and step size of the gradient update.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "NN = Neural_Network(1,1,320)\n",
    "NN.compile(gradient_descent, MSE_loss, MSE_loss_prime)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "ax_1, ax_2, ax_3, ax_4 = ax.ravel()\n",
    "ax_1.scatter(X , NN.forward(X))\n",
    "ax_1.set_title(\"Predicted y values BEFORE GD\")\n",
    "loss = NN.fit(X, y, epochs=200, batch_size=5, eta=1e-5)\n",
    "ax_2.scatter(X, NN.forward(X))\n",
    "ax_2.set_title(\"Predicted y values AFTER GD\")\n",
    "ax_3.scatter(X,y)\n",
    "ax_3.set_title(\"True y values\")\n",
    "ax_4.set_title(\"Loss function throughout training\")\n",
    "ax_4.plot(range(len(loss)),loss, 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<h3>Optional EXERCISE</h3> \n",
    "    <p>Tweak the network to allow for classification purposes. For this, a sigmoid layer has to be added as the final step in\n",
    "    <code>NN.forward()</code>. Make sure to adjust the backpropagate step and the loss function accordingly.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "145.083px",
    "left": "1614px",
    "right": "20px",
    "top": "182px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
