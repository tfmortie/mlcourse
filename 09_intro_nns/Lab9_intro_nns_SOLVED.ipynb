{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjxvlCzY6h4t"
      },
      "source": [
        "<img src='https://analyticsindiamag.com/wp-content/uploads/2022/04/Screenshot-2022-04-06-at-9.55.11-PM.png' width=750>\n",
        "\n",
        "*Images generated by a deep neural network that interprets text to generate images (DALL·E 2)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xqzgGkp6Z0a"
      },
      "source": [
        "# PC Lab 9: Introduction to Neural Networks \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNEdF_h4-AmQ"
      },
      "source": [
        "Deep learning is the subfield of machine learning that concerns neural networks with representation learning capabilities. As of recent years, it is arguably the most quickly growing field within machine learning, enjoying major breakthroughs every year. Listing a couple ones from last year(s): ChatGPT, AlphaFold v2, DALL·E 2, AlphaZero. Although the popularity of neural nets is a recent phenomenon, they were first described by Warren McCulloch and Walter Pitts in 1943. Early progress in training competitive neural networks was stalled by a multitude of reasons, such as the limited computer resources, sub-optimal network architectures and the use of smaller datasets. In this PC-lab we will introduce you to the basics of implementing a neural network using contemporary practices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jqUbY3CO_fY"
      },
      "source": [
        "## 1. Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19SzILbZQkIL"
      },
      "source": [
        "### From linear models to neurons to neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CX3qibbPBs7"
      },
      "source": [
        "The core unit of every (artificial) neural network is considered the neuron. Every neuron can be observed as a linear combination of **one or more inputs** $\\mathbf{a}$ with weights $\\mathbf{w}$ (and optionally adding a **bias** $b$), outputting a **single output** $z$:\n",
        "\n",
        "$$z = \\sum\\limits_{i=1}^{n}(a_iw_i) + b,$$\n",
        "\n",
        "equivalently written as dot product:\n",
        "\n",
        "$$z = \\mathbf{a} \\cdot \\mathbf{w} + b.$$\n",
        "\n",
        "When multiple neurons are placed next to each other, we get multiple output neurons, this is called a **layer**. Mathematically, our weights and biases (intercepts) now become a matrix and vector respectively, and we obtain as output a vector $\\mathbf{z}$:\n",
        "\n",
        "$\\mathbf{z} = \\mathbf{a} \\cdot \\mathbf{W} + \\mathbf{b}.$\n",
        "\n",
        "Multiple **layers** can be stacked sequentially to make up a deep neural network. Performing this gives us a big linear model, because multiple matrix multiplications performed consecutively can also be written as just one: i.e. $\\mathbf{x} \\cdot \\mathbf{W_1} \\cdot \\mathbf{W_2} ...$ could also be written as just $\\mathbf{x} \\cdot \\mathbf{W_{all}}$. To obtain the *deep learning magic*, we need to make the whole thing **non-linear**. We do this by adding **activation functions** after every (hidden) layer. The most classical activation is the sigmoid activation $\\sigma()$, used also in logistic regression. Nowadays, we usually opt for a more simple activation function: the **ReLU** $\\texttt{ReLU}(z) = max(0,z)$. This function has the favorable property that its derivative is very efficient to compute (1 when $z$ is positive, 0 when it is negative). It also acts as a switch: a neuron will have a \"dead\" ($0$) activation whenever $z$ is negative.\n",
        "\n",
        "For the output layer of a neural network: our activation depends on the task at hand. For binary classification, we use sigmoid to constrain our output between 0 and 1. For multi-class, we use a softmax operation so the output of all neurons sums to 1. For regression, we simply do not use an activation or a custom one depending on your data: if you already know that your outputs can't be negative but can take all positive numbers ($\\mathbb{R}^+$), then maybe a ReLU activation in the output nodes makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o7g3tpiMXW4"
      },
      "source": [
        "In order to build more intuition for neural networks: consider the following figure where we \"visually build up\" a neural network starting from linear regression with four input features (**a**), to logistic regression (**b**), to an archetypical output neuron with ReLU activation (**c**). For multi-output settings, we visualize multi-output regression (**d**), multi-label classification (more than one class can be 1 in a sample) (**e**), and multi-class classification via softmax (**f**). Finally, a simple neural network with two hidden layers for binary classification (sigmoid output head) is shown under **g**.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/tfmortie/mlmust/main/09_intro_nns/lr2nn.png'>\n",
        "\n",
        "**This figure makes it crystal clear that the most simple neural network is just a bunch of linear regressions stacked on top of eachother with non-linearities in between.** More advanced neural network architectures exist that modify how we make information flow between inputs. In this example, everything is just connected to everything with linear weights. This type of neural network is what we call an **MLP** or a **multi-layer perceptron**.\n",
        "\n",
        "Depending on the type of output, different loss functions may be used:\n",
        "<img src='https://raw.githubusercontent.com/tfmortie/mlmust/main/09_intro_nns/lossfunctions.png' width=800>\n",
        "\n",
        "<!-- TEX CODE TO GENERATE THE ABOVE:\n",
        "\\begin{table}[]\n",
        "\\resizebox{1.00\\linewidth}{!}{\n",
        "\\begin{tabular}{llll}\n",
        "\\toprule\n",
        "\\textbf{Loss}    & \\textbf{Formula}     & \\textbf{Purpose}        & \\textbf{Domain} \\\\[1mm] \\midrule\n",
        "Squared loss & $\\mathcal{C}(y,~f(\\mathbf{x}))~=~(y-f(\\mathbf{x}))^2$ & Regression & $f(\\mathbf{x}) \\in \\mathbb{R}$ \\\\[2mm]\n",
        "Logistic loss & $\\mathcal{C}(y,~f(\\mathbf{x}))~= -y\\log(f(\\mathbf{x}))-(1-y)\\log(1-f(\\mathbf{x}))$ & Binary clf & $f(\\mathbf{x}) \\in [0,1]$ \\\\[2mm]\n",
        "Cross entropy & $\\mathcal{C}(\\mathbf{y},~\\mathbf{f}(\\mathbf{x}))~= - \\sum_{j=1}^k y_j\\log(f_j(\\mathbf{x})) $ & \\begin{tabular}[c]{@{}l@{}}Multi-class\\\\ classification\\end{tabular} & $\\mathbf{f}(\\mathbf{x}) \\in \\Delta^k$ \\\\[3.5mm]\n",
        "Multi-label logistic loss & $\\mathcal{C}(\\mathbf{y},~\\mathbf{f}(\\mathbf{x}))~= - \\sum_{j=1}^k(-y_j\\log(f_j(\\mathbf{x}))-(1-y_j)\\log(1-f_j(\\mathbf{x}))) $ & \\begin{tabular}[c]{@{}l@{}}Multi-label\\\\ classification\\end{tabular} & $\\mathbf{f}(\\mathbf{x}) \\in [0,1]^k$ \\\\[3.5mm]\n",
        "Multi-output squared loss & $\\mathcal{C}(\\mathbf{y},~\\mathbf{f}(\\mathbf{x}))~= - \\sum_{j=1}^k(y_j-f_j(\\mathbf{x}))^2 $ & \\begin{tabular}[c]{@{}l@{}}Multi-output\\\\ regression\\end{tabular} & $\\mathbf{f}(\\mathbf{x}) \\in \\mathbb{R}^k$ \\\\[2mm]\\bottomrule\n",
        "\\end{tabular}\n",
        "}\n",
        "\\end{table}\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-HCezsOMXXC"
      },
      "source": [
        "Keep in mind that all of the above methods usually fit a bias/intercept in addition to weights fitted on the input features.\n",
        "For an MLP, visually it would look like this:\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/tfmortie/mlmust/main/09_intro_nns/biases.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDxgf-POMXXM"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>THOUGHT EXERCISE:</b> **How much weights does the model pictured above have (including biases)?**\n",
        "</div>\n",
        "\n",
        "Keep in mind that every layer consists of (1) a matrix multiplication of an input $\\mathbf{A} \\in \\mathbb{R}^{N, D}$ with a set of weights $\\mathbf{W} \\in \\mathbb{R}^{D, M}$ and (2) a non-linearity. With $D$ the number of input features/dimensions/nodes (including one node/feature for the intercept, see the following equation) and $M$ the number of output dimensions/nodes.\n",
        "\\begin{equation}\n",
        "\\mathbf{A}\\mathbf{W} =\n",
        "\\begin{bmatrix}\n",
        "1 & x_{1,1} & ...  & x_{1,D-1} & x_{1,D} \\\\\n",
        "1 & x_{1,1} & ... & x_{1,D-1} & x_{1,D} \\\\\n",
        "... & ... & ... & ... & ...\\\\\n",
        "1 & x_{N-1,1} & ... & x_{N-1,D-1} & x_{N-1,D} \\\\\n",
        "1 & x_{N,1} & ...  & x_{N,D-1} & x_{N,D} \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "W_{1,1} & W_{1,1} & ...  & W_{1,M-1} & W_{1,M} \\\\\n",
        "W_{1,1} & W_{1,1} & ... & W_{1,M-1} & W_{1,M} \\\\\n",
        "... & ... & ... & ... & ...\\\\\n",
        "W_{D-1,1} & W_{D-1,1} & ... & W_{D-1,M-1} & W_{D-1,M} \\\\\n",
        "W_{D,1} & W_{D,1} & ...  & W_{D,M-1} & W_{D,M} \\\\\n",
        "\\end{bmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPIXHSNmo0gA"
      },
      "source": [
        "Written answer:\n",
        "The network goes from 4->3->2->1 neurons.\n",
        "\n",
        "The first layer has (4+1)\\*3 weights.\n",
        "The next (3+1)\\*2.\n",
        "The last (2+1)\\*1.\n",
        "In total: 15+8+3=26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we-9uaqpP-g6"
      },
      "source": [
        "The whole network is trained by first performing a forward pass to get predictions and to compute a loss w.r.t. ground-truth labels, then doing backpropagation (essentially applying the chain rule of derivatives) to obtain the gradient of all weights w.r.t. the loss. These gradients are then used by gradient descent (or more modern variants such as Adam) to optimize the neural network.\n",
        "\n",
        "Training neural networks is (typically) more computationally demanding than more traditional machine learning methods, and we usually use neural networks when we have large datasets. For these two reasons, it is not a good idea to process the whole dataset at once in every training step/iteration. Therefore, to train the network, we process samples in batches, called **(mini-batch) stochastic gradient descent**. This allows for faster training and improved convergence of the loss during gradient descent. Advantages of stochastic gradient descent or other optimization algorithms for loss calculation are not discussed in this PC-lab, but have been [extensively discussed](https://ruder.io/optimizing-gradient-descent/) before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1IGpzXZMXXk"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piqgXwstMXXq"
      },
      "source": [
        "Dropout is a popular addition to neural networks. It is a form of regularization during which we stochastically deactivate a percentage of neurons in every training step by putting their activation to zero. This regularization only happens during training, as during testing we (usually) want deterministic outputs. Conceptually, it is similar to other regularization techniques such as ridge regression and subsampling of features in random forest training, in the sense that it will force our model to look at all features, because sometimes one single feature will not be available during training. The difference here is that we do it by stochastically putting nodes to zero during training, and that we can perform it not only on our input features, but also on our hidden nodes.\n",
        "\n",
        "Mathematically, it can be performed by simply sampling a boolean vector and doing element-wise multiplication.\n",
        "\n",
        "Visually, it would look a bit like this, where nodes in cyan are dropped out, and the associated cyan weights do not have any influence on training anymore (in that training step):\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/tfmortie/mlmust/main/09_intro_nns/dropout.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG3LPfPU-8ky"
      },
      "source": [
        "## 2. PyTorch\n",
        "\n",
        "To implement neural networks with more ease, a few high-level Python libraries are available: PyTorch, TensorFlow/Keras, JAX, etc. In this lab, we will use [PyTorch](https://pytorch.org). PyTorch is the most popular library for deep learning in academia as of today. For this course it offers the advantage that it has the most 'pythonic' syntax, to the point where almost all NumPy functions have a PyTorch counterpart.\n",
        "\n",
        "If you want to run this notebook locally, you can find the installation instructions for PyTorch [here](https://pytorch.org/get-started/locally/). Make sure to select the right installation options depending on your system (if you have a GPU or not).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t1cmzGhe6kJK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKVm96u6BXev"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are the fundamental data structures in PyTorch. They are similar to NumPy arrays. The difference is that tensors can also run on GPU hardware. GPU hardware is optimized for many small computations. Matrix multiplications, the building blocks of all deep learning, run orders-of-magnitude faster on GPU than on CPU. Let's see how tensors are constructed and what we can do with them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJL-R3elBv9E",
        "outputId": "574c29ef-098c-4e40-a4f1-1ddf1c494bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[5, 8],\n",
            "        [9, 8]])\n",
            "[[5 8]\n",
            " [9 8]]\n"
          ]
        }
      ],
      "source": [
        "x = [[5,8],[9,8]]\n",
        "print(torch.tensor(x))\n",
        "print(np.array(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOjuB-_7B-er",
        "outputId": "f2b52643-7ab9-464a-d8b9-2066a83ed628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[5, 8],\n",
            "        [9, 8]])\n",
            "[[5 8]\n",
            " [9 8]]\n"
          ]
        }
      ],
      "source": [
        "x_numpy = np.array(x)\n",
        "print(torch.from_numpy(x_numpy))\n",
        "\n",
        "x_torch = torch.tensor(x)\n",
        "print(x_torch.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvQP_Y-HBEJt",
        "outputId": "d045a248-8db4-4db7-a994-20869d3b1353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8,)\n",
            "(8, 50)\n",
            "torch.Size([8])\n",
            "torch.Size([8, 50])\n"
          ]
        }
      ],
      "source": [
        "print(np.random.randn(8).shape)\n",
        "print(np.random.randn(8,50).shape)\n",
        "\n",
        "\n",
        "print(torch.randn(8).shape) # an alternative for .shape in PyTorch is .size()\n",
        "print(torch.randn(8,50).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grsQLtyKBGcq",
        "outputId": "2031c16d-fb55-442d-d027-fa54671a43ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 50)\n",
            "torch.Size([8, 50])\n"
          ]
        }
      ],
      "source": [
        "print(np.zeros((8,50)).shape)\n",
        "print(torch.zeros(8,50).shape) # works with 'ones' as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-T8i15DXD7"
      },
      "source": [
        "In PyTorch, the standard data type for floats is `float32`, which is synonymous to `float` within its framework. `float64` is synonymous to `double`.\n",
        "This is different from the NumPy defaults and naming conventions: NumPy default data type for float is `float64`. Keep this in mind when converting NumPy arrays to tensors and back!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e24OlYbC7nr",
        "outputId": "07d4e748-48fa-4327-de65-4913f2f12f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(np.zeros(8).dtype)\n",
        "print(torch.zeros(8).dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMr4OR05MXY6"
      },
      "source": [
        "Conversion of data types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFuID3EGDIea",
        "outputId": "bd43a6a9-b20e-48fd-cd1b-f5b8e5adb8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "torch.float64\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(8)\n",
        "print(x.dtype)\n",
        "x = x.to(torch.float64)\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOAtkL-D269"
      },
      "source": [
        "`torch.long` is synonymous to `torch.int64`. The only difference between int32 and int64 is the amount of bytes with which you will store every integer. If you go up to very high numbers, you will get numerical overflow faster with more compressed data types. We recommend you to always use the defaults: `torch.long` and `torch.float`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAeLblceDTBq",
        "outputId": "86015b22-00ac-4f05-9dbf-09a1e5c3e102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 6, 0, 0, 2, 7, 3, 1], dtype=torch.int32)\n",
            "torch.int32\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "x = torch.randint(low=0, high=8, size=(8,), dtype=torch.int32)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "x = x.to(torch.long)\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNm0VKLzEbxH"
      },
      "source": [
        "Indexing and other operations work similarly as for NumPy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWdkTEzXDtpq",
        "outputId": "652cb884-19a7-42c3-ee52-e87f7bb0f601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 50, 60])\n",
            "torch.Size([4, 30, 60])\n",
            "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000, -1.3001,  1.1683, -0.3288, -2.0775,  1.8150,  1.9130])\n",
            "tensor(-3.7731) tensor(3.9263) tensor(0.)\n",
            "tensor(-3.7731) tensor(3.9263) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(8,50,60)\n",
        "print(x.shape)\n",
        "print(x[:4,10:-10].shape)\n",
        "x[0,0,:10] = 0\n",
        "print(x[0,0,:16])\n",
        "\n",
        "print(torch.min(x), torch.max(x), torch.min(torch.abs(x)))\n",
        "# most of these functions are also tensor methods:\n",
        "print(x.min(), x.max(), x.abs().min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqK-1JtNMXZY"
      },
      "source": [
        "Joining tensors via concatenation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIZpsdFHEuTK",
        "outputId": "60694c90-fae7-406f-ccfe-c654842d76af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 50, 60])\n",
            "torch.Size([16, 50, 60])\n",
            "torch.Size([8, 150, 60])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "x_cat0 = torch.cat([x, x], dim=0)\n",
        "print(x_cat0.shape)\n",
        "x_cat1 = torch.cat([x, x, x], dim=1)\n",
        "print(x_cat1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPxk_yKfFgUi"
      },
      "source": [
        "Matrix multiplication: let's say we have an input `x`, consisting of 8 samples with 26 features, which is linearly combined with weights `w` in order to get a single output for every sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6LGBkLiFNXK",
        "outputId": "1791ba3a-1b88-4c13-acb1-f89c6c6a57ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-4.0475],\n",
            "        [ 3.5234],\n",
            "        [-6.9343],\n",
            "        [ 3.4038],\n",
            "        [ 2.7518],\n",
            "        [-2.3095],\n",
            "        [ 7.5920],\n",
            "        [-7.1561]])\n",
            "torch.Size([8, 1])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(8,26)\n",
        "w = torch.randn(26,1)\n",
        "\n",
        "y_hat = torch.matmul(x, w) # an alternative and equivalent syntax is x @ w\n",
        "print(y_hat)\n",
        "print(y_hat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az2LZ1hnGDds"
      },
      "source": [
        "Note that matrix multiplication is different from element-wise multiplication. For element-wise, `*` is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTgPXaUIMXZu",
        "outputId": "7d2268cf-fd51-46da-da66-d08c645d2fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor([-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000])\n",
            "tensor([-2., -2., -2., -2., -2., -2., -2., -2.])\n",
            "tensor([-2.6184, -2.6184, -2.6184, -2.6184, -2.6184, -2.6184, -2.6184, -2.6184])\n",
            "tensor([-3.0914, -1.7544, -3.6144, -2.8212, -1.1423, -2.7835, -2.0920, -2.7721])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(8)\n",
        "print(x)\n",
        "x = x - 1.5\n",
        "print(x)\n",
        "x -= 1.5\n",
        "print(x)\n",
        "x += torch.randn(1)\n",
        "print(x)\n",
        "x += torch.randn(8)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va08ltgupiFI"
      },
      "source": [
        " ## 3. Building a neural network in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJoq1gsI56b"
      },
      "source": [
        "### 3.1 The building blocks\n",
        "\n",
        "Neural networks are initialized through the use of class objects. You have encountered class objects already during this course: Scikit-learn models are all class objects. The difference here is that we will code our own class first, before using it.\n",
        "\n",
        "Many of the functionalities necessary to create [**all types of neural networks**](http://www.asimovinstitute.org/neural-network-zoo/) have [**already been implemented**](http://pytorch.org/docs/master/nn.html).\n",
        "\n",
        "Let's inspect the most basic building blocks first: the [linear layer](https://pytorch.org/docs/master/generated/torch.nn.Linear.html#torch.nn.Linear) and the [ReLU](https://pytorch.org/docs/master/generated/torch.nn.ReLU.html#torch.nn.ReLU) activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk2J6rxxMXaF"
      },
      "source": [
        "A linear layer is an object that will perform a matrix multiplication once called. Here, we instantiate such a layer with 20 input nodes and 40 output nodes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66CEo4JuMXaI",
        "outputId": "2221c27c-aef6-4108-a239-854e08897498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=20, out_features=40, bias=True)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "nn.Linear(20, 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI0RkwIXMXaO"
      },
      "source": [
        "Let's simulate some random data for this layer: a dataset (or batch) with 16 samples and 20 features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "27Qc4tKsMXaS"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(16, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz0B6EzmMXaY"
      },
      "source": [
        "Now let's use our linear layer on this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrSGoQcCMXac",
        "outputId": "ba45b31a-5628-4f38-b31a-eaf915693cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 20])\n",
            "torch.Size([16, 40])\n"
          ]
        }
      ],
      "source": [
        "layer = nn.Linear(20, 40)\n",
        "print(x.shape)\n",
        "z = layer(x)\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0j01q3UMXah"
      },
      "source": [
        "What happens when we try to feed our layer an input with a different number of features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "qvAGyMa0MXan",
        "outputId": "b8b0de83-09ce-4138-9939-31c823eb1f5c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (16x30 and 20x40)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a4ef47082bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x30 and 20x40)"
          ]
        }
      ],
      "source": [
        "x = torch.randn(16, 30)\n",
        "layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEQOYifSMXat"
      },
      "source": [
        "Let's see the ReLU in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CC_eT1wMXax",
        "outputId": "097b5c55-c798-4195-e71d-1b0c50df07e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0139,  1.3949,  1.0959, -0.6904],\n",
            "        [-1.3344,  0.7912, -0.4655,  0.7359]])\n",
            "tensor([[0.0139, 1.3949, 1.0959, 0.0000],\n",
            "        [0.0000, 0.7912, 0.0000, 0.7359]])\n"
          ]
        }
      ],
      "source": [
        "relu = nn.ReLU()\n",
        "\n",
        "x = torch.randn(2, 4)\n",
        "print(x)\n",
        "z = relu(x)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS75ldCQMXa2"
      },
      "source": [
        "As you may have noticed, `nn.Module`s are class objects, similarly as Scikit-learn models that you instantiate and then call.\n",
        "\n",
        "You can chain `nn.Module`s with the use of `nn.Sequential`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r3NjqwzMXa9"
      },
      "outputs": [],
      "source": [
        "linear_and_relu = nn.Sequential(nn.Linear(20, 40), nn.ReLU())\n",
        "\n",
        "x = torch.randn(16, 20)\n",
        "z = linear_and_relu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb07hQ5fMXbG"
      },
      "source": [
        "Or even longer constructs:\n",
        "\n",
        "Always keep in mind what happens with the dimensions of your input and outputs with every layer. If your first layer outputs 40 features/nodes/hidden dimensions, then logically the next will have to take 40 as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl_95q5iMXbM",
        "outputId": "769c598b-8bd3-45c9-b9f4-191954845a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1])\n",
            "tensor([[-0.3451],\n",
            "        [-0.3956],\n",
            "        [-0.2456],\n",
            "        [-0.3528],\n",
            "        [-0.3552],\n",
            "        [-0.3553],\n",
            "        [-0.2867],\n",
            "        [-0.3365],\n",
            "        [-0.3746],\n",
            "        [-0.4007],\n",
            "        [-0.3852],\n",
            "        [-0.3914],\n",
            "        [-0.3847],\n",
            "        [-0.3026],\n",
            "        [-0.3468],\n",
            "        [-0.3749]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a_whole_damn_network = nn.Sequential(\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 4),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 1)\n",
        "    )\n",
        "\n",
        "x = torch.randn(16, 128)\n",
        "z = a_whole_damn_network(x)\n",
        "print(z.shape)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODrbnv-MXbT"
      },
      "source": [
        "The output $z$ that we now obtain after this whole network are called **logits**. They are the real-numbered $\\mathbb{R}$ outputs that we obtain at the end of the network before our last activation function. This last activation function will be a, depending on the task at hand, sigmoid, softmax, or the identifity function for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErcZ92U3MXbe"
      },
      "source": [
        "### 3.2 Class object neural networks and hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT_rF-1cMXbi"
      },
      "source": [
        "We've seen how to implement a neural network using PyTorch `nn.Sequential`. It is more flexible however to write our own model class. This allows us to have more control over which operations we use and allows us to define our own hyperparameters. To make a PyTorch model, we specify our class object to be a submodule of `nn.Module` and inherit its methods via `super().__init__()`. Further, we specify all necessary attributes (such as layers) in our `__init__` function (executed upon initialization) and implement a `forward` function, which is executed when the object is called after being initialized.\n",
        "\n",
        "The following code shows two examples. The first one corresponds to a neural network without hyperparameters. The second one correponds to the same network, however, where we make use of the `__init__` function in order to pass hyperparameters as arguments. We can for example specify a hyperparameter that specifies whether dropout is used or not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCWUPuY_I-nq"
      },
      "outputs": [],
      "source": [
        "class BasicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(50, 40)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.layer2 = nn.Linear(40, 20)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "        self.layer4 = nn.Linear(10, 5)\n",
        "        # Think again: why do we not want a relu and dropout after our last layer again?\n",
        "\n",
        "    def forward(self, x):\n",
        "        # call them in separate lines:\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # or together:\n",
        "        x = self.dropout2(self.relu2(self.layer2(x)))\n",
        "        x = self.dropout3(self.relu3(self.layer3(x)))\n",
        "\n",
        "        # we could've also wrapped everything in a nn.Sequential ..\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "class HyperparameterModel(nn.Module):\n",
        "    def __init__(self, dimensions_from_input_to_output = [50, 40, 20, 10, 5], dropout = True):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        # iterate through all layers:\n",
        "        for i in range(len(dimensions_from_input_to_output) - 2):\n",
        "            layer = nn.Linear(dimensions_from_input_to_output[i], dimensions_from_input_to_output[i + 1])\n",
        "            layers.append(layer)\n",
        "            layers.append(nn.ReLU())\n",
        "            if dropout == True:\n",
        "                layers.append(nn.Dropout(0.2))\n",
        "\n",
        "\n",
        "        # the last layer separate from the loop because we don't want a ReLU and dropout after the last layer\n",
        "        layer = nn.Linear(dimensions_from_input_to_output[i+1], dimensions_from_input_to_output[i + 2])\n",
        "        layers.append(layer)\n",
        "\n",
        "        # wrap the layers in a sequential\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test the first model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj1h-SUXMXbw",
        "outputId": "6b63df67-faf2-499a-a846-3733757b907a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BasicModel(\n",
              "  (layer1): Linear(in_features=50, out_features=40, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (layer2): Linear(in_features=40, out_features=20, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (layer3): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (dropout3): Dropout(p=0.2, inplace=False)\n",
              "  (layer4): Linear(in_features=10, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = BasicModel()\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGo96VzdMXb1",
        "outputId": "222a3660-7739-47f6-edb6-2db45f6532da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0194,  0.0271, -0.1542,  0.1592,  0.0312],\n",
            "        [-0.0525, -0.1321, -0.1807,  0.1533, -0.0450],\n",
            "        [ 0.0050, -0.0230, -0.1262,  0.1614, -0.0267],\n",
            "        [ 0.0104, -0.0821, -0.2013,  0.1051, -0.0107]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 50)\n",
        "y = net(x)\n",
        "print(y)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dot4uBfzMXb-"
      },
      "source": [
        "And now the second model, with default arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlVAqCvgMXcC",
        "outputId": "f0005bdf-636b-49a7-f8fe-593c508ee904"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HyperparameterModel(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=40, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=40, out_features=20, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=20, out_features=10, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.2, inplace=False)\n",
              "    (9): Linear(in_features=10, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = HyperparameterModel()\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSn3_hWMXcI",
        "outputId": "25ed18f7-1e7a-46c0-c7e0-e1f6b254b9b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0860, -0.2695, -0.0666, -0.2422,  0.4435],\n",
            "        [ 0.1039, -0.2587, -0.0850, -0.2383,  0.4415],\n",
            "        [ 0.1082, -0.1894, -0.1617, -0.1805,  0.3134],\n",
            "        [ 0.1447, -0.3212,  0.0065, -0.2603,  0.4904]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 50)\n",
        "y = net(x)\n",
        "print(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN6ZLONoMXcP"
      },
      "source": [
        "And, finally, again the second model, albeit with specific arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFbjxV_9MXcS",
        "outputId": "ec705bb4-2df3-4a60-aab8-ca3037381266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HyperparameterModel(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=160, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=160, out_features=80, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=80, out_features=40, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=40, out_features=20, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=20, out_features=10, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=10, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = HyperparameterModel(dimensions_from_input_to_output = [50, 160, 80, 40, 20, 10, 5], dropout = False)\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35MBDkKZMXcW",
        "outputId": "a44ffc6a-8332-4f19-ee57-11ca37f84ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0453, -0.0810,  0.1928,  0.2837, -0.1461],\n",
            "        [-0.0491, -0.0818,  0.1999,  0.2830, -0.1562],\n",
            "        [-0.0468, -0.0805,  0.1894,  0.2807, -0.1391],\n",
            "        [-0.0456, -0.0833,  0.1960,  0.2834, -0.1454]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 50)\n",
        "y = net(x)\n",
        "print(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci8sWl7RMXcZ"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.1:</b> **Copy over any of the two networks above (preferably the one you understand best), and modify it to take as input 784 features and as output 10 nodes. We will use this network later in the PC lab. You can test your network for bugs using some randomly generated data (as seen above).**\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuJm_kzwMXce"
      },
      "outputs": [],
      "source": [
        "######## YOUR CODE HERE #########\n",
        "model = HyperparameterModel(dimensions_from_input_to_output = [784, 160, 80, 40, 20, 10], dropout = False)\n",
        "\n",
        "x = torch.randn(4, 784)\n",
        "model(x)\n",
        "\n",
        "#################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8pqMG8vMXci"
      },
      "source": [
        "### 3.3 Data and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5dpoMHtMXcj"
      },
      "source": [
        "You may have noticed that the outputs of your model have a `grad_fn` attribute. This grad function will be used by PyTorch's automatic differentation engine to perform backward passes and compute gradients for every parameter with respect to the loss/cost function.\n",
        "\n",
        "Now that we have our model and know that PyTorch will automatically compute gradients for us, we can move on to train a model. To do this, we need the following:\n",
        "\n",
        "The most basic blueprint of PyTorch model training consists of\n",
        "- Get your data\n",
        "- Wrap your data splits in a [data loader](https://pytorch.org/docs/stable/data.html)\n",
        "- Instantiate the model\n",
        "- Instantiate a [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "- Instantiate an [optimizer object](https://pytorch.org/docs/stable/optim.html), to which you pass the parameters you want to optimize\n",
        "- Iterate through your training data, for every batch:\n",
        "    - reset the gradients\n",
        "    - do forward pass\n",
        "    - compute loss\n",
        "    - backward pass\n",
        "    - update parameters\n",
        "\n",
        "(Optionally):\n",
        "- After every full iteration through all training data samples (called an epoch), loop through all batches of validation data:\n",
        "    - forward pass\n",
        "    - compute loss and validation scores\n",
        "\n",
        "In this way, we can monitor how good our model is performing on left-out validation data during training, this is used in early stopping. Notably, we do not compute and reset gradients and update parameters during our validation iterations, because we do not want to fit our model on this data.\n",
        "\n",
        "Let's start with step one: get your data and wrap them in data loaders. We will first illustrate how we can convert our usual Pandas or NumPy datasets to be compatible with PyTorch with some random data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZG5Ikr8MXck"
      },
      "outputs": [],
      "source": [
        "X_train = np.random.randn(100, 784)\n",
        "y_train = np.random.randint(low = 0, high = 10, size = (100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-bbTYpxMXcm",
        "outputId": "8733fe5a-6339-42dc-b695-6885aff1f297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float64\n"
          ]
        }
      ],
      "source": [
        "X_train = torch.from_numpy(X_train)\n",
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KlAd2-iMXcq"
      },
      "source": [
        "It is important to keep in mind data types: by default NumPy works with `float64`. However, if you instantiate a model in PyTorch, by default it will have weights in `float32`. It is therefore advised to convert your data to `float32`. In PyTorch, `float` is shorthand for `float32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF43PgTRMXcr",
        "outputId": "238df29f-3efa-490b-9012-de1984b95b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.float()\n",
        "# Equivalent: X_train.to(torch.float) or X_train.to(torch.float32)\n",
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMTh2qpAMXcu",
        "outputId": "a41c12e7-9c53-4d97-ed3a-fb782a1ca405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "y_train = torch.tensor(y_train)\n",
        "print(y_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnI0TnDQMXc1"
      },
      "source": [
        "Now that we have our X_train and y_train as tensors, we can make them PyTorch-ready by wrapping them in a PyTorch dataset, followed by wrapping them in a DataLoader. The latter gives access to batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMRu_hLsMXc4"
      },
      "outputs": [],
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, pin_memory=True, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quJWFJxiMXc5"
      },
      "source": [
        "Now we can use our train_dataloader as such:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv5E6nmXMXc6",
        "outputId": "3dd99b31-5049-4af5-b213-58e5369397d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([4, 784]) torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    X, y = batch\n",
        "    print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fb8HQt4MXc_"
      },
      "source": [
        "As you can see, we can iterate through the batches by using a for loop. Each batch consists of a list of X and y tensors. Let's isolate one batch for testing purposes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk4l7myPMXdF",
        "outputId": "a183f5cf-083d-44a8-e76e-af7dac3afa54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[-0.4215, -0.8713, -0.5904,  ...,  0.0987, -0.3434,  2.0297],\n",
              "         [ 1.1620,  2.0100, -0.1697,  ..., -0.9857, -0.6931, -2.1949],\n",
              "         [ 0.0610,  0.7990, -0.1335,  ..., -1.7615, -0.6285,  0.3766],\n",
              "         ...,\n",
              "         [-1.4407,  0.2814, -0.9213,  ...,  0.1769,  0.1921,  0.6911],\n",
              "         [-0.0920, -2.1625, -0.2856,  ...,  1.4268, -1.3603,  0.5337],\n",
              "         [ 1.1021,  1.2742,  0.2581,  ...,  0.3398,  0.0429,  0.4328]]),\n",
              " tensor([9, 2, 9, 3, 5, 2, 5, 6, 8, 6, 0, 3, 6, 5, 8, 9])]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifxPbgJjMXdJ"
      },
      "source": [
        "For the remainder of the PC lab, we will work with the MNIST dataset included in `torchvision`. In case you want to run this code locally, you can install Torchvision by means of `pip install torchvision`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "a591a86ff5df43a4a417af06acae5ef4",
            "e22ea29341c74ebcaa1ef014728cc24d",
            "3c28cf5cafbe4e15a38c42eb3f409452",
            "db67f845207342bbad405f05d25a649e",
            "db5fe7534189435b822b8cca45234cff",
            "55494d082cb8485c94170af195dc36d7",
            "7a34a8a9bbea4843b42569dc0fe5a2dd",
            "18ae853e824d4d828fd73360c04355cb",
            "3f32f546e23740e8bd2472c329f61358",
            "5f7037650b424f47bdbfbb55d765ff05",
            "00ec74b2595546429a582fe4e44160de",
            "bcb9e5bdfe4f48209e63a62b99f2b0b1",
            "babcf4781af448f2a08570e00c5eddaf",
            "86fc88de950d46d0ba2a7275a52d20c2",
            "d0a57eb97b694f0db0edf1ee5da5de8f",
            "4573319a9ca24fecb372b4ac5201bf1e",
            "3d9ed4120cfb43a8b5a74fd860b2d74d",
            "44b75b30ffcf4bf49a5d356cc4563511",
            "74bb87d162b34908a44c74f95e6a92c5",
            "36e77a835c2146bca9d9f76c625c35c2",
            "95fde7fa34594ad4a3aad003528d6049",
            "6ce97fe735c14938a584d8aa5fa46708",
            "69fdf10dd8ee4804a6b4fba290b0431b",
            "99bf6663329a47d8b4324adb8db91e31",
            "878ea64340784b89a4957ec6ece4d343",
            "c8bcc9f59f464f9ab4304233463a9194",
            "8e58143cedfc4632bb79b1a5bbf0370b",
            "42f566d6225a442c8c0be3e0e17b1efa",
            "2dd3c5e91b1642c8b7832d62296d7a9b",
            "b1c49e78124c48f78622cf08dc378354",
            "0f221a4b6faf406f84388c67c0fa108a",
            "0c8487c8d6d6408f925331ff2dc798b9",
            "43dcdcf9ace14d8a8db44b83ae5a2931",
            "7966f6424e814aebae0170fb5224ca5a",
            "4898879e48d5411cb6d5f44fb85346d7",
            "78c4cff64b594699af85db450b2fce6f",
            "23bef317abc246eda5458ba43285a66e",
            "f964eb529bdc4c498e831a9d92fcc3e5",
            "c14ea132914546be8d78c27b0bb4b8c4",
            "66789cb5d42547249511f516f2af4aa2",
            "2672f83ec3ad4712b845798d2891ac7a",
            "71a2607d8f564363ba5b72b339eb7c95",
            "7ae53a1e7ea24a1f8d5c0f390a4a516f",
            "246d24122d0b49db9f8458b1dafd89d2"
          ]
        },
        "id": "as-YG3-_MXdM",
        "outputId": "344abef1-e6d6-4ee4-cde7-621c9b71551c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 8] nodename nor servname provided, or not known>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1343\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b2d652355c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_data = datasets.MNIST(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                     \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to download (trying next):\\n{error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# expand redirect chain if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_redirect_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_redirect_hops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# check if file is located on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_hops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    535\u001b[0m                                   '_open', req)\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/predmod/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1343\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "X_train = train_data.data\n",
        "y_train = train_data.targets\n",
        "\n",
        "X_test = test_data.data\n",
        "y_test = test_data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8hdN8G5MXdQ",
        "outputId": "a331e1a7-f796-44cb-d9ee-2387815c1f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shapes:\n",
            "torch.Size([60000, 28, 28]) torch.Size([60000]) torch.Size([10000, 28, 28]) torch.Size([10000])\n",
            "first training image tensor:\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
            "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
            "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
            "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
            "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
            "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
            "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
            "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
            "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
            "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
            "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
            "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
            "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
            "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
            "       dtype=torch.uint8)\n",
            "first five labels:\n",
            "tensor([5, 0, 4, 1, 9])\n"
          ]
        }
      ],
      "source": [
        "print('shapes:')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "print('first training image tensor:')\n",
        "print(X_train[0])\n",
        "print('first five labels:')\n",
        "print(y_train[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA03h75wMXdV"
      },
      "source": [
        "Our data consists of images, where each sample consists of $28 \\times 28$ input features/pixels. In order to feed this data to our model, we will need to flatten these features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgNA_Y8gMXdW"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, 28 * 28)\n",
        "X_test = X_test.reshape(-1, 28 * 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQryYAP6MXda"
      },
      "source": [
        "Next, since our (grayscale) pixel values range between 0 and 255, it is good practice to min-max scale the data by means of dividing by 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUXvQOqXMXdb"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai8QjbZ9MXdh"
      },
      "source": [
        "Finally, for the sake of sanity, let's check the data types for training and test sets: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n9Pg1VxMXdj",
        "outputId": "18253702-650b-439a-80c2-c2179b112c4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32, torch.int64, torch.int64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.dtype, X_test.dtype, y_train.dtype, y_test.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3mE5c6nMXdk"
      },
      "source": [
        "Let's split up our training set in a training and validation set and finally wrap our data in a data loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9DQFGa3MXdl"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "train_indices, val_indices = np.split(np.random.permutation(len(X_train)), [int(len(X_train)*0.8)])\n",
        "X_val = X_train[val_indices]\n",
        "y_val = y_train[val_indices]\n",
        "X_train = X_train[train_indices]\n",
        "y_train = y_train[train_indices]\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, pin_memory=True, shuffle=True)\n",
        "\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, pin_memory=True, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, pin_memory=True, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu4GXH_2MXdn"
      },
      "source": [
        "Let's visualize a random batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "wn3rRoSTMXdq",
        "outputId": "ce9bd2b5-e225-40cb-8097-28c81871e695"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x576 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "X_batch, y_batch = batch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 4, 4\n",
        "for i in range(cols * rows):\n",
        "    img, label = X_batch[i], y_batch[i]\n",
        "    figure.add_subplot(rows, cols, i+1)\n",
        "    plt.title(label.item())\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.reshape(-1, 28, 28).squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGmLYd15MXdw"
      },
      "source": [
        "In one of the previous exercises, we already implemented a model compatible with MNIST: 784 input features and 10 output nodes (one for each class). Hence, we can move on to loss functions and optimizers. For multi-class classification, we will need to use the [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss). Take a look at what kind of inputs this loss function expects. According to the documentation: `The input is expected to contain raw, unnormalized scores for each class.` Meaning that we can pass logits directly to this loss function, without the need to apply a softmax operation. \n",
        "\n",
        "When it comes to the optimizer, we can choose [vanilla gradient descent](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) or the more commonly used [Adam optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam), which is itself a pimped version of stochastic gradient descent (with momentum).\n",
        "\n",
        "For model training, it is also crucial to set the appropriate learning rate.  The learning rate is a crucial hyperparameter in machine learning algorithms, particularly in the context of gradient-based optimization. It determines the size of the steps taken during the iterative process of updating model parameters to minimize the loss function. A learning rate which is too high may result in overshooting the minimum, leading to instability, while a too small learning rate can slow down convergence or cause the model to get stuck in a suboptimal solution. Finding the right balance is often a matter of experimentation and depends on the specific characteristics of the data and the model architecture. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kZwMU_IMXd1"
      },
      "outputs": [],
      "source": [
        "model = HyperparameterModel(dimensions_from_input_to_output= [784, 128, 10]) # your model from previous exercises here.\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005) # SGD = stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrEVraTMXd7"
      },
      "source": [
        "Now we're ready to perform training. We'll build up the training loop step-wise in the following codeblocks. Let's first start with passing one batch to the model, computing the loss, performing backpropagation and updating the weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROoh6JGdMXd8",
        "outputId": "8a11f5f6-fb72-4f7c-de19-557dfd4192b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 784]) torch.Size([16])\n",
            "torch.Size([16, 10])\n",
            "Outputs as logits, first two samples:\n",
            "tensor([[ 0.0545, -0.0201,  0.0477,  0.0428, -0.0040,  0.0234, -0.1408, -0.0766,\n",
            "         -0.0289,  0.0439],\n",
            "        [ 0.0133,  0.0047,  0.1006,  0.1443, -0.0265,  0.1450,  0.0169, -0.1208,\n",
            "          0.0300,  0.1703]], grad_fn=<SliceBackward0>)\n",
            "loss: tensor(2.2893, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "X_batch, y_batch = batch\n",
        "\n",
        "y_hat_batch = model(X_batch)\n",
        "\n",
        "loss = loss_function(y_hat_batch, y_batch) # Compute loss\n",
        "\n",
        "loss.backward()   # Calculate gradients\n",
        "optimizer.step()   # Update weights using defined optimizer\n",
        "\n",
        "print(X_batch.shape, y_batch.shape)\n",
        "print(y_hat_batch.shape)\n",
        "print(\"Outputs as logits, first two samples:\")\n",
        "print(y_hat_batch[:2])\n",
        "print('loss:', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hlu1gnRMXd_"
      },
      "source": [
        "Everytime we perform a training step, we should reset the gradients so that the gradients computed on the previous batch do not influence the next. We can do this by calling `.zero_grad()` on our optimizer. In practice, it is most safe to call this before every forward pass. A full epoch of training is obtained by the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiDrim2GMXeE"
      },
      "outputs": [],
      "source": [
        "all_losses = []\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    X_batch, y_batch = batch\n",
        "\n",
        "    y_hat_batch = model(X_batch)\n",
        "\n",
        "    loss = loss_function(y_hat_batch, y_batch) # Compute loss\n",
        "\n",
        "    loss.backward()   # Calculate gradients\n",
        "    optimizer.step()   # Update weights using defined optimizer\n",
        "\n",
        "    all_losses.append(loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXPQQS4QMXeR"
      },
      "source": [
        "Plotting the loss function of every batch during one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "KgO5nCJJMXeZ",
        "outputId": "78d97b69-57ec-417c-85e2-1b107b0de58b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5de3b914d0>]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(len(all_losses)), all_losses)\n",
        "smoothed_losses = np.convolve(all_losses, np.ones(50)/50, mode = \"valid\")\n",
        "plt.plot(np.arange(len(smoothed_losses)), smoothed_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD36b8QPMXee"
      },
      "source": [
        "We have evaluated the training progress during one epoch. What if we want to see the performance on the validation set during training, so that we can see if/when the model starts overfitting? It is recommended to perform a pass through the whole validation set after every training epoch. During this pass, it is important to block automatic gradient computation by means of `torch.no_grad()`. In addition, we need to tell PyTorch to put the model in evaluation mode, in order to turn off stochastic components such as dropout. After the validation epoch, we should put the model back in training mode. The above gives rise to the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw0wKUcNMXeh",
        "outputId": "5f391863-ce50-42fd-d1d7-4c0aba38c6db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8773333333333333\n",
            "0.4791885650952657\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "true_labels = []\n",
        "losses = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        y_hat_batch = model(X_batch)\n",
        "\n",
        "        loss = loss_function(y_hat_batch, y_batch)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        predictions.append(y_hat_batch)\n",
        "        true_labels.append(y_batch)\n",
        "\n",
        "model.train()\n",
        "\n",
        "predictions = torch.cat(predictions)\n",
        "true_labels = torch.cat(true_labels)\n",
        "accuracy = (true_labels == predictions.argmax(-1)).sum().item() / len(predictions)\n",
        "\n",
        "print(accuracy)\n",
        "print(np.mean(losses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_yo3RiMXeq"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.2:</b> **Using the code above, put it all together to train a model for multiple epochs. After every epoch, print or save some training and validation statistics. Monitor how good your model is training. What things could you change? In particular, try the Adam optimizer or try using gradient descent with the momentum argument. How does this influence training speed? What is it doing? Try tweaking the learning rate. You should be able to obtain an accuracy of +- 96%.**\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj0vgM2WMXeu",
        "outputId": "167620ca-bb4d-4765-a654-a9f273204f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 \t 1.0295445522417626 0.49003028618295985 0.87275\n",
            "2 \t 0.458134299899141 0.3716748375097911 0.8945\n",
            "3 \t 0.38025129948928954 0.32847441735863686 0.9049166666666667\n",
            "4 \t 0.3378292314012845 0.2972507485697667 0.9126666666666666\n",
            "5 \t 0.30908864925056695 0.2742604612062375 0.9215833333333333\n",
            "6 \t 0.2860055919792503 0.2544648086602489 0.9274166666666667\n",
            "7 \t 0.26701789459213615 0.23875977500279744 0.9309166666666666\n",
            "8 \t 0.25047674973867834 0.22539564369246365 0.9349166666666666\n",
            "9 \t 0.2373111587334424 0.2151957892353336 0.9370833333333334\n",
            "10 \t 0.22578602118821195 0.20450363989795248 0.94125\n",
            "11 \t 0.21266779185148577 0.19446045813088617 0.94325\n",
            "12 \t 0.2052584621074299 0.1861418180267016 0.9461666666666667\n",
            "13 \t 0.19657312537543475 0.17968149414472281 0.9478333333333333\n",
            "14 \t 0.18804479710618033 0.17327240923419596 0.95025\n",
            "15 \t 0.1807208038441216 0.16908437561926742 0.95075\n",
            "16 \t 0.1771316344998777 0.16283077561606962 0.9525833333333333\n",
            "17 \t 0.17033553914663693 0.15786253048541646 0.95375\n",
            "18 \t 0.16223713276116178 0.15349014486496648 0.95475\n",
            "19 \t 0.16078838091234987 0.14906232473440467 0.9559166666666666\n",
            "20 \t 0.15444813291030005 0.14507949173015852 0.9571666666666667\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "model = HyperparameterModel(dimensions_from_input_to_output= [784, 128, 10]) # your model from previous exercises here.\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005) # SGD = stochastic gradient descent\n",
        "\n",
        "for i in range(1, N_EPOCHS + 1):\n",
        "    all_losses = []\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        y_hat_batch = model(X_batch)\n",
        "\n",
        "        loss = loss_function(y_hat_batch, y_batch) # Compute loss\n",
        "\n",
        "        loss.backward()   # Calculate gradients\n",
        "        optimizer.step()   # Update weights using defined optimizer\n",
        "\n",
        "        all_losses.append(loss.item())\n",
        "    train_loss = np.mean(all_losses)\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch in val_dataloader:\n",
        "            X_batch, y_batch = batch\n",
        "\n",
        "            y_hat_batch = model(X_batch)\n",
        "\n",
        "            loss = loss_function(y_hat_batch, y_batch)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            predictions.append(y_hat_batch)\n",
        "            true_labels.append(y_batch)\n",
        "\n",
        "    predictions = torch.cat(predictions)\n",
        "    true_labels = torch.cat(true_labels)\n",
        "    accuracy = (true_labels == predictions.argmax(-1)).sum().item() / len(predictions)\n",
        "\n",
        "    print(i, '\\t', train_loss, np.mean(losses), accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04jmvNeBMXe0"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "<b>EXERCISE 3.3:</b> **Evaluate your model on the test set. What is the performance?**\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J8XfWlPMXe2",
        "outputId": "892e4920-66f4-477d-af37-0709239b7fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9605\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE ###\n",
        "predictions = []\n",
        "true_labels = []\n",
        "losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in test_dataloader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        y_hat_batch = model(X_batch)\n",
        "\n",
        "        loss = loss_function(y_hat_batch, y_batch)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        predictions.append(y_hat_batch)\n",
        "        true_labels.append(y_batch)\n",
        "\n",
        "predictions = torch.cat(predictions)\n",
        "true_labels = torch.cat(true_labels)\n",
        "accuracy = (true_labels == predictions.argmax(-1)).sum().item() / len(predictions)\n",
        "\n",
        "print(accuracy)\n",
        "######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUoF-7B2MXfS"
      },
      "source": [
        "### Extra: Using GPUs\n",
        "\n",
        "Matrix multiplication run orders of magnitude faster on GPU hardware. If you have a local GPU and have installed a PyTorch version with GPU, you should be able to run this code locally. Otherwise, In Google Colab, you can request access to a GPU via `Runtime > Change runtime type > Hardware accelerator = GPU`.\n",
        "\n",
        "Briefly, the steps needed to train on GPUs consist of\n",
        "1. Putting your model on the GPU\n",
        "2. During your training loop, putting every batch on the GPU before the forward pass\n",
        "3. If you have a validation loop, doing the same there for every batch.\n",
        "4. If you have variables that you will use after training (e.g. predictions on the validation set), remember to return this back to the CPU, as GPUs have limited memory.\n",
        "\n",
        "In PyTorch, we put variables and models on the GPU by specifying their 'device' to be 'cuda' (the parallel computing platform for nvidia GPUs that PyTorch uses).\n",
        "\n",
        "The following code illustrates how to train your models on GPU hardware:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4q8iNSBMXfT",
        "outputId": "d5663082-5e79-476d-8dec-e34bed345c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.6440e-03, -1.8704e-04,  4.5266e-04,  ..., -2.1688e-04,\n",
              "          1.2355e-04,  3.8274e-04],\n",
              "        [ 4.1367e-03,  4.4949e-04,  2.6534e-03,  ..., -3.0660e-03,\n",
              "         -1.6851e-03,  2.8717e-03],\n",
              "        [ 1.5144e-03, -6.3354e-04, -3.9330e-04,  ..., -4.5328e-05,\n",
              "         -1.7569e-03, -5.2670e-05],\n",
              "        ...,\n",
              "        [-4.0101e-04,  1.2125e-03,  1.3494e-03,  ..., -9.5715e-04,\n",
              "          1.4939e-03,  8.3638e-04],\n",
              "        [ 2.2591e-03, -3.0156e-04,  9.1510e-04,  ..., -5.9826e-04,\n",
              "         -5.1530e-04,  5.5109e-04],\n",
              "        [ 2.9774e-03,  7.4705e-04,  1.8870e-03,  ..., -2.8524e-03,\n",
              "         -2.2332e-03,  3.2974e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = next(iter(train_dataloader))\n",
        "\n",
        "model = model.to('cuda')\n",
        "print(X.device)\n",
        "X = X.to('cuda')\n",
        "print(X.device)\n",
        "\n",
        "y_hat = model(X)\n",
        "\n",
        "y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAm5JACMXfU"
      },
      "source": [
        "We encourage you to try out training on GPUs during the next PC lab(s)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PClab_intro_nns_SOLVED.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ec74b2595546429a582fe4e44160de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c8487c8d6d6408f925331ff2dc798b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f221a4b6faf406f84388c67c0fa108a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18ae853e824d4d828fd73360c04355cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bef317abc246eda5458ba43285a66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae53a1e7ea24a1f8d5c0f390a4a516f",
            "placeholder": "​",
            "style": "IPY_MODEL_246d24122d0b49db9f8458b1dafd89d2",
            "value": " 5120/? [00:00&lt;00:00, 161549.96it/s]"
          }
        },
        "246d24122d0b49db9f8458b1dafd89d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2672f83ec3ad4712b845798d2891ac7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd3c5e91b1642c8b7832d62296d7a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e77a835c2146bca9d9f76c625c35c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c28cf5cafbe4e15a38c42eb3f409452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ae853e824d4d828fd73360c04355cb",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f32f546e23740e8bd2472c329f61358",
            "value": 9912422
          }
        },
        "3d9ed4120cfb43a8b5a74fd860b2d74d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f32f546e23740e8bd2472c329f61358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42f566d6225a442c8c0be3e0e17b1efa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43dcdcf9ace14d8a8db44b83ae5a2931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44b75b30ffcf4bf49a5d356cc4563511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4573319a9ca24fecb372b4ac5201bf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4898879e48d5411cb6d5f44fb85346d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14ea132914546be8d78c27b0bb4b8c4",
            "placeholder": "​",
            "style": "IPY_MODEL_66789cb5d42547249511f516f2af4aa2",
            "value": ""
          }
        },
        "55494d082cb8485c94170af195dc36d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7037650b424f47bdbfbb55d765ff05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66789cb5d42547249511f516f2af4aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69fdf10dd8ee4804a6b4fba290b0431b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99bf6663329a47d8b4324adb8db91e31",
              "IPY_MODEL_878ea64340784b89a4957ec6ece4d343",
              "IPY_MODEL_c8bcc9f59f464f9ab4304233463a9194"
            ],
            "layout": "IPY_MODEL_8e58143cedfc4632bb79b1a5bbf0370b"
          }
        },
        "6ce97fe735c14938a584d8aa5fa46708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a2607d8f564363ba5b72b339eb7c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74bb87d162b34908a44c74f95e6a92c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c4cff64b594699af85db450b2fce6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2672f83ec3ad4712b845798d2891ac7a",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71a2607d8f564363ba5b72b339eb7c95",
            "value": 4542
          }
        },
        "7966f6424e814aebae0170fb5224ca5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4898879e48d5411cb6d5f44fb85346d7",
              "IPY_MODEL_78c4cff64b594699af85db450b2fce6f",
              "IPY_MODEL_23bef317abc246eda5458ba43285a66e"
            ],
            "layout": "IPY_MODEL_f964eb529bdc4c498e831a9d92fcc3e5"
          }
        },
        "7a34a8a9bbea4843b42569dc0fe5a2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ae53a1e7ea24a1f8d5c0f390a4a516f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fc88de950d46d0ba2a7275a52d20c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74bb87d162b34908a44c74f95e6a92c5",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36e77a835c2146bca9d9f76c625c35c2",
            "value": 28881
          }
        },
        "878ea64340784b89a4957ec6ece4d343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c49e78124c48f78622cf08dc378354",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f221a4b6faf406f84388c67c0fa108a",
            "value": 1648877
          }
        },
        "8e58143cedfc4632bb79b1a5bbf0370b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95fde7fa34594ad4a3aad003528d6049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99bf6663329a47d8b4324adb8db91e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f566d6225a442c8c0be3e0e17b1efa",
            "placeholder": "​",
            "style": "IPY_MODEL_2dd3c5e91b1642c8b7832d62296d7a9b",
            "value": ""
          }
        },
        "a591a86ff5df43a4a417af06acae5ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e22ea29341c74ebcaa1ef014728cc24d",
              "IPY_MODEL_3c28cf5cafbe4e15a38c42eb3f409452",
              "IPY_MODEL_db67f845207342bbad405f05d25a649e"
            ],
            "layout": "IPY_MODEL_db5fe7534189435b822b8cca45234cff"
          }
        },
        "b1c49e78124c48f78622cf08dc378354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "babcf4781af448f2a08570e00c5eddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9ed4120cfb43a8b5a74fd860b2d74d",
            "placeholder": "​",
            "style": "IPY_MODEL_44b75b30ffcf4bf49a5d356cc4563511",
            "value": ""
          }
        },
        "bcb9e5bdfe4f48209e63a62b99f2b0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_babcf4781af448f2a08570e00c5eddaf",
              "IPY_MODEL_86fc88de950d46d0ba2a7275a52d20c2",
              "IPY_MODEL_d0a57eb97b694f0db0edf1ee5da5de8f"
            ],
            "layout": "IPY_MODEL_4573319a9ca24fecb372b4ac5201bf1e"
          }
        },
        "c14ea132914546be8d78c27b0bb4b8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8bcc9f59f464f9ab4304233463a9194": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8487c8d6d6408f925331ff2dc798b9",
            "placeholder": "​",
            "style": "IPY_MODEL_43dcdcf9ace14d8a8db44b83ae5a2931",
            "value": " 1649664/? [00:00&lt;00:00, 21619976.17it/s]"
          }
        },
        "d0a57eb97b694f0db0edf1ee5da5de8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fde7fa34594ad4a3aad003528d6049",
            "placeholder": "​",
            "style": "IPY_MODEL_6ce97fe735c14938a584d8aa5fa46708",
            "value": " 29696/? [00:00&lt;00:00, 734346.93it/s]"
          }
        },
        "db5fe7534189435b822b8cca45234cff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db67f845207342bbad405f05d25a649e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7037650b424f47bdbfbb55d765ff05",
            "placeholder": "​",
            "style": "IPY_MODEL_00ec74b2595546429a582fe4e44160de",
            "value": " 9913344/? [00:00&lt;00:00, 50353821.40it/s]"
          }
        },
        "e22ea29341c74ebcaa1ef014728cc24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55494d082cb8485c94170af195dc36d7",
            "placeholder": "​",
            "style": "IPY_MODEL_7a34a8a9bbea4843b42569dc0fe5a2dd",
            "value": ""
          }
        },
        "f964eb529bdc4c498e831a9d92fcc3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
