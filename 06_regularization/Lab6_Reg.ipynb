{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJJ_c765KfKe"
      },
      "source": [
        "# PC Lab 6: Regularization Methods \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQv_DtYEKfKl"
      },
      "source": [
        "We have already seen linear regression to tackle regression problems. With linear regression, we model a continous outcome as a linear function of the features:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y} = w_{0}x_{0} + w_{1}x_{1} + ... + w_{p}x_{p} = \\sum\\limits_{i=0}^{p}w_{i}x_{i}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkM2_pFeKfKm"
      },
      "source": [
        "This works well when there are a lot of training observations and when the number of features (the dimensionality of the problem) is not too large. However, there are a couple of situations where ordinary linear regression might give problems:\n",
        "\n",
        "* When the number of features $p$ becomes large with respect to the number of observations $n$, the variance of the model weights estimated by linear regression increases, which might result in poor predictive performance. Futhermore, there is no longer an analytical solution provided by least squares when $p > n$.\n",
        "* It is possible that there are a lot of uninteresting or redundant features. If we want a sparse and interpretable model, we might want to do feature selection to reduce $p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzmPe28KfKn"
      },
      "source": [
        "In this lab, we will cover two solutions to the problems above: subset selection and regularization methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ips5qzMzKfKo"
      },
      "source": [
        "## Subset selection methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luHc0r4HKfKp"
      },
      "source": [
        "In subset selection, we only use a subset of the features that are available. The goal is to come up with a model that is sparse and that generalizes better to unseen data. There are two main strategies for subset selection: in *best subset selection*, we fit all the $p \\choose k$ models for each $k = 1, 2.. p$ and retain the best model for each $k$. Finally, we select the model that performs best on some measure that controls for overfitting:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an2AElBWKfKq"
      },
      "source": [
        "![bestsubset](https://raw.githubusercontent.com/gdewael/teaching/main/predmod/lab6/img/best_subset.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuf8noSoKfKq"
      },
      "source": [
        "This becomes quickly unfeasible for large values of $p$. Therefore, an alternative approach is to perform *stepwise selection*, which explores a much smaller set of feature combinations. Stepwise selection can be performed either backward or forward. For large $p$ they are the only computationally feasible subset selection methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31dfsSMzKfKr"
      },
      "source": [
        "![forward](https://raw.githubusercontent.com/gdewael/teaching/main/predmod/lab6/img/forward.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j47zElu7KfKs"
      },
      "source": [
        "Finally, it is important to account for the fact that the MSE (or, equivalently, the RSS) will always go down on the training data as we add more and more features. To select the best model out of several candidates, it is important to have an estimate of the test error of each model. This can be done indirectly by using a metric that penalizes for model complexity such as the AIC or the adjusted $R^2$. Another option is to use cross-validation to get an estimate of the test error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "homZZs_VKfKs"
      },
      "source": [
        "**Let's apply subset selection on two datasets.** The first dataset contains features of mixtures used to produce concrete. The goal is to predict the compressive strength of the concrete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN7chQL-KfKt"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/BioML-UGent/MLLS/main/06_regularization/concreteComprStrength.txt\", \"concreteComprStrength.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/BioML-UGent/MLLS/main/06_regularization/fc_data_new.csv\", \"fc_data_new.csv\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/BioML-UGent/MLLS/main/06_regularization/communities.csv\", \"communities.csv\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/BioML-UGent/MLLS/main/06_regularization/meatNIR1000.csv\", \"meatNIR1000.csv\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/BioML-UGent/MLLS/main/06_regularization/meatNIR1000.colnames\", \"meatNIR1000.colnames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7pKomwTKfKu"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "import pandas as pd\n",
        "\n",
        "concretedata = pd.read_table('concreteComprStrength.txt', delim_whitespace=True, header=0, index_col=None)\n",
        "print(concretedata.shape)\n",
        "concretedata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_RJOzdwKfKu"
      },
      "source": [
        "Let's build up an intuition for the code we need for doing best subset selection with linear regression. We will implement algorithm 6.1 from the book as shown above. First we split the data and look at how we can generate all possible combinations of features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0IhV2jkKfKv"
      },
      "outputs": [],
      "source": [
        "X = concretedata.drop(['compressiveStrength'], axis=1)\n",
        "y = concretedata['compressiveStrength']\n",
        "\n",
        "from itertools import chain, combinations\n",
        "\n",
        "list_of_things = [1, 2, 3]\n",
        "\n",
        "for subset in chain.from_iterable(\n",
        "    combinations(list_of_things, r)\n",
        "    for r in range(1, len(list_of_things)+1)\n",
        "    ):\n",
        "\n",
        "    print(subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV19YjZlKfKv"
      },
      "source": [
        "Now we can use this code to iterate not through `list_of_things` but through the possible features. For every subset we fit a model and keep it in a dictionary that records the score for that specific subset of features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMnSHnB5KfKw"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = concretedata.drop(['compressiveStrength'], axis=1)\n",
        "y = concretedata['compressiveStrength']\n",
        "\n",
        "from itertools import chain, combinations\n",
        "\n",
        "list_of_things = X.columns\n",
        "\n",
        "scoring_dict = {}\n",
        "\n",
        "for subset in chain.from_iterable(\n",
        "    combinations(list_of_things, r)\n",
        "    for r in range(1, len(list_of_things)+1)\n",
        "    ):\n",
        "\n",
        "    X_subset = X[list(subset)]\n",
        "\n",
        "    model = LinearRegression()\n",
        "\n",
        "    model.fit(X_subset, y)\n",
        "\n",
        "    scoring_dict[subset] = model.score(X_subset, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzD5G7tKKfKw"
      },
      "source": [
        "Taking five random samples from this dict to get an idea what's in it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOzdQkFnKfKx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.sample(list(scoring_dict.items()), 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_p3sxFTKfKx"
      },
      "source": [
        "Getting the best model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rSEYSmCKfKx"
      },
      "outputs": [],
      "source": [
        "max(scoring_dict, key=scoring_dict.get), scoring_dict[max(scoring_dict, key=scoring_dict.get)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIcXQqKaKfKy"
      },
      "source": [
        "We see that the best model (RÂ² score-wise) is the one where all features are present. However, this is estimated on training data, so it might very well be that this is overfit. To do this in a better way, we will use cross-validation.\n",
        "When doing this, it is important that for every model we train, we use exactly the same splits, otherwise, extra unwanted sources of variation are present in our model performance estimates. The following code block expands upon the previous code block with these things in mind: **This code may take a little while to run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKySUOLVKfKy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_validate\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X = concretedata.drop(['compressiveStrength'], axis=1)\n",
        "y = concretedata['compressiveStrength']\n",
        "list_of_things = X.columns\n",
        "scoring_dict = {}\n",
        "\n",
        "#NEW:\n",
        "# Define splitter object outside loop to ensure same splits over loop\n",
        "splitter = KFold(n_splits=5, shuffle=True, random_state=None)\n",
        "####\n",
        "\n",
        "for subset in chain.from_iterable(\n",
        "    combinations(list_of_things, r)\n",
        "    for r in range(1, len(list_of_things)+1)\n",
        "    ):\n",
        "\n",
        "    X_subset = X[list(subset)]\n",
        "\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # NEW: instead of simply fitting the model on all train data,\n",
        "    # now we use cross validation to fit and evaluate model\n",
        "    # cross_validate() returns a dict with key 'test_score' containing\n",
        "    # a list of  CV performances of every split\n",
        "    scores = cross_validate(model, X_subset.values, y.values, cv=splitter)\n",
        "    scoring_dict[subset] = np.mean(scores['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEVXWrKcKfKz"
      },
      "source": [
        "#### Exercise 1: how much models did we just train, exactly?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBBRbK130tUU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWcSra0HKfKz"
      },
      "source": [
        "Let's visualize how the test performance changes in function of how many features we had in the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo5SB38DKfKz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter([len(k) for k in scoring_dict.keys()], list(scoring_dict.values()), alpha = 0.25)\n",
        "plt.xlabel('number of features')\n",
        "plt.ylabel('RÂ² score')\n",
        "# taking the best model for every 'n' number of features and plotting them separately:\n",
        "best_score_n = [\n",
        "    max([v for k, v in scoring_dict.items() if len(k) == i])\n",
        "    for i in range(1, X.shape[1]+1)\n",
        "]\n",
        "plt.scatter(range(1, X.shape[1]+1), best_score_n)\n",
        "print('Best feature combination:', max(scoring_dict, key=scoring_dict.get))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydij2VyKKfK0"
      },
      "source": [
        "We see that one certain combination of 5 features already results in a performance on +- the same level as the one with all features. This finding begs the question: could we have found this combination more efficiently, without testing out all possible feature combinations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO-V_gdFKfK0"
      },
      "source": [
        "Now, we will introduce a second dataset. This time, the features are measurements from a flow cytometry experiment. The 'SC' features measure scatter, and say something about the morphologhy of the cells (FSC: forwad scatter, SSC: sideway scatter). The 'FL' features are fluorescence features from different parts of the spectrum. There are two possible bacterial species present in the dataset. The goal is to classify the correct species based on the measurements from the flow cytometer. Species number one corresponds to *Pseudomonas putida*, while species number 6 is *Brachybacterium faecium*. We will use logistic regression to do the classification.\n",
        "\n",
        "This dataset has 10 features instead of the 8 features encountered in the previous dataset. This makes the number of possible combinations (power set): $(2^{10} -1 ) \\cdot n_{folds} = 5115$, instead of $(2^{8} -1) \\cdot n_{folds} = 1275$. We could repeat the same *best subset selection* method, but we will be smarter about it and implement *stepwise forward selection*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C3fnDroKfK0"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "bacterialdata = pd.read_csv('fc_data_new.csv', index_col=0)\n",
        "bacterialdata = bacterialdata.drop(['Width', 'Time'], axis=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao9GPki-KfK0"
      },
      "outputs": [],
      "source": [
        "bacterialdata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGgCr6PIKfK1"
      },
      "source": [
        "#### Exercise: Considering we have 10 features and will use 5-fold cross validation: how much models will we train using stepwise forward selection?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEgmigKqKfK1"
      },
      "source": [
        "#### Exercise: Complete the code below to implement stepwise forward selection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmQcmatPKfK1"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = bacterialdata.drop(['species'], axis=1)\n",
        "y = bacterialdata['species']\n",
        "list_of_things = X.columns\n",
        "scoring_dict = {}\n",
        "\n",
        "splitter = KFold(n_splits=5, shuffle=True, random_state=None)\n",
        "\n",
        "\n",
        "features_already_in_model = set()\n",
        "features_not_in_model = set(X.columns)\n",
        "\n",
        "# iterate through the numbers of features that we can add at every step\n",
        "for :\n",
        "    # at every step: iterate through the features that we can still add\n",
        "    # keep a separate scoring dictionary for features added at this step:\n",
        "    scoring_dict_k = {}\n",
        "    for feature in features_not_in_model:\n",
        "        # select the previously added features + a feature to (maybe) add\n",
        "        X_subset =\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000) # call the model\n",
        "\n",
        "        scores = cross_validate() # do cross validation on the model\n",
        "\n",
        "        scoring_dict_k[feature] =  # record the mean cross validation score\n",
        "\n",
        "    feature_to_add = max(scoring_dict_k, key=scoring_dict_k.get)\n",
        "    features_already_in_model.add(feature_to_add)\n",
        "    features_not_in_model.remove(feature_to_add)\n",
        "    scoring_dict[tuple(features_already_in_model)] = max(scoring_dict_k.values())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter([len(k) for k in scoring_dict.keys()], list(scoring_dict.values()))\n",
        "plt.xlabel('number of features')\n",
        "plt.ylabel('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg6Uy6UZKfK2"
      },
      "outputs": [],
      "source": [
        "for k, v in scoring_dict.items():\n",
        "    print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8lNaR5LKfK2"
      },
      "source": [
        "#### Exercise: Let's say we performed this feature selection method with k-nearest neighbor classifiers instead of logistic regression, and let's say we wanted to additionally tune the number of nearest neighbors we consider. How would you go about combining both feature selection and hyperparameter tuning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jIYSkbtKfK2"
      },
      "source": [
        "## Regularization methods: ridge regression and the lasso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMiV1GtsKfK3"
      },
      "source": [
        "Regularization is one of the most important concepts in machine learning to avoid overfitting. It comes in many forms. In linear regression, regularization techniques typically constrain the coefficient estimates. In return for a little extra bias, this reduces the variance of the coefficient esimates. The two main shrinkage techniques are **ridge regression** and the **lasso**.\n",
        "\n",
        "**Ridge regression penalizes the sum of the squares of the model weights by adding a term to the MSE loss function**:\n",
        "![ridge](https://raw.githubusercontent.com/gdewael/teaching/main/predmod/lab6/img/ridge.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olZ9IYcCKfK3"
      },
      "source": [
        "The lasso does a similar thing, but penalizes the absolute value of the model coefficients. The effect of both approaches is that the model coefficients are shrunk towards zero, resulting in less overfitting and less variance in the predictions (at the cost of a little more bias). We will apply both models on two datasets.\n",
        "\n",
        "Note that we shown the equation for regularization pentalties here for linear regression with MSE loss, but the technique is equally applicable to classification loss functions (e.g. cross entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7JN31TbKfK3"
      },
      "source": [
        "### Linear models for high dimensional data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Z0ejcmKfK3"
      },
      "source": [
        "We will apply ridge regression on the Communities and Crime Data Set. The dataset contains 123 population statistics on 1994 communities. We would like to predict the number of violent crimes per 100000 inhabitants. This is the final column of the dataframe. Of the 123 features, a lot contain missing values, so we will drop these columns and use only 99 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqLsPmtzKfK3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('./communities.csv')\n",
        "\n",
        "# Drop columns with missing values\n",
        "data = data.dropna(axis=1)\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aMRVhH6KfK4"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>Exercise</h2>\n",
        "    <p>Use linear regression and ridge regression to predict the number of violent crimes per 100,000 inhabitants. Use 5-fold cross-validation to evaluate both models. The scikit-learn implementation of RidgeCV automatically performs cross-validation to tune the hyperparameter that determines the amount of regularization, so you don't need to implement a second cross-validation loop. Which model performs best?</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSCLkUQ3KfK4"
      },
      "source": [
        "**Before we apply ridge regression, it's important to make sure that all the features are on the same scale. If one of the features is on a completely different scale (let's say, income can be measured in dollars or in thousands of dollars), this might lead the ridge regression coefficient to change substantially because of the penalty term in the optimization problem. We can make sure that all the features are on the same scale by use of the standard scaling: (see book p. 232)**\n",
        "\n",
        "\\begin{equation}\n",
        "\\tilde{x}_{ij} = \\frac{x_{ij}-\\bar{x}_{j}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_{ij} - \\bar{x}_{j})^2}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgYKuuOhKfK4"
      },
      "source": [
        "We can do this with the ```StandardScaler``` from scikit-learn. We will do the scaling each time in the cross-validation loop using only training data statistics (*think for yourselves: do you still remember why we only use training statistics to do this?*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_n7gdMNKfK4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AddUmtcFKfK5"
      },
      "outputs": [],
      "source": [
        "# Select X and y\n",
        "y = data['ViolentCrimesPerPop'].values\n",
        "X = data.drop(['ViolentCrimesPerPop'], axis=1).values\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "linreg_scores = []\n",
        "ridge_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # select training and testing X & y from indices\n",
        "\n",
        "\n",
        "    # scale X\n",
        "\n",
        "\n",
        "    # initialize the models\n",
        "\n",
        "\n",
        "    # fit, and store the accuracy on the test set\n",
        "\n",
        "\n",
        "print('Average validation fold RÂ² of linear regression: {}'.format(np.mean(linreg_scores)))\n",
        "print('Average validation fold RÂ² of ridge regression: {}'.format(np.mean(ridge_scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC670WUaKfK5"
      },
      "source": [
        "Now suppose that we don't have 99 features, but four times as many features. And suppose that a lot of features are correlated. This situation is very common in lots of datasets. We will mimic this situation by adding correlated features to our original feature matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbNgSkx2KfK5"
      },
      "outputs": [],
      "source": [
        "X_1 = X + np.random.normal(loc=0, scale=0.05, size=(X.shape))\n",
        "X_2 = X + np.random.normal(loc=0, scale=0.1, size=(X.shape))\n",
        "X_3 = X + np.random.normal(loc=0, scale=0.01, size=(X.shape))\n",
        "X_expanded = np.concatenate((X, X_1, X_2, X_3), axis=1)\n",
        "\n",
        "X_expanded.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Kjz4_rKfK5"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>Exercise</h2>\n",
        "    <p>Repeat the comparison between ridge regression and linear regression from above, but with the new feature matrix that contains correlated features. What happens with the performance of linear regression? What happens with the regularization parameter? Now, add even more correlated features and repeat the analysis.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09hjGXMiKfK5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXKYNnSOKfK5"
      },
      "source": [
        "\n",
        "Finally, it's interesting to look at how the amount of regularization in ridge regression and lasso regression affects the magnitudes of the fitted weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMq5LvgIKfK6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "y = data['ViolentCrimesPerPop'].values\n",
        "X = data.drop(['ViolentCrimesPerPop'], axis=1).values\n",
        "\n",
        "# Scale X, note the \"wrong\" way in which we do it here. This code is only to make a nice plot!\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(X)\n",
        "x = X\n",
        "alphas = np.logspace(-5,2,100)\n",
        "\n",
        "ridge_coefficients = np.ndarray(shape=(50, len(alphas)))\n",
        "lasso_coefficients = np.ndarray(shape=(50, len(alphas)))\n",
        "\n",
        "for i,a in enumerate(alphas):\n",
        "    ridgemodel = Ridge(alpha=a)\n",
        "    lassomodel = Lasso(alpha=a, max_iter=10000)\n",
        "\n",
        "    ridgemodel.fit(X,y)\n",
        "    lassomodel.fit(X,y)\n",
        "\n",
        "    ridge_coefficients[:, i] = ridgemodel.coef_[:50]\n",
        "    lasso_coefficients[:, i] = lassomodel.coef_[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Nvx7akKfK6"
      },
      "outputs": [],
      "source": [
        "fig, ((ax1, ax2)) = plt.subplots(figsize=(15,10), nrows=2, sharex=True)\n",
        "\n",
        "for c in range(ridge_coefficients.shape[0]):\n",
        "    pd.Series(ridge_coefficients[c,:]).plot(ax=ax1)\n",
        "    pd.Series(lasso_coefficients[c,:]).plot(ax=ax2)\n",
        "\n",
        "ax2.set_xlabel('Regularization parameter').set_fontsize(20)\n",
        "ax1.set_ylabel('Model weights')\n",
        "ax2.set_ylabel('Model weights')\n",
        "ax1.set_title('Model weights for increasing regularization - Ridge regression').set_fontsize(20)\n",
        "ax2.set_title('Model weights for increasing regularization - Lasso').set_fontsize(20)\n",
        "ax2.get_xaxis().set_ticks(alphas);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDm2nZ8bKfK6"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>Exercise</h2>\n",
        "    <p>Make sure you understand the plots above. What is the main difference between ridge regression and the lasso?\n",
        "    </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWgjkB4AKfK6"
      },
      "source": [
        "### Feature selection with the lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_82GZJCKfK6"
      },
      "source": [
        "Suppose that we are interested in selecting only a couple of features out of a high dimensional dataset. Let's fit ridge regression and lasso regression on the data and look at the model coefficients for both models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4szzL8tKfK6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ridgemodel = RidgeCV(cv=5)\n",
        "lassomodel = LassoCV(cv=5, max_iter=10000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Scale X\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "ridgemodel.fit(X_train, y_train)\n",
        "ridgescore = np.round(ridgemodel.score(X_test, y_test),2)\n",
        "lassomodel.fit(X_train, y_train)\n",
        "lassoscore = np.round(lassomodel.score(X_test, y_test),2)\n",
        "\n",
        "# Plot of the coefficients for ridge regression\n",
        "fig, ((ax1, ax2)) = plt.subplots(figsize=(15, 10), nrows=2)\n",
        "pd.Series(ridgemodel.coef_).plot(kind='bar', ax=ax1)\n",
        "ax1.set_title('Ridge regression coefficients. Test set RÂ²: {}'.format(ridgescore)).set_fontsize(40)\n",
        "ax1.get_xaxis().set_ticks([])\n",
        "ax1.set_xlabel('Features')\n",
        "\n",
        "# Plot of the coefficients for the lasso\n",
        "pd.Series(lassomodel.coef_).plot(kind='bar', ax=ax2)\n",
        "ax2.set_title('Lasso regression coefficients. Test set RÂ²: {}'.format(lassoscore)).set_fontsize(40)\n",
        "ax2.get_xaxis().set_ticks([])\n",
        "ax2.set_xlabel('Features');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlfJcYzJKfK6"
      },
      "source": [
        "The lasso applies regularization by constraining the sum of the absolute values of the model coefficients (the L1-norm). A result of this is that a lot of model coefficients are set to zero: the lasso performs **feature selection**. This is not the case for ridge regression: the model weights are rarely set to zero. Feature selection is a nice property if we want an interpretable model. Let's list the features with non-zero coefficients in the lasso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wVKQdtUKfK7"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,9))\n",
        "sns.barplot(x= pd.Series(lassomodel.coef_[lassomodel.coef_ != 0]),\n",
        "            y=data.drop(['ViolentCrimesPerPop'], axis=1).columns[lassomodel.coef_ != 0],\n",
        "            palette=['steelblue' if n > 0 else 'coral' for n in lassomodel.coef_[lassomodel.coef_ != 0]],\n",
        "            ax=ax);\n",
        "ax.set_title('Lasso model coefficients for the Community Crime dataset').set_fontsize(20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMwkhvMrKfK7"
      },
      "source": [
        "#### Extra note: **machine learning bias**\n",
        "\n",
        "Take a look at which features our model has identified as important for predicting whether a community will have a higher percentage of crime. You will perhaps be shocked (or unsurprised) to find that our model has quite a racial bias.\n",
        "\n",
        "An in-depth discussion of this topic is out-of-scope for this PC-lab. However we note two important factors contributing to this bias here:\n",
        "- Sampling bias: were communities selected uniformly, or more pertinently \"fairly\" (How do you define \"fairness\"?)\n",
        "- Correlation between features: socio-economical factors causal for crime rates will be correlated with all of the features. Remember that our linear model simply captures patterns/correlations between features and outcomes. Without a view of the causal processes underlying the data-generation, we can never infer causalities from data in itself.\n",
        "\n",
        "When a model trained on real-world (past) data is employed to influence future decisions, it is prudent to keep in mind that that model has learned to reflect the state of the world as it is/was, not how it should be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijMhAKRsKfK7"
      },
      "source": [
        "### Extra parts: Regularization methods for $n < p$ data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY3uqAi_KfK7"
      },
      "source": [
        "In high dimensional data, we often have more features than observations. This is often called the $n < p$ scenario. In this situation, linear regression breaks down: the variance on the weight estimates blows up and the model will fail on unseen data. Both ridge regression and the lasso are valuable solutions here.\n",
        "\n",
        "We will work with a dataset that contains spectral measurements on food samples. The target variables are the water, fat and protein content of the samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY7Bxv-mKfK7"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = pd.read_csv('./meatNIR1000.csv', header=None)\n",
        "colnames = pd.read_csv('./meatNIR1000.colnames', header=None)\n",
        "data.columns = colnames.values[0]\n",
        "W = data['water']\n",
        "F = data['fat']\n",
        "P = data['protein']\n",
        "\n",
        "data = data.drop(['water', 'fat', 'protein'], axis=1)\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3swHHIZ4KfK7"
      },
      "source": [
        "We have 240 observations, but 500 features, so we are in a $n < p$ setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWwyF4upKfK7"
      },
      "outputs": [],
      "source": [
        "# let's plot some random data points\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "for i in range(20):\n",
        "    ax.plot(data.iloc[np.random.choice(range(len(data)))])\n",
        "ax.set_xlabel('Wavelength').set_fontsize(20)\n",
        "ax.set_ylabel('Absorbance').set_fontsize(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SebAujEKKfK7"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>Exercise</h2>\n",
        "    <p>Try to fit a linear regression model to predict the fat content of a sample on the entire dataset (don't bother with cross validation / splitting / scaling, just fit a model). Look at the model coefficients (look up documentation to see how to) What happens?\n",
        "    </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJV_SlPmKfK8"
      },
      "outputs": [],
      "source": [
        "# ** solution\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X = data.values\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X, F)\n",
        "model.coef_[:20]\n",
        "# ** solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKAcTk5nKfK8"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h2>Exercise</h2>\n",
        "    <p>Compare the performance of linear regression with ridge regression and with the lasso. Use 5-fold cross-validation to evaluate both models.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoLQlGHXKfK8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.linear_model import LassoCV, RidgeCV\n",
        "# Select X and y\n",
        "y = F\n",
        "X = data.values\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "linreg_scores = []\n",
        "ridge_scores = []\n",
        "lasso_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "print('Average validation fold RÂ² of linear regression: {}'.format(np.mean(linreg_scores)))\n",
        "print('Average validation fold RÂ² of ridge regression: {}'.format(np.mean(ridge_scores)))\n",
        "print('Average validation fold RÂ² of lasso regression: {}'.format(np.mean(lasso_scores)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkpBE1YuKfK8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "i8lNaR5LKfK2",
        "zMwkhvMrKfK7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
